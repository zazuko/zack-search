{"version":3,"file":"chunk-0.development.js","sources":["webpack:///./node_modules/@rdfjs/parser-jsonld/index.js","webpack:///./node_modules/@rdfjs/parser-jsonld/lib/ParserStream.js","webpack:///./node_modules/canonicalize/lib/canonicalize.js","webpack:///./node_modules/cross-fetch/dist/browser-polyfill.js","webpack:///./node_modules/http-link-header/lib/link.js","webpack:///index.ts","webpack:///ContextParser.ts","webpack:///ErrorCoded.ts","webpack:///FetchDocumentLoader.ts","webpack:///JsonLdContext.ts","webpack:///JsonLdContextNormalized.ts","webpack:///Util.ts","webpack:///./node_modules/jsonld-streaming-parser/index.js","webpack:///./node_modules/jsonld-streaming-parser/lib/ContextTree.js","webpack:///./node_modules/jsonld-streaming-parser/lib/JsonLdParser.js","webpack:///./node_modules/jsonld-streaming-parser/lib/ParsingContext.js","webpack:///./node_modules/jsonld-streaming-parser/lib/Util.js","webpack:///./node_modules/jsonld-streaming-parser/lib/containerhandler/ContainerHandlerIdentifier.js","webpack:///./node_modules/jsonld-streaming-parser/lib/containerhandler/ContainerHandlerIndex.js","webpack:///./node_modules/jsonld-streaming-parser/lib/containerhandler/ContainerHandlerLanguage.js","webpack:///./node_modules/jsonld-streaming-parser/lib/containerhandler/ContainerHandlerType.js","webpack:///./node_modules/jsonld-streaming-parser/lib/entryhandler/EntryHandlerArrayValue.js","webpack:///./node_modules/jsonld-streaming-parser/lib/entryhandler/EntryHandlerContainer.js","webpack:///./node_modules/jsonld-streaming-parser/lib/entryhandler/EntryHandlerInvalidFallback.js","webpack:///./node_modules/jsonld-streaming-parser/lib/entryhandler/EntryHandlerPredicate.js","webpack:///./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeyword.js","webpack:///./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordContext.js","webpack:///./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordGraph.js","webpack:///./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordId.js","webpack:///./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordIncluded.js","webpack:///./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordNest.js","webpack:///./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordType.js","webpack:///./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordUnknownFallback.js","webpack:///./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordValue.js","webpack:///Resolve.ts"],"sourcesContent":["const Sink = require('@rdfjs/sink')\nconst ParserStream = require('./lib/ParserStream')\n\nclass Parser extends Sink {\n  constructor (options) {\n    super(ParserStream, options)\n  }\n}\n\nmodule.exports = Parser\n","const rdf = require('@rdfjs/data-model')\nconst { JsonLdParser } = require('jsonld-streaming-parser')\nconst { Transform } = require('readable-stream')\n\nconst relativeIriProtocol = 'null:'\n\nfunction termCleanup (factory) {\n  return term => {\n    if (term.termType !== 'NamedNode') {\n      return null\n    }\n\n    if (!term.value.startsWith(relativeIriProtocol)) {\n      return null\n    }\n\n    // remove dummy protocol workaround for relative IRIs\n    return factory.namedNode(term.value.slice(relativeIriProtocol.length))\n  }\n}\n\nfunction quadCleanup (factory) {\n  const cleanup = termCleanup(factory)\n\n  return quad => {\n    const subject = cleanup(quad.subject)\n    const predicate = cleanup(quad.predicate)\n    const object = cleanup(quad.object)\n    const graph = cleanup(quad.graph)\n\n    if (subject || predicate || object || graph) {\n      return factory.quad(\n        subject || quad.subject,\n        predicate || quad.predicate,\n        object || quad.object,\n        graph || quad.graph\n      )\n    }\n\n    return quad\n  }\n}\n\nclass ParserStream {\n  constructor (input, { baseIRI = relativeIriProtocol, context = null, factory = rdf } = {}) {\n    const parser = new JsonLdParser({\n      baseIRI,\n      context,\n      dataFactory: factory,\n      streamingProfile: false\n    })\n\n    input.pipe(parser)\n\n    const cleanup = quadCleanup(factory)\n\n    const transform = new Transform({\n      objectMode: true,\n      transform: (quad, encoding, callback) => {\n        callback(null, cleanup(quad))\n      }\n    })\n\n    parser.on('context', context => {\n      Object.entries(context).forEach(([prefix, iri]) => {\n        transform.emit('prefix', prefix, factory.namedNode(iri))\n      })\n    })\n    parser.on('error', err => transform.destroy(err))\n    parser.pipe(transform)\n\n    return transform\n  }\n}\n\nmodule.exports = ParserStream\n","/* jshint esversion: 6 */\n/* jslint node: true */\n'use strict';\n\nmodule.exports = function serialize (object) {\n  if (object === null || typeof object !== 'object' || object.toJSON != null) {\n    return JSON.stringify(object);\n  }\n\n  if (Array.isArray(object)) {\n    return '[' + object.reduce((t, cv, ci) => {\n      const comma = ci === 0 ? '' : ',';\n      const value = cv === undefined || typeof cv === 'symbol' ? null : cv;\n      return t + comma + serialize(value);\n    }, '') + ']';\n  }\n\n  return '{' + Object.keys(object).sort().reduce((t, cv, ci) => {\n    if (object[cv] === undefined ||\n        typeof object[cv] === 'symbol') {\n      return t;\n    }\n    const comma = t.length === 0 ? '' : ',';\n    return t + comma + serialize(cv) + ':' + serialize(object[cv]);\n  }, '') + '}';\n};\n","(function(self) {\n\nvar irrelevant = (function (exports) {\n\n  var support = {\n    searchParams: 'URLSearchParams' in self,\n    iterable: 'Symbol' in self && 'iterator' in Symbol,\n    blob:\n      'FileReader' in self &&\n      'Blob' in self &&\n      (function() {\n        try {\n          new Blob();\n          return true\n        } catch (e) {\n          return false\n        }\n      })(),\n    formData: 'FormData' in self,\n    arrayBuffer: 'ArrayBuffer' in self\n  };\n\n  function isDataView(obj) {\n    return obj && DataView.prototype.isPrototypeOf(obj)\n  }\n\n  if (support.arrayBuffer) {\n    var viewClasses = [\n      '[object Int8Array]',\n      '[object Uint8Array]',\n      '[object Uint8ClampedArray]',\n      '[object Int16Array]',\n      '[object Uint16Array]',\n      '[object Int32Array]',\n      '[object Uint32Array]',\n      '[object Float32Array]',\n      '[object Float64Array]'\n    ];\n\n    var isArrayBufferView =\n      ArrayBuffer.isView ||\n      function(obj) {\n        return obj && viewClasses.indexOf(Object.prototype.toString.call(obj)) > -1\n      };\n  }\n\n  function normalizeName(name) {\n    if (typeof name !== 'string') {\n      name = String(name);\n    }\n    if (/[^a-z0-9\\-#$%&'*+.^_`|~]/i.test(name)) {\n      throw new TypeError('Invalid character in header field name')\n    }\n    return name.toLowerCase()\n  }\n\n  function normalizeValue(value) {\n    if (typeof value !== 'string') {\n      value = String(value);\n    }\n    return value\n  }\n\n  // Build a destructive iterator for the value list\n  function iteratorFor(items) {\n    var iterator = {\n      next: function() {\n        var value = items.shift();\n        return {done: value === undefined, value: value}\n      }\n    };\n\n    if (support.iterable) {\n      iterator[Symbol.iterator] = function() {\n        return iterator\n      };\n    }\n\n    return iterator\n  }\n\n  function Headers(headers) {\n    this.map = {};\n\n    if (headers instanceof Headers) {\n      headers.forEach(function(value, name) {\n        this.append(name, value);\n      }, this);\n    } else if (Array.isArray(headers)) {\n      headers.forEach(function(header) {\n        this.append(header[0], header[1]);\n      }, this);\n    } else if (headers) {\n      Object.getOwnPropertyNames(headers).forEach(function(name) {\n        this.append(name, headers[name]);\n      }, this);\n    }\n  }\n\n  Headers.prototype.append = function(name, value) {\n    name = normalizeName(name);\n    value = normalizeValue(value);\n    var oldValue = this.map[name];\n    this.map[name] = oldValue ? oldValue + ', ' + value : value;\n  };\n\n  Headers.prototype['delete'] = function(name) {\n    delete this.map[normalizeName(name)];\n  };\n\n  Headers.prototype.get = function(name) {\n    name = normalizeName(name);\n    return this.has(name) ? this.map[name] : null\n  };\n\n  Headers.prototype.has = function(name) {\n    return this.map.hasOwnProperty(normalizeName(name))\n  };\n\n  Headers.prototype.set = function(name, value) {\n    this.map[normalizeName(name)] = normalizeValue(value);\n  };\n\n  Headers.prototype.forEach = function(callback, thisArg) {\n    for (var name in this.map) {\n      if (this.map.hasOwnProperty(name)) {\n        callback.call(thisArg, this.map[name], name, this);\n      }\n    }\n  };\n\n  Headers.prototype.keys = function() {\n    var items = [];\n    this.forEach(function(value, name) {\n      items.push(name);\n    });\n    return iteratorFor(items)\n  };\n\n  Headers.prototype.values = function() {\n    var items = [];\n    this.forEach(function(value) {\n      items.push(value);\n    });\n    return iteratorFor(items)\n  };\n\n  Headers.prototype.entries = function() {\n    var items = [];\n    this.forEach(function(value, name) {\n      items.push([name, value]);\n    });\n    return iteratorFor(items)\n  };\n\n  if (support.iterable) {\n    Headers.prototype[Symbol.iterator] = Headers.prototype.entries;\n  }\n\n  function consumed(body) {\n    if (body.bodyUsed) {\n      return Promise.reject(new TypeError('Already read'))\n    }\n    body.bodyUsed = true;\n  }\n\n  function fileReaderReady(reader) {\n    return new Promise(function(resolve, reject) {\n      reader.onload = function() {\n        resolve(reader.result);\n      };\n      reader.onerror = function() {\n        reject(reader.error);\n      };\n    })\n  }\n\n  function readBlobAsArrayBuffer(blob) {\n    var reader = new FileReader();\n    var promise = fileReaderReady(reader);\n    reader.readAsArrayBuffer(blob);\n    return promise\n  }\n\n  function readBlobAsText(blob) {\n    var reader = new FileReader();\n    var promise = fileReaderReady(reader);\n    reader.readAsText(blob);\n    return promise\n  }\n\n  function readArrayBufferAsText(buf) {\n    var view = new Uint8Array(buf);\n    var chars = new Array(view.length);\n\n    for (var i = 0; i < view.length; i++) {\n      chars[i] = String.fromCharCode(view[i]);\n    }\n    return chars.join('')\n  }\n\n  function bufferClone(buf) {\n    if (buf.slice) {\n      return buf.slice(0)\n    } else {\n      var view = new Uint8Array(buf.byteLength);\n      view.set(new Uint8Array(buf));\n      return view.buffer\n    }\n  }\n\n  function Body() {\n    this.bodyUsed = false;\n\n    this._initBody = function(body) {\n      this._bodyInit = body;\n      if (!body) {\n        this._bodyText = '';\n      } else if (typeof body === 'string') {\n        this._bodyText = body;\n      } else if (support.blob && Blob.prototype.isPrototypeOf(body)) {\n        this._bodyBlob = body;\n      } else if (support.formData && FormData.prototype.isPrototypeOf(body)) {\n        this._bodyFormData = body;\n      } else if (support.searchParams && URLSearchParams.prototype.isPrototypeOf(body)) {\n        this._bodyText = body.toString();\n      } else if (support.arrayBuffer && support.blob && isDataView(body)) {\n        this._bodyArrayBuffer = bufferClone(body.buffer);\n        // IE 10-11 can't handle a DataView body.\n        this._bodyInit = new Blob([this._bodyArrayBuffer]);\n      } else if (support.arrayBuffer && (ArrayBuffer.prototype.isPrototypeOf(body) || isArrayBufferView(body))) {\n        this._bodyArrayBuffer = bufferClone(body);\n      } else {\n        this._bodyText = body = Object.prototype.toString.call(body);\n      }\n\n      if (!this.headers.get('content-type')) {\n        if (typeof body === 'string') {\n          this.headers.set('content-type', 'text/plain;charset=UTF-8');\n        } else if (this._bodyBlob && this._bodyBlob.type) {\n          this.headers.set('content-type', this._bodyBlob.type);\n        } else if (support.searchParams && URLSearchParams.prototype.isPrototypeOf(body)) {\n          this.headers.set('content-type', 'application/x-www-form-urlencoded;charset=UTF-8');\n        }\n      }\n    };\n\n    if (support.blob) {\n      this.blob = function() {\n        var rejected = consumed(this);\n        if (rejected) {\n          return rejected\n        }\n\n        if (this._bodyBlob) {\n          return Promise.resolve(this._bodyBlob)\n        } else if (this._bodyArrayBuffer) {\n          return Promise.resolve(new Blob([this._bodyArrayBuffer]))\n        } else if (this._bodyFormData) {\n          throw new Error('could not read FormData body as blob')\n        } else {\n          return Promise.resolve(new Blob([this._bodyText]))\n        }\n      };\n\n      this.arrayBuffer = function() {\n        if (this._bodyArrayBuffer) {\n          return consumed(this) || Promise.resolve(this._bodyArrayBuffer)\n        } else {\n          return this.blob().then(readBlobAsArrayBuffer)\n        }\n      };\n    }\n\n    this.text = function() {\n      var rejected = consumed(this);\n      if (rejected) {\n        return rejected\n      }\n\n      if (this._bodyBlob) {\n        return readBlobAsText(this._bodyBlob)\n      } else if (this._bodyArrayBuffer) {\n        return Promise.resolve(readArrayBufferAsText(this._bodyArrayBuffer))\n      } else if (this._bodyFormData) {\n        throw new Error('could not read FormData body as text')\n      } else {\n        return Promise.resolve(this._bodyText)\n      }\n    };\n\n    if (support.formData) {\n      this.formData = function() {\n        return this.text().then(decode)\n      };\n    }\n\n    this.json = function() {\n      return this.text().then(JSON.parse)\n    };\n\n    return this\n  }\n\n  // HTTP methods whose capitalization should be normalized\n  var methods = ['DELETE', 'GET', 'HEAD', 'OPTIONS', 'POST', 'PUT'];\n\n  function normalizeMethod(method) {\n    var upcased = method.toUpperCase();\n    return methods.indexOf(upcased) > -1 ? upcased : method\n  }\n\n  function Request(input, options) {\n    options = options || {};\n    var body = options.body;\n\n    if (input instanceof Request) {\n      if (input.bodyUsed) {\n        throw new TypeError('Already read')\n      }\n      this.url = input.url;\n      this.credentials = input.credentials;\n      if (!options.headers) {\n        this.headers = new Headers(input.headers);\n      }\n      this.method = input.method;\n      this.mode = input.mode;\n      this.signal = input.signal;\n      if (!body && input._bodyInit != null) {\n        body = input._bodyInit;\n        input.bodyUsed = true;\n      }\n    } else {\n      this.url = String(input);\n    }\n\n    this.credentials = options.credentials || this.credentials || 'same-origin';\n    if (options.headers || !this.headers) {\n      this.headers = new Headers(options.headers);\n    }\n    this.method = normalizeMethod(options.method || this.method || 'GET');\n    this.mode = options.mode || this.mode || null;\n    this.signal = options.signal || this.signal;\n    this.referrer = null;\n\n    if ((this.method === 'GET' || this.method === 'HEAD') && body) {\n      throw new TypeError('Body not allowed for GET or HEAD requests')\n    }\n    this._initBody(body);\n  }\n\n  Request.prototype.clone = function() {\n    return new Request(this, {body: this._bodyInit})\n  };\n\n  function decode(body) {\n    var form = new FormData();\n    body\n      .trim()\n      .split('&')\n      .forEach(function(bytes) {\n        if (bytes) {\n          var split = bytes.split('=');\n          var name = split.shift().replace(/\\+/g, ' ');\n          var value = split.join('=').replace(/\\+/g, ' ');\n          form.append(decodeURIComponent(name), decodeURIComponent(value));\n        }\n      });\n    return form\n  }\n\n  function parseHeaders(rawHeaders) {\n    var headers = new Headers();\n    // Replace instances of \\r\\n and \\n followed by at least one space or horizontal tab with a space\n    // https://tools.ietf.org/html/rfc7230#section-3.2\n    var preProcessedHeaders = rawHeaders.replace(/\\r?\\n[\\t ]+/g, ' ');\n    preProcessedHeaders.split(/\\r?\\n/).forEach(function(line) {\n      var parts = line.split(':');\n      var key = parts.shift().trim();\n      if (key) {\n        var value = parts.join(':').trim();\n        headers.append(key, value);\n      }\n    });\n    return headers\n  }\n\n  Body.call(Request.prototype);\n\n  function Response(bodyInit, options) {\n    if (!options) {\n      options = {};\n    }\n\n    this.type = 'default';\n    this.status = options.status === undefined ? 200 : options.status;\n    this.ok = this.status >= 200 && this.status < 300;\n    this.statusText = 'statusText' in options ? options.statusText : 'OK';\n    this.headers = new Headers(options.headers);\n    this.url = options.url || '';\n    this._initBody(bodyInit);\n  }\n\n  Body.call(Response.prototype);\n\n  Response.prototype.clone = function() {\n    return new Response(this._bodyInit, {\n      status: this.status,\n      statusText: this.statusText,\n      headers: new Headers(this.headers),\n      url: this.url\n    })\n  };\n\n  Response.error = function() {\n    var response = new Response(null, {status: 0, statusText: ''});\n    response.type = 'error';\n    return response\n  };\n\n  var redirectStatuses = [301, 302, 303, 307, 308];\n\n  Response.redirect = function(url, status) {\n    if (redirectStatuses.indexOf(status) === -1) {\n      throw new RangeError('Invalid status code')\n    }\n\n    return new Response(null, {status: status, headers: {location: url}})\n  };\n\n  exports.DOMException = self.DOMException;\n  try {\n    new exports.DOMException();\n  } catch (err) {\n    exports.DOMException = function(message, name) {\n      this.message = message;\n      this.name = name;\n      var error = Error(message);\n      this.stack = error.stack;\n    };\n    exports.DOMException.prototype = Object.create(Error.prototype);\n    exports.DOMException.prototype.constructor = exports.DOMException;\n  }\n\n  function fetch(input, init) {\n    return new Promise(function(resolve, reject) {\n      var request = new Request(input, init);\n\n      if (request.signal && request.signal.aborted) {\n        return reject(new exports.DOMException('Aborted', 'AbortError'))\n      }\n\n      var xhr = new XMLHttpRequest();\n\n      function abortXhr() {\n        xhr.abort();\n      }\n\n      xhr.onload = function() {\n        var options = {\n          status: xhr.status,\n          statusText: xhr.statusText,\n          headers: parseHeaders(xhr.getAllResponseHeaders() || '')\n        };\n        options.url = 'responseURL' in xhr ? xhr.responseURL : options.headers.get('X-Request-URL');\n        var body = 'response' in xhr ? xhr.response : xhr.responseText;\n        resolve(new Response(body, options));\n      };\n\n      xhr.onerror = function() {\n        reject(new TypeError('Network request failed'));\n      };\n\n      xhr.ontimeout = function() {\n        reject(new TypeError('Network request failed'));\n      };\n\n      xhr.onabort = function() {\n        reject(new exports.DOMException('Aborted', 'AbortError'));\n      };\n\n      xhr.open(request.method, request.url, true);\n\n      if (request.credentials === 'include') {\n        xhr.withCredentials = true;\n      } else if (request.credentials === 'omit') {\n        xhr.withCredentials = false;\n      }\n\n      if ('responseType' in xhr && support.blob) {\n        xhr.responseType = 'blob';\n      }\n\n      request.headers.forEach(function(value, name) {\n        xhr.setRequestHeader(name, value);\n      });\n\n      if (request.signal) {\n        request.signal.addEventListener('abort', abortXhr);\n\n        xhr.onreadystatechange = function() {\n          // DONE (success or failure)\n          if (xhr.readyState === 4) {\n            request.signal.removeEventListener('abort', abortXhr);\n          }\n        };\n      }\n\n      xhr.send(typeof request._bodyInit === 'undefined' ? null : request._bodyInit);\n    })\n  }\n\n  fetch.polyfill = true;\n\n  if (!self.fetch) {\n    self.fetch = fetch;\n    self.Headers = Headers;\n    self.Request = Request;\n    self.Response = Response;\n  }\n\n  exports.Headers = Headers;\n  exports.Request = Request;\n  exports.Response = Response;\n  exports.fetch = fetch;\n\n  Object.defineProperty(exports, '__esModule', { value: true });\n\n  return exports;\n\n})({});\n})(typeof self !== 'undefined' ? self : this);\n","'use strict'\n\nvar COMPATIBLE_ENCODING_PATTERN = /^utf-?8|ascii|utf-?16-?le|ucs-?2|base-?64|latin-?1$/i\nvar WS_TRIM_PATTERN = /^[\\s\\uFEFF\\xA0]+|[\\s\\uFEFF\\xA0]+$/g\nvar WS_CHAR_PATTERN = /\\s|\\uFEFF|\\xA0/\nvar WS_FOLD_PATTERN = /\\r?\\n[\\x20\\x09]+/g\nvar DELIMITER_PATTERN = /[;,\"]/\nvar WS_DELIMITER_PATTERN = /[;,\"]|\\s/\n\n/**\n * Token character pattern\n * @type {RegExp}\n * @see https://tools.ietf.org/html/rfc7230#section-3.2.6\n */\nvar TOKEN_PATTERN = /^[!#$%&'*+\\-\\.^_`|~\\da-zA-Z]+$/\n\nvar STATE = {\n  IDLE: 1 << 0,\n  URI: 1 << 1,\n  ATTR: 1 << 2,\n}\n\nfunction trim( value ) {\n  return value.replace( WS_TRIM_PATTERN, '' )\n}\n\nfunction hasWhitespace( value ) {\n  return WS_CHAR_PATTERN.test( value )\n}\n\nfunction skipWhitespace( value, offset ) {\n  while( hasWhitespace( value[offset] ) ) {\n    offset++\n  }\n  return offset\n}\n\nfunction needsQuotes( value ) {\n  return WS_DELIMITER_PATTERN.test( value ) ||\n    !TOKEN_PATTERN.test( value )\n}\n\n/**\n * Shallow compares two objects to check if their properties match.\n * @param {object} object1 First object to compare.\n * @param {object} object2 Second object to compare.\n * @returns {boolean} Do the objects have matching properties.\n */\nfunction shallowCompareObjects( object1, object2 ) {\n  return (\n    Object.keys( object1 ).length === Object.keys( object2 ).length &&\n    Object.keys( object1 ).every(\n      ( key ) => key in object2 && object1[ key ] === object2[ key ]\n    )\n  );\n}\n\nclass Link {\n\n  /**\n   * Link\n   * @constructor\n   * @param {String} [value]\n   * @returns {Link}\n   */\n  constructor( value ) {\n\n    /** @type {Array} URI references */\n    this.refs = []\n\n    if( value ) {\n      this.parse( value )\n    }\n\n  }\n\n  /**\n   * Get refs with given relation type\n   * @param {String} value\n   * @returns {Array<Object>}\n   */\n  rel( value ) {\n\n    var links = []\n    var type = value.toLowerCase()\n\n    for( var i = 0; i < this.refs.length; i++ ) {\n      if( this.refs[ i ].rel.toLowerCase() === type ) {\n        links.push( this.refs[ i ] )\n      }\n    }\n\n    return links\n\n  }\n\n  /**\n   * Get refs where given attribute has a given value\n   * @param {String} attr\n   * @param {String} value\n   * @returns {Array<Object>}\n   */\n  get( attr, value ) {\n\n    attr = attr.toLowerCase()\n\n    var links = []\n\n    for( var i = 0; i < this.refs.length; i++ ) {\n      if( this.refs[ i ][ attr ] === value ) {\n        links.push( this.refs[ i ] )\n      }\n    }\n\n    return links\n\n  }\n\n  /** Sets a reference. */\n  set( link ) {\n    this.refs.push( link )\n    return this\n  }\n\n  /**\n   * Sets a reference if a reference with similar properties isn’t already set.\n   */\n  setUnique( link ) {\n\n    if( !this.refs.some(( ref ) => shallowCompareObjects( ref, link )) ) {\n      this.refs.push( link )\n    }\n\n    return this\n\n  }\n\n  has( attr, value ) {\n\n    attr = attr.toLowerCase()\n\n    for( var i = 0; i < this.refs.length; i++ ) {\n      if( this.refs[ i ][ attr ] === value ) {\n        return true\n      }\n    }\n\n    return false\n\n  }\n\n  parse( value, offset ) {\n\n    offset = offset || 0\n    value = offset ? value.slice( offset ) : value\n\n    // Trim & unfold folded lines\n    value = trim( value ).replace( WS_FOLD_PATTERN, '' )\n\n    var state = STATE.IDLE\n    var length = value.length\n    var offset = 0\n    var ref = null\n\n    while( offset < length ) {\n      if( state === STATE.IDLE ) {\n        if( hasWhitespace( value[offset] ) ) {\n          offset++\n          continue\n        } else if( value[offset] === '<' ) {\n          if( ref != null ) {\n            ref.rel != null ?\n              this.refs.push( ...Link.expandRelations( ref ) ) :\n              this.refs.push( ref )\n          }\n          var end = value.indexOf( '>', offset )\n          if( end === -1 ) throw new Error( 'Expected end of URI delimiter at offset ' + offset )\n          ref = { uri: value.slice( offset + 1, end ) }\n          // this.refs.push( ref )\n          offset = end\n          state = STATE.URI\n        } else {\n          throw new Error( 'Unexpected character \"' + value[offset] + '\" at offset ' + offset )\n        }\n        offset++\n      } else if( state === STATE.URI ) {\n        if( hasWhitespace( value[offset] ) ) {\n          offset++\n          continue\n        } else if( value[offset] === ';' ) {\n          state = STATE.ATTR\n          offset++\n        } else if( value[offset] === ',' ) {\n          state = STATE.IDLE\n          offset++\n        } else {\n          throw new Error( 'Unexpected character \"' + value[offset] + '\" at offset ' + offset )\n        }\n      } else if( state === STATE.ATTR ) {\n        if( value[offset] ===';' || hasWhitespace( value[offset] ) ) {\n          offset++\n          continue\n        }\n        var end = value.indexOf( '=', offset )\n        if( end === -1 ) throw new Error( 'Expected attribute delimiter at offset ' + offset )\n        var attr = trim( value.slice( offset, end ) ).toLowerCase()\n        var attrValue = ''\n        offset = end + 1\n        offset = skipWhitespace( value, offset )\n        if( value[offset] === '\"' ) {\n          offset++\n          while( offset < length ) {\n            if( value[offset] === '\"' ) {\n              offset++; break\n            }\n            if( value[offset] === '\\\\' ) {\n              offset++\n            }\n            attrValue += value[offset]\n            offset++\n          }\n        } else {\n          var end = offset + 1\n          while( !DELIMITER_PATTERN.test( value[end] ) && end < length ) {\n            end++\n          }\n          attrValue = value.slice( offset, end )\n          offset = end\n        }\n        if( ref[ attr ] && Link.isSingleOccurenceAttr( attr ) ) {\n          // Ignore multiples of attributes which may only appear once\n        } else if( attr[ attr.length - 1 ] === '*' ) {\n          ref[ attr ] = Link.parseExtendedValue( attrValue )\n        } else {\n          attrValue = attr === 'type' ?\n            attrValue.toLowerCase() : attrValue\n          if( ref[ attr ] != null ) {\n            if( Array.isArray( ref[ attr ] ) ) {\n              ref[ attr ].push( attrValue )\n            } else {\n              ref[ attr ] = [ ref[ attr ], attrValue ]\n            }\n          } else {\n            ref[ attr ] = attrValue\n          }\n        }\n        switch( value[offset] ) {\n          case ',': state = STATE.IDLE; break\n          case ';': state = STATE.ATTR; break\n        }\n        offset++\n      } else {\n        throw new Error( 'Unknown parser state \"' + state + '\"' )\n      }\n    }\n\n    if( ref != null ) {\n      ref.rel != null ?\n        this.refs.push( ...Link.expandRelations( ref ) ) :\n        this.refs.push( ref )\n    }\n\n    ref = null\n\n    return this\n\n  }\n\n  toString() {\n\n    var refs = []\n    var link = ''\n    var ref = null\n\n    for( var i = 0; i < this.refs.length; i++ ) {\n      ref = this.refs[i]\n      link = Object.keys( this.refs[i] ).reduce( function( link, attr ) {\n        if( attr === 'uri' ) return link\n        return link + '; ' + Link.formatAttribute( attr, ref[ attr ] )\n      }, '<' + ref.uri + '>' )\n      refs.push( link )\n    }\n\n    return refs.join( ', ' )\n\n  }\n\n}\n\n/**\n * Determines whether an encoding can be\n * natively handled with a `Buffer`\n * @param {String} value\n * @returns {Boolean}\n */\nLink.isCompatibleEncoding = function( value ) {\n  return COMPATIBLE_ENCODING_PATTERN.test( value )\n}\n\nLink.parse = function( value, offset ) {\n  return new Link().parse( value, offset )\n}\n\nLink.isSingleOccurenceAttr = function( attr ) {\n  return attr === 'rel' || attr === 'type' || attr === 'media' ||\n    attr === 'title' || attr === 'title*'\n}\n\nLink.isTokenAttr = function( attr ) {\n  return attr === 'rel' || attr === 'type' || attr === 'anchor'\n}\n\nLink.escapeQuotes = function( value ) {\n  return value.replace( /\"/g, '\\\\\"' )\n}\n\nLink.expandRelations = function( ref ) {\n  var rels = ref.rel.split( ' ' )\n  return rels.map( function( rel ) {\n    var value = Object.assign( {}, ref )\n    value.rel = rel\n    return value\n  })\n}\n\n/**\n * Parses an extended value and attempts to decode it\n * @internal\n * @param {String} value\n * @return {Object}\n */\nLink.parseExtendedValue = function( value ) {\n  var parts = /([^']+)?(?:'([^']*)')?(.+)/.exec( value )\n  return {\n    language: parts[2].toLowerCase(),\n    encoding: Link.isCompatibleEncoding( parts[1] ) ?\n      null : parts[1].toLowerCase(),\n    value: Link.isCompatibleEncoding( parts[1] ) ?\n      decodeURIComponent( parts[3] ) : parts[3]\n  }\n}\n\n/**\n * Format a given extended attribute and it's value\n * @param {String} attr\n * @param {Object} data\n * @return {String}\n */\nLink.formatExtendedAttribute = function( attr, data ) {\n\n  var encoding = ( data.encoding || 'utf-8' ).toUpperCase()\n  var language = data.language || 'en'\n\n  var encodedValue = ''\n\n  if( Buffer.isBuffer( data.value ) && Link.isCompatibleEncoding( encoding ) ) {\n    encodedValue = data.value.toString( encoding )\n  } else if( Buffer.isBuffer( data.value ) ) {\n    encodedValue = data.value.toString( 'hex' )\n      .replace( /[0-9a-f]{2}/gi, '%$1' )\n  } else {\n    encodedValue = encodeURIComponent( data.value )\n  }\n\n  return attr + '=' + encoding + '\\'' +\n    language + '\\'' + encodedValue\n\n}\n\n/**\n * Format a given attribute and it's value\n * @param {String} attr\n * @param {String|Object} value\n * @return {String}\n */\nLink.formatAttribute = function( attr, value ) {\n\n  if( Array.isArray( value ) ) {\n    return value.map(( item ) => {\n      return Link.formatAttribute( attr, item )\n    }).join( '; ' )\n  }\n\n  if( attr[ attr.length - 1 ] === '*' || typeof value !== 'string' ) {\n    return Link.formatExtendedAttribute( attr, value )\n  }\n\n  if( Link.isTokenAttr( attr ) ) {\n    value = needsQuotes( value ) ?\n      '\"' + Link.escapeQuotes( value ) + '\"' :\n      Link.escapeQuotes( value )\n  } else if( needsQuotes( value ) ) {\n    value = encodeURIComponent( value )\n    // We don't need to escape <SP> <,> <;> within quotes\n    value = value\n      .replace( /%20/g, ' ' )\n      .replace( /%2C/g, ',' )\n      .replace( /%3B/g, ';' )\n\n    value = '\"' + value + '\"'\n  }\n\n  return attr + '=' + value\n\n}\n\nmodule.exports = Link\n","export * from './lib/ContextParser';\nexport * from './lib/ErrorCoded';\nexport * from './lib/FetchDocumentLoader';\nexport * from './lib/IDocumentLoader';\nexport * from './lib/JsonLdContext';\nexport * from './lib/JsonLdContextNormalized';\nexport * from './lib/Util';\n","import 'cross-fetch/polyfill';\nimport {resolve} from \"relative-to-absolute-iri\";\nimport {ERROR_CODES, ErrorCoded} from \"./ErrorCoded\";\nimport {FetchDocumentLoader} from \"./FetchDocumentLoader\";\nimport {IDocumentLoader} from \"./IDocumentLoader\";\nimport {IJsonLdContext, IJsonLdContextNormalizedRaw, IPrefixValue, JsonLdContext} from \"./JsonLdContext\";\nimport {JsonLdContextNormalized} from \"./JsonLdContextNormalized\";\nimport {Util} from \"./Util\";\n\n// tslint:disable-next-line:no-var-requires\nconst canonicalizeJson = require('canonicalize');\n\n/**\n * Parses JSON-LD contexts.\n */\nexport class ContextParser {\n\n  public static readonly DEFAULT_PROCESSING_MODE: number = 1.1;\n\n  private readonly documentLoader: IDocumentLoader;\n  private readonly documentCache: {[url: string]: JsonLdContext};\n  private readonly validateContext: boolean;\n  private readonly expandContentTypeToBase: boolean;\n  private readonly remoteContextsDepthLimit: number;\n  private readonly redirectSchemaOrgHttps: boolean;\n\n  constructor(options?: IContextParserOptions) {\n    options = options || {};\n    this.documentLoader = options.documentLoader || new FetchDocumentLoader();\n    this.documentCache = {};\n    this.validateContext = !options.skipValidation;\n    this.expandContentTypeToBase = !!options.expandContentTypeToBase;\n    this.remoteContextsDepthLimit = options.remoteContextsDepthLimit || 32;\n    this.redirectSchemaOrgHttps = 'redirectSchemaOrgHttps' in options ? !!options.redirectSchemaOrgHttps : true;\n  }\n\n  /**\n   * Validate the given @language value.\n   * An error will be thrown if it is invalid.\n   * @param value An @language value.\n   * @param {boolean} strictRange If the string value should be strictly checked against a regex.\n   * @param {string} errorCode The error code to emit on errors.\n   * @return {boolean} If validation passed.\n   *                   Can only be false if strictRange is false and the string value did not pass the regex.\n   */\n  public static validateLanguage(value: any, strictRange: boolean, errorCode: string): boolean {\n    if (typeof value !== 'string') {\n      throw new ErrorCoded(`The value of an '@language' must be a string, got '${JSON.stringify(value)}'`, errorCode);\n    }\n\n    if (!Util.REGEX_LANGUAGE_TAG.test(value)) {\n      if (strictRange) {\n        throw new ErrorCoded(`The value of an '@language' must be a valid language tag, got '${\n          JSON.stringify(value)}'`, errorCode);\n      } else {\n        return false;\n      }\n    }\n\n    return true;\n  }\n\n  /**\n   * Validate the given @direction value.\n   * An error will be thrown if it is invalid.\n   * @param value An @direction value.\n   * @param {boolean} strictValues If the string value should be strictly checked against a regex.\n   * @return {boolean} If validation passed.\n   *                   Can only be false if strictRange is false and the string value did not pass the regex.\n   */\n  public static validateDirection(value: any, strictValues: boolean) {\n    if (typeof value !== 'string') {\n      throw new ErrorCoded(`The value of an '@direction' must be a string, got '${JSON.stringify(value)}'`,\n        ERROR_CODES.INVALID_BASE_DIRECTION);\n    }\n\n    if (!Util.REGEX_DIRECTION_TAG.test(value)) {\n      if (strictValues) {\n        throw new ErrorCoded(`The value of an '@direction' must be 'ltr' or 'rtl', got '${\n          JSON.stringify(value)}'`, ERROR_CODES.INVALID_BASE_DIRECTION);\n      } else {\n        return false;\n      }\n    }\n\n    return true;\n  }\n\n  /**\n   * Add an @id term for all @reverse terms.\n   * @param {IJsonLdContextNormalizedRaw} context A context.\n   * @return {IJsonLdContextNormalizedRaw} The mutated input context.\n   */\n  public idifyReverseTerms(context: IJsonLdContextNormalizedRaw): IJsonLdContextNormalizedRaw {\n    for (const key of Object.keys(context)) {\n      const value: IPrefixValue = context[key];\n      if (value && typeof value === 'object') {\n        if (value['@reverse'] && !value['@id']) {\n          if (typeof value['@reverse'] !== 'string' || Util.isValidKeyword(value['@reverse'])) {\n            throw new ErrorCoded(`Invalid @reverse value, must be absolute IRI or blank node: '${value['@reverse']}'`,\n              ERROR_CODES.INVALID_IRI_MAPPING);\n          }\n          value['@id'] = <string> value['@reverse'];\n          if (Util.isPotentialKeyword(value['@reverse'])) {\n            delete value['@reverse'];\n          } else {\n            value['@reverse'] = <any> true;\n          }\n        }\n      }\n    }\n\n    return context;\n  }\n\n  /**\n   * Expand all prefixed terms in the given context.\n   * @param {IJsonLdContextNormalizedRaw} context A context.\n   * @param {boolean} expandContentTypeToBase If @type inside the context may be expanded\n   *                                          via @base if @vocab is set to null.\n   */\n  public expandPrefixedTerms(context: JsonLdContextNormalized, expandContentTypeToBase: boolean) {\n    const contextRaw = context.getContextRaw();\n    for (const key of Object.keys(contextRaw)) {\n      // Only expand allowed keys\n      if (Util.EXPAND_KEYS_BLACKLIST.indexOf(key) < 0 && !Util.isReservedInternalKeyword(key)) {\n        // Error if we try to alias a keyword to something else.\n        const keyValue = contextRaw[key];\n        if (Util.isPotentialKeyword(key) && Util.ALIAS_DOMAIN_BLACKLIST.indexOf(key) >= 0) {\n          if (key !== '@type' || typeof contextRaw[key] === 'object'\n            && !(contextRaw[key]['@protected'] || contextRaw[key]['@container'] === '@set')) {\n            throw new ErrorCoded(`Keywords can not be aliased to something else.\nTried mapping ${key} to ${JSON.stringify(keyValue)}`, ERROR_CODES.KEYWORD_REDEFINITION);\n          }\n        }\n\n        // Error if we try to alias to an illegal keyword\n        if (Util.ALIAS_RANGE_BLACKLIST.indexOf(Util.getContextValueId(keyValue)) >= 0) {\n          throw new ErrorCoded(`Aliasing to certain keywords is not allowed.\nTried mapping ${key} to ${JSON.stringify(keyValue)}`, ERROR_CODES.INVALID_KEYWORD_ALIAS);\n        }\n\n        // Error if this term was marked as prefix as well\n        if (keyValue && Util.isPotentialKeyword(Util.getContextValueId(keyValue))\n          && keyValue['@prefix'] === true) {\n          throw new ErrorCoded(`Tried to use keyword aliases as prefix: '${key}': '${JSON.stringify(keyValue)}'`,\n            ERROR_CODES.INVALID_TERM_DEFINITION);\n        }\n\n        // Loop because prefixes might be nested\n        while (Util.isPrefixValue(contextRaw[key])) {\n          const value: IPrefixValue = contextRaw[key];\n          let changed: boolean = false;\n          if (typeof value === 'string') {\n            contextRaw[key] = context.expandTerm(value, true);\n            changed = changed || value !== contextRaw[key];\n          } else {\n            const id = value['@id'];\n            const type = value['@type'];\n            // If @id is missing, don't allow @id to be added if @prefix: true and key not being a valid IRI.\n            const canAddIdEntry = !('@prefix' in value) || Util.isValidIri(key);\n            if ('@id' in value) {\n              // Use @id value for expansion\n              if (id !== undefined && id !== null && typeof id === 'string') {\n                contextRaw[key]['@id'] = context.expandTerm(id, true);\n                changed = changed || id !== contextRaw[key]['@id'];\n              }\n            } else if (!Util.isPotentialKeyword(key) && canAddIdEntry) {\n              // Add an explicit @id value based on the expanded key value\n              const newId = context.expandTerm(key, true);\n              if (newId !== key) {\n                // Don't set @id if expansion failed\n                contextRaw[key]['@id'] = newId;\n                changed = true;\n              }\n            }\n            if (type && typeof type === 'string' && type !== '@vocab'\n              && (!value['@container'] || !(<any> value['@container'])['@type'])\n              && canAddIdEntry) {\n              // First check @vocab, then fallback to @base\n              contextRaw[key]['@type'] = context.expandTerm(type, true);\n              if (expandContentTypeToBase && type === contextRaw[key]['@type']) {\n                contextRaw[key]['@type'] = context.expandTerm(type, false);\n              }\n              changed = changed || type !== contextRaw[key]['@type'];\n            }\n          }\n          if (!changed) {\n            break;\n          }\n        }\n      }\n    }\n  }\n\n  /**\n   * Normalize the @language entries in the given context to lowercase.\n   * @param {IJsonLdContextNormalizedRaw} context A context.\n   * @param {IParseOptions} parseOptions The parsing options.\n   */\n  public normalize(context: IJsonLdContextNormalizedRaw,\n                   { processingMode, normalizeLanguageTags }: IParseOptions) {\n    // Lowercase language keys in 1.0\n    if (normalizeLanguageTags || processingMode === 1.0) {\n      for (const key of Object.keys(context)) {\n        if (key === '@language' && typeof context[key] === 'string') {\n          context[key] = (<string> context[key]).toLowerCase();\n        } else {\n          const value = context[key];\n          if (value && typeof value === 'object') {\n            if (typeof value['@language'] === 'string') {\n              value['@language'] = value['@language'].toLowerCase();\n            }\n          }\n        }\n      }\n    }\n  }\n\n  /**\n   * Convert all @container strings and array values to hash-based values.\n   * @param {IJsonLdContextNormalizedRaw} context A context.\n   */\n  public containersToHash(context: IJsonLdContextNormalizedRaw) {\n    for (const key of Object.keys(context)) {\n      const value = context[key];\n      if (value && typeof value === 'object') {\n        if (typeof value['@container'] === 'string') {\n          value['@container'] = { [value['@container']]: true };\n        } else if (Array.isArray(value['@container'])) {\n          const newValue: {[key: string]: boolean} = {};\n          for (const containerValue of value['@container']) {\n            newValue[containerValue] = true;\n          }\n          value['@container'] = newValue;\n        }\n      }\n    }\n  }\n\n  /**\n   * Normalize and apply context-levevl @protected terms onto each term separately.\n   * @param {IJsonLdContextNormalizedRaw} context A context.\n   * @param {number} processingMode The processing mode.\n   */\n  public applyScopedProtected(context: IJsonLdContextNormalizedRaw, { processingMode }: IParseOptions) {\n    if (processingMode && processingMode >= 1.1) {\n      if (context['@protected']) {\n        for (const key of Object.keys(context)) {\n          if (Util.isReservedInternalKeyword(key)) {\n            continue;\n          }\n\n          if (!Util.isPotentialKeyword(key) && !Util.isTermProtected(context, key)) {\n            const value = context[key];\n            if (value && typeof value === 'object') {\n              if (!('@protected' in context[key])) {\n                // Mark terms with object values as protected if they don't have an @protected: false annotation\n                context[key]['@protected'] = true;\n              }\n            } else {\n              // Convert string-based term values to object-based values with @protected: true\n              context[key] = {\n                '@id': value,\n                '@protected': true,\n              };\n            }\n          }\n        }\n        delete context['@protected'];\n      }\n    }\n  }\n\n  /**\n   * Check if the given context inheritance does not contain any overrides of protected terms.\n   * @param {IJsonLdContextNormalizedRaw} contextBefore The context that may contain some protected terms.\n   * @param {IJsonLdContextNormalizedRaw} contextAfter A new context that is being applied on the first one.\n   * @param {IExpandOptions} expandOptions Options that are needed for any expansions during this validation.\n   */\n  public validateKeywordRedefinitions(contextBefore: IJsonLdContextNormalizedRaw,\n                                      contextAfter: IJsonLdContextNormalizedRaw,\n                                      expandOptions: IExpandOptions) {\n    for (const key of Object.keys(contextAfter)) {\n      if (Util.isTermProtected(contextBefore, key)) {\n        // The entry in the context before will always be in object-mode\n        // If the new entry is in string-mode, convert it to object-mode\n        // before checking if it is identical.\n        if (typeof contextAfter[key] === 'string') {\n          const isPrefix = Util.isSimpleTermDefinitionPrefix(contextAfter[key], expandOptions);\n          contextAfter[key] = { '@id': contextAfter[key] };\n\n          // If the simple term def was a prefix, explicitly mark the term as a prefix in the expanded term definition,\n          // because otherwise we loose this information due to JSON-LD interpreting prefixes differently\n          // in simple vs expanded term definitions.\n          if (isPrefix) {\n            contextAfter[key]['@prefix'] = true;\n            contextBefore[key]['@prefix'] = true; // Also on before, to make sure the next step still considers them ==\n          }\n        }\n\n        // Convert term values to strings for each comparison\n        const valueBefore = canonicalizeJson(contextBefore[key]);\n        // We modify this deliberately,\n        // as we need it for the value comparison (they must be identical modulo '@protected')),\n        // and for the fact that this new value will override the first one.\n        contextAfter[key]['@protected'] = true;\n        const valueAfter = canonicalizeJson(contextAfter[key]);\n\n        // Error if they are not identical\n        if (valueBefore !== valueAfter) {\n          throw new ErrorCoded(`Attempted to override the protected keyword ${key} from ${\n            JSON.stringify(Util.getContextValueId(contextBefore[key]))} to ${\n            JSON.stringify(Util.getContextValueId(contextAfter[key]))}`,\n            ERROR_CODES.PROTECTED_TERM_REDEFINITION);\n        }\n      }\n    }\n  }\n\n  /**\n   * Validate the entries of the given context.\n   * @param {IJsonLdContextNormalizedRaw} context A context.\n   * @param {IParseOptions} options The parse options.\n   */\n  public validate(context: IJsonLdContextNormalizedRaw, { processingMode }: IParseOptions) {\n    for (const key of Object.keys(context)) {\n      // Ignore reserved internal keywords.\n      if (Util.isReservedInternalKeyword(key)) {\n        continue;\n      }\n\n      // Do not allow empty term\n      if (key === '') {\n        throw new ErrorCoded(`The empty term is not allowed, got: '${key}': '${JSON.stringify(context[key])}'`,\n          ERROR_CODES.INVALID_TERM_DEFINITION);\n      }\n\n      const value = context[key];\n      const valueType = typeof value;\n      // First check if the key is a keyword\n      if (Util.isPotentialKeyword(key)) {\n        switch (key.substr(1)) {\n        case 'vocab':\n          if (value !== null && valueType !== 'string') {\n            throw new ErrorCoded(`Found an invalid @vocab IRI: ${value}`, ERROR_CODES.INVALID_VOCAB_MAPPING);\n          }\n          break;\n        case 'base':\n          if (value !== null && valueType !== 'string') {\n            throw new ErrorCoded(`Found an invalid @base IRI: ${context[key]}`, ERROR_CODES.INVALID_BASE_IRI);\n          }\n          break;\n        case 'language':\n          if (value !== null) {\n            ContextParser.validateLanguage(value, true, ERROR_CODES.INVALID_DEFAULT_LANGUAGE);\n          }\n          break;\n        case 'version':\n          if (value !== null && valueType !== 'number') {\n            throw new ErrorCoded(`Found an invalid @version number: ${value}`, ERROR_CODES.INVALID_VERSION_VALUE);\n          }\n          break;\n        case 'direction':\n          if (value !== null) {\n            ContextParser.validateDirection(value, true);\n          }\n          break;\n        case 'propagate':\n          if (processingMode === 1.0) {\n            throw new ErrorCoded(`Found an illegal @propagate keyword: ${value}`, ERROR_CODES.INVALID_CONTEXT_ENTRY);\n          }\n          if (value !== null && valueType !== 'boolean') {\n            throw new ErrorCoded(`Found an invalid @propagate value: ${value}`, ERROR_CODES.INVALID_PROPAGATE_VALUE);\n          }\n          break;\n        }\n\n        // Don't allow keywords to be overridden\n        if (Util.isValidKeyword(key) && Util.isValidKeyword(Util.getContextValueId(value))) {\n          throw new ErrorCoded(`Illegal keyword alias in term value, found: '${key}': '${Util\n              .getContextValueId(value)}'`,\n            ERROR_CODES.KEYWORD_REDEFINITION);\n        }\n\n        continue;\n      }\n\n      // Otherwise, consider the key a term\n      if (value !== null) {\n        switch (valueType) {\n        case 'string':\n          if (Util.getPrefix(value, context) === key) {\n            throw new ErrorCoded(`Detected cyclical IRI mapping in context entry: '${key}': '${JSON\n              .stringify(value)}'`, ERROR_CODES.CYCLIC_IRI_MAPPING);\n          }\n          if (Util.isValidIriWeak(key)) {\n            if (value === '@type') {\n              throw new ErrorCoded(`IRIs can not be mapped to @type, found: '${key}': '${value}'`,\n                ERROR_CODES.INVALID_IRI_MAPPING);\n            } else if (Util.isValidIri(value) && value !== new JsonLdContextNormalized(context).expandTerm(key)) {\n              throw new ErrorCoded(\n                `IRIs can not be mapped to other IRIs, found: '${key}': '${value}'`,\n                ERROR_CODES.INVALID_IRI_MAPPING);\n            }\n          }\n          break;\n        case 'object':\n          if (!Util.isCompactIri(key) && !('@id' in value)\n            && (value['@type'] === '@id' ? !context['@base'] : !context['@vocab'])) {\n            throw new ErrorCoded(`Missing @id in context entry: '${key}': '${JSON.stringify(value)}'`,\n              ERROR_CODES.INVALID_IRI_MAPPING);\n          }\n\n          for (const objectKey of Object.keys(value)) {\n            const objectValue = value[objectKey];\n            if (!objectValue) {\n              continue;\n            }\n\n            switch (objectKey) {\n            case '@id':\n              if (Util.isValidKeyword(objectValue)\n                && objectValue !== '@type' && objectValue !== '@id' && objectValue !== '@graph') {\n                throw new ErrorCoded(`Illegal keyword alias in term value, found: '${key}': '${JSON.stringify(value)}'`,\n                  ERROR_CODES.INVALID_IRI_MAPPING);\n              }\n              if (Util.isValidIriWeak(key)) {\n                if (objectValue === '@type') {\n                  throw new ErrorCoded(`IRIs can not be mapped to @type, found: '${key}': '${JSON.stringify(value)}'`,\n                    ERROR_CODES.INVALID_IRI_MAPPING);\n                } else if (Util.isValidIri(objectValue)\n                  && objectValue !== new JsonLdContextNormalized(context).expandTerm(key)) {\n                  throw new ErrorCoded(\n                    `IRIs can not be mapped to other IRIs, found: '${key}': '${JSON.stringify(value)}'`,\n                    ERROR_CODES.INVALID_IRI_MAPPING);\n                }\n              }\n              if (typeof objectValue !== 'string') {\n                throw new ErrorCoded(`Detected non-string @id in context entry: '${key}': '${JSON.stringify(value)}'`,\n                  ERROR_CODES.INVALID_IRI_MAPPING);\n              }\n\n              if (Util.getPrefix(objectValue, context) === key) {\n                throw new ErrorCoded(`Detected cyclical IRI mapping in context entry: '${key}': '${JSON\n                  .stringify(value)}'`, ERROR_CODES.CYCLIC_IRI_MAPPING);\n              }\n\n              break;\n            case '@type':\n              if (value['@container'] === '@type' && objectValue !== '@id' && objectValue !== '@vocab') {\n                throw new ErrorCoded(`@container: @type only allows @type: @id or @vocab, but got: '${\n                    key}': '${objectValue}'`,\n                  ERROR_CODES.INVALID_TYPE_MAPPING);\n              }\n              if (typeof objectValue !== 'string') {\n                throw new ErrorCoded(`The value of an '@type' must be a string, got '${JSON.stringify(valueType)}'`,\n                  ERROR_CODES.INVALID_TYPE_MAPPING);\n              }\n              if (objectValue !== '@id' && objectValue !== '@vocab'\n                && (processingMode === 1.0 || objectValue !== '@json')\n                && (processingMode === 1.0 || objectValue !== '@none')\n                && (objectValue[0] === '_' || !Util.isValidIri(objectValue))) {\n                throw new ErrorCoded(`A context @type must be an absolute IRI, found: '${key}': '${objectValue}'`,\n                  ERROR_CODES.INVALID_TYPE_MAPPING);\n              }\n              break;\n            case '@reverse':\n              if (typeof objectValue === 'string' && value['@id'] && value['@id'] !== objectValue) {\n                throw new ErrorCoded(`Found non-matching @id and @reverse term values in '${key}':\\\n'${objectValue}' and '${value['@id']}'`, ERROR_CODES.INVALID_REVERSE_PROPERTY);\n              }\n              if ('@nest' in value) {\n                throw new ErrorCoded(`@nest is not allowed in the reverse property '${key}'`,\n                  ERROR_CODES.INVALID_REVERSE_PROPERTY);\n              }\n              break;\n            case '@container':\n              if (processingMode === 1.0) {\n                if (Object.keys(objectValue).length > 1\n                  || Util.CONTAINERS_1_0.indexOf(Object.keys(objectValue)[0]) < 0) {\n                  throw new ErrorCoded(`Invalid term @container for '${key}' ('${Object.keys(objectValue)}') in 1.0, \\\nmust be only one of ${Util.CONTAINERS_1_0.join(', ')}`, ERROR_CODES.INVALID_CONTAINER_MAPPING);\n                }\n              }\n              for (const containerValue of Object.keys(objectValue)) {\n                if (containerValue === '@list' && value['@reverse']) {\n                  throw new ErrorCoded(`Term value can not be @container: @list and @reverse at the same time on '${\n                    key}'`, ERROR_CODES.INVALID_REVERSE_PROPERTY);\n                }\n                if (Util.CONTAINERS.indexOf(containerValue) < 0) {\n                  throw new ErrorCoded(`Invalid term @container for '${key}' ('${containerValue}'), \\\nmust be one of ${Util.CONTAINERS.join(', ')}`, ERROR_CODES.INVALID_CONTAINER_MAPPING);\n                }\n              }\n              break;\n            case '@language':\n              ContextParser.validateLanguage(objectValue, true, ERROR_CODES.INVALID_LANGUAGE_MAPPING);\n              break;\n            case '@direction':\n              ContextParser.validateDirection(objectValue, true);\n              break;\n            case '@prefix':\n              if (objectValue !== null && typeof objectValue !== 'boolean') {\n                throw new ErrorCoded(`Found an invalid term @prefix boolean in: '${key}': '${JSON.stringify(value)}'`,\n                  ERROR_CODES.INVALID_PREFIX_VALUE);\n              }\n              if (!('@id' in value) && !Util.isValidIri(key)) {\n                throw new ErrorCoded(`Invalid @prefix definition for '${key}' ('${JSON.stringify(value)}'`,\n                  ERROR_CODES.INVALID_TERM_DEFINITION);\n              }\n              break;\n            case '@index':\n              if (processingMode === 1.0 || !value['@container'] || !value['@container']['@index']) {\n                throw new ErrorCoded(`Attempt to add illegal key to value object: '${\n                  key}': '${JSON.stringify(value)}'`, ERROR_CODES.INVALID_TERM_DEFINITION);\n              }\n              break;\n            case '@nest':\n              if (Util.isPotentialKeyword(objectValue) && objectValue !== '@nest') {\n                throw new ErrorCoded(`Found an invalid term @nest value in: '${key}': '${JSON.stringify(value)}'`,\n                  ERROR_CODES.INVALID_NEST_VALUE);\n              }\n            }\n          }\n          break;\n        default:\n          throw new ErrorCoded(`Found an invalid term value: '${key}': '${value}'`,\n            ERROR_CODES.INVALID_TERM_DEFINITION);\n        }\n      }\n    }\n  }\n\n  /**\n   * Apply the @base context entry to the given context under certain circumstances.\n   * @param context A context.\n   * @param options Parsing options.\n   * @param inheritFromParent If the @base value from the parent context can be inherited.\n   * @return The given context.\n   */\n  public applyBaseEntry(context: IJsonLdContextNormalizedRaw, options: IParseOptions,\n                        inheritFromParent: boolean): IJsonLdContextNormalizedRaw {\n    // In some special cases, this can be a string, so ignore those.\n    if (typeof context === 'string') {\n      return context;\n    }\n\n    // Give priority to @base in the parent context\n    if (inheritFromParent && !('@base' in context) && options.parentContext\n      && typeof options.parentContext === 'object' && '@base' in options.parentContext) {\n      context['@base'] = options.parentContext['@base'];\n      if (options.parentContext['@__baseDocument']) {\n        context['@__baseDocument'] = true;\n      }\n    }\n\n    // Override the base IRI if provided.\n    if (options.baseIRI && !options.external) {\n      if (!('@base' in context)) {\n        // The context base is the document base\n        context['@base'] = options.baseIRI;\n        context['@__baseDocument'] = true;\n      } else if (context['@base'] !== null && typeof context['@base'] === 'string'\n        && !Util.isValidIri(<string> context['@base'])) {\n        // The context base is relative to the document base\n        context['@base'] = resolve(<string> context['@base'],\n          options.parentContext && options.parentContext['@base'] || options.baseIRI);\n      }\n    }\n    return context;\n  }\n\n  /**\n   * Resolve relative context IRIs, or return full IRIs as-is.\n   * @param {string} contextIri A context IRI.\n   * @param {string} baseIRI A base IRI.\n   * @return {string} The normalized context IRI.\n   */\n  public normalizeContextIri(contextIri: string, baseIRI?: string) {\n    if (!Util.isValidIri(contextIri)) {\n      try {\n        contextIri = resolve(contextIri, baseIRI);\n      } catch {\n        throw new Error(`Invalid context IRI: ${contextIri}`);\n      }\n    }\n\n    // TODO: Temporary workaround for fixing schema.org CORS issues (https://github.com/schemaorg/schemaorg/issues/2578#issuecomment-652324465)\n    if (this.redirectSchemaOrgHttps && contextIri.startsWith('http://schema.org')) {\n      contextIri = 'https://schema.org/';\n    }\n\n    return contextIri;\n  }\n\n  /**\n   * Parse scoped contexts in the given context.\n   * @param {IJsonLdContextNormalizedRaw} context A context.\n   * @param {IParseOptions} options Parsing options.\n   * @return {IJsonLdContextNormalizedRaw} The mutated input context.\n   */\n  public async parseInnerContexts(context: IJsonLdContextNormalizedRaw, options: IParseOptions)\n    : Promise<IJsonLdContextNormalizedRaw> {\n    for (const key of Object.keys(context)) {\n      const value = context[key];\n      if (value && typeof value === 'object') {\n        if ('@context' in value && value['@context'] !== null && !options.ignoreScopedContexts) {\n          // Simulate a processing based on the parent context to check if there are any (potential errors).\n          // Honestly, I find it a bit weird to do this here, as the context may be unused,\n          // and the final effective context may differ based on any other embedded/scoped contexts.\n          // But hey, it's part of the spec, so we have no choice...\n          // https://w3c.github.io/json-ld-api/#h-note-10\n          if (this.validateContext) {\n            try {\n              const parentContext = {...context};\n              parentContext[key] = {...parentContext[key]};\n              delete parentContext[key]['@context'];\n              await this.parse(value['@context'],\n                { ...options, external: false, parentContext, ignoreProtection: true, ignoreRemoteScopedContexts: true, ignoreScopedContexts: true });\n            } catch (e) {\n              throw new ErrorCoded(e.message, ERROR_CODES.INVALID_SCOPED_CONTEXT);\n            }\n          }\n\n          value['@context'] = (await this.parse(value['@context'],\n            { ...options, external: false, minimalProcessing: true, ignoreRemoteScopedContexts: true, parentContext: context }))\n            .getContextRaw();\n        }\n      }\n    }\n    return context;\n  }\n\n  /**\n   * Parse a JSON-LD context in any form.\n   * @param {JsonLdContext} context A context, URL to a context, or an array of contexts/URLs.\n   * @param {IParseOptions} options Optional parsing options.\n   * @return {Promise<JsonLdContextNormalized>} A promise resolving to the context.\n   */\n  public async parse(context: JsonLdContext,\n                     options: IParseOptions = {}): Promise<JsonLdContextNormalized> {\n    const {\n      baseIRI,\n      parentContext: parentContextInitial,\n      external,\n      processingMode = ContextParser.DEFAULT_PROCESSING_MODE,\n      normalizeLanguageTags,\n      ignoreProtection,\n      minimalProcessing,\n    } = options;\n    let parentContext = parentContextInitial;\n    const remoteContexts = options.remoteContexts || {};\n\n    // Avoid remote context overflows\n    if (Object.keys(remoteContexts).length >= this.remoteContextsDepthLimit) {\n      throw new ErrorCoded('Detected an overflow in remote context inclusions: ' + Object.keys(remoteContexts),\n        ERROR_CODES.CONTEXT_OVERFLOW);\n    }\n\n    if (context === null || context === undefined) {\n      // Don't allow context nullification and there are protected terms\n      if (!ignoreProtection && parentContext && Util.hasProtectedTerms(parentContext)) {\n        throw new ErrorCoded('Illegal context nullification when terms are protected',\n          ERROR_CODES.INVALID_CONTEXT_NULLIFICATION);\n      }\n\n      // Context that are explicitly set to null are empty.\n      return new JsonLdContextNormalized(this.applyBaseEntry({}, options, false));\n    } else if (typeof context === 'string') {\n      const contextIri = this.normalizeContextIri(context, baseIRI);\n      const overriddenLoad = this.getOverriddenLoad(contextIri, options);\n      if (overriddenLoad) {\n        return new JsonLdContextNormalized(overriddenLoad);\n      }\n      const parsedStringContext = await this.parse(await this.load(contextIri),\n        {\n          ...options,\n          baseIRI: contextIri,\n          external: true,\n          remoteContexts: { ...remoteContexts, [contextIri]: true },\n        });\n      this.applyBaseEntry(parsedStringContext.getContextRaw(), options, true);\n      return parsedStringContext;\n    } else if (Array.isArray(context)) {\n      // As a performance consideration, first load all external contexts in parallel.\n      const contextIris: string[] = [];\n      const contexts = await Promise.all(context.map((subContext, i) => {\n        if (typeof subContext === 'string') {\n          const contextIri = this.normalizeContextIri(subContext, baseIRI);\n          contextIris[i] = contextIri;\n          const overriddenLoad = this.getOverriddenLoad(contextIri, options);\n          if (overriddenLoad) {\n            return overriddenLoad;\n          }\n          return this.load(contextIri);\n        } else {\n          return subContext;\n        }\n      }));\n\n      // Don't apply inheritance logic on minimal processing\n      if (minimalProcessing) {\n        return new JsonLdContextNormalized(contexts);\n      }\n\n      const reducedContexts = await contexts.reduce((accContextPromise, contextEntry, i) => accContextPromise\n          .then((accContext) => this.parse(contextEntry, {\n            ...options,\n            baseIRI: contextIris[i] || options.baseIRI,\n            external: !!contextIris[i] || options.external,\n            parentContext: accContext.getContextRaw(),\n            remoteContexts: contextIris[i] ? { ...remoteContexts, [contextIris[i]]: true } : remoteContexts,\n          })),\n        Promise.resolve(new JsonLdContextNormalized(parentContext || {})));\n\n      // Override the base IRI if provided.\n      this.applyBaseEntry(reducedContexts.getContextRaw(), options, true);\n\n      return reducedContexts;\n    } else if (typeof context === 'object') {\n      if ('@context' in context) {\n        return await this.parse(context['@context'], options);\n      }\n\n      // Make a deep clone of the given context, to avoid modifying it.\n      context = <IJsonLdContextNormalizedRaw> JSON.parse(JSON.stringify(context)); // No better way in JS at the moment.\n      if (parentContext && !minimalProcessing) {\n        parentContext = <IJsonLdContextNormalizedRaw> JSON.parse(JSON.stringify(parentContext));\n      }\n\n      // We have an actual context object.\n      let newContext: IJsonLdContextNormalizedRaw = {};\n\n      // According to the JSON-LD spec, @base must be ignored from external contexts.\n      if (external) {\n        delete context['@base'];\n      }\n\n      // Override the base IRI if provided.\n      this.applyBaseEntry(context, options, true);\n\n      // Hashify container entries\n      // Do this before protected term validation as that influences term format\n      this.containersToHash(context);\n\n      // Don't perform any other modifications if only minimal processing is needed.\n      if (minimalProcessing) {\n        return new JsonLdContextNormalized(context);\n      }\n\n      // In JSON-LD 1.1, load @import'ed context prior to processing.\n      let importContext = {};\n      if ('@import' in context) {\n        if (processingMode >= 1.1) {\n          // Only accept string values\n          if (typeof context['@import'] !== 'string') {\n            throw new ErrorCoded('An @import value must be a string, but got ' + typeof context['@import'],\n              ERROR_CODES.INVALID_IMPORT_VALUE);\n          }\n\n          // Load context\n          importContext = await this.loadImportContext(this.normalizeContextIri(context['@import'], baseIRI));\n          delete context['@import'];\n        } else {\n          throw new ErrorCoded('Context importing is not supported in JSON-LD 1.0',\n            ERROR_CODES.INVALID_CONTEXT_ENTRY);\n        }\n      }\n\n      // Merge different parts of the final context in order\n      newContext = {\n        ...newContext,\n        ...(typeof parentContext === 'object' ? parentContext : {}),\n        ...importContext,\n        ...context,\n      };\n      const newContextWrapped = new JsonLdContextNormalized(newContext);\n\n      // Parse inner contexts with minimal processing\n      await this.parseInnerContexts(newContext, options);\n\n      // In JSON-LD 1.1, @vocab can be relative to @vocab in the parent context.\n      if ((newContext && newContext['@version'] || ContextParser.DEFAULT_PROCESSING_MODE) >= 1.1\n        && ((context['@vocab'] && typeof context['@vocab'] === 'string') || context['@vocab'] === '')\n        && context['@vocab'].indexOf(':') < 0 && parentContext && '@vocab' in parentContext) {\n        newContext['@vocab'] = parentContext['@vocab'] + context['@vocab'];\n      }\n\n      // Handle terms (before protection checks)\n      this.idifyReverseTerms(newContext);\n      this.expandPrefixedTerms(newContextWrapped, this.expandContentTypeToBase);\n\n      // In JSON-LD 1.1, check if we are not redefining any protected keywords\n      if (!ignoreProtection && parentContext && processingMode >= 1.1) {\n        this.validateKeywordRedefinitions(parentContext, newContext, defaultExpandOptions);\n      }\n\n      this.normalize(newContext, { processingMode, normalizeLanguageTags });\n      this.applyScopedProtected(newContext, { processingMode });\n      if (this.validateContext) {\n        this.validate(newContext, { processingMode });\n      }\n\n      return newContextWrapped;\n    } else {\n      throw new ErrorCoded(`Tried parsing a context that is not a string, array or object, but got ${context}`,\n        ERROR_CODES.INVALID_LOCAL_CONTEXT);\n    }\n  }\n\n  /**\n   * Fetch the given URL as a raw JSON-LD context.\n   * @param url An URL.\n   * @return A promise resolving to a raw JSON-LD context.\n   */\n  public async load(url: string): Promise<JsonLdContext> {\n    // First try to retrieve the context from cache\n    const cached = this.documentCache[url];\n    if (cached) {\n      return typeof cached === 'string' ? cached : Array.isArray(cached) ? cached.slice() : {... cached};\n    }\n\n    // If not in cache, load it\n    let document: IJsonLdContext;\n    try {\n      document = await this.documentLoader.load(url);\n    } catch (e) {\n      throw new ErrorCoded(`Failed to load remote context ${url}: ${e.message}`,\n        ERROR_CODES.LOADING_REMOTE_CONTEXT_FAILED);\n    }\n\n    // Validate the context\n    if (!('@context' in document)) {\n      throw new ErrorCoded(`Missing @context in remote context at ${url}`,\n        ERROR_CODES.INVALID_REMOTE_CONTEXT);\n    }\n\n    return this.documentCache[url] = document['@context'];\n  }\n\n  /**\n   * Override the given context that may be loaded.\n   *\n   * This will check whether or not the url is recursively being loaded.\n   * @param url An URL.\n   * @param options Parsing options.\n   * @return An overridden context, or null.\n   *         Optionally an error can be thrown if a cyclic context is detected.\n   */\n  public getOverriddenLoad(url: string, options: IParseOptions): IJsonLdContextNormalizedRaw | null {\n    if (url in (options.remoteContexts || {})) {\n      if (options.ignoreRemoteScopedContexts) {\n        return <IJsonLdContextNormalizedRaw> <any> url;\n      } else {\n        throw new ErrorCoded('Detected a cyclic context inclusion of ' + url,\n          ERROR_CODES.RECURSIVE_CONTEXT_INCLUSION);\n      }\n    }\n    return null;\n  }\n\n  /**\n   * Load an @import'ed context.\n   * @param importContextIri The full URI of an @import value.\n   */\n  public async loadImportContext(importContextIri: string): Promise<IJsonLdContextNormalizedRaw> {\n    // Load the context\n    const importContext = await this.load(importContextIri);\n\n    // Require the context to be a non-array object\n    if (typeof importContext !== 'object' || Array.isArray(importContext)) {\n      throw new ErrorCoded('An imported context must be a single object: ' + importContextIri,\n        ERROR_CODES.INVALID_REMOTE_CONTEXT);\n    }\n\n    // Error if the context contains another @import\n    if ('@import' in importContext) {\n      throw new ErrorCoded('An imported context can not import another context: ' + importContextIri,\n        ERROR_CODES.INVALID_CONTEXT_ENTRY);\n    }\n\n    // Containers have to be converted into hash values the same way as for the importing context\n    // Otherwise context validation will fail for container values\n    this.containersToHash(importContext);\n    return importContext;\n  }\n\n}\n\nexport interface IContextParserOptions {\n  /**\n   * An optional loader that should be used for fetching external JSON-LD contexts.\n   */\n  documentLoader?: IDocumentLoader;\n  /**\n   * By default, JSON-LD contexts will be validated.\n   * This can be disabled by setting this option to true.\n   * This will achieve slightly better performance for large contexts,\n   * and may be useful if contexts are known to be valid.\n   */\n  skipValidation?: boolean;\n  /**\n   * If @type inside the context may be expanded via @base is @vocab is set to null.\n   */\n  expandContentTypeToBase?: boolean;\n  /**\n   * The maximum number of remote contexts that can be fetched recursively.\n   *\n   * Defaults to 32.\n   */\n  remoteContextsDepthLimit?: number;\n  /**\n   * If http-based schema.org contexts should internally be redirected to https.\n   * WARNING: this option is a temporary workaround for https://github.com/schemaorg/schemaorg/issues/2578#issuecomment-652324465\n   * and will be removed once that issue is fixed.\n   * Defaults to true.\n   */\n  redirectSchemaOrgHttps?: boolean;\n}\n\nexport interface IParseOptions {\n  /**\n   * An optional fallback base IRI to set.\n   */\n  baseIRI?: string;\n  /**\n   * The parent context.\n   */\n  parentContext?: IJsonLdContextNormalizedRaw;\n  /**\n   * If the parsing context is an external context.\n   */\n  external?: boolean;\n  /**\n   * The default JSON-LD version that the context should be parsed with.\n   */\n  processingMode?: number;\n  /**\n   * If language tags should be normalized to lowercase.\n   * This is always true for JSON-LD 1.0,\n   * but false by default for all following versions.\n   */\n  normalizeLanguageTags?: boolean;\n  /**\n   * If checks for validating term protection should be skipped.\n   */\n  ignoreProtection?: boolean;\n  /**\n   * If the context should only be parsed and validated,\n   * without performing normalizations and other modifications.\n   *\n   * If true, this *will* dereference external contexts.\n   *\n   * This option is used internally when handling type-scoped and property-scoped contexts.\n   */\n  minimalProcessing?: boolean;\n  /**\n   * If true, a remote context that will be looked up,\n   * and is already contained in `remoteContexts`,\n   * will not emit an error but will produce an empty context.\n   */\n  ignoreRemoteScopedContexts?: boolean;\n  /**\n   * A hash containing all remote contexts that have been looked up before.\n   *\n   * This is used to avoid stack overflows on cyclic context references.\n   */\n  remoteContexts?: {[url: string]: boolean};\n  /**\n   * If further processing of scoped contexts should be skipped.\n   *\n   * This is done to avoid combinatorial explosions when handling a scoped context if there are many scoped contexts.\n   */\n  ignoreScopedContexts?: boolean;\n}\n\nexport interface IExpandOptions {\n  /**\n   * If compact IRI prefixes can end with any kind of character in simple term definitions,\n   * instead of only the default gen-delim characters (:,/,?,#,[,],@).\n   */\n  allowPrefixNonGenDelims: boolean;\n  /**\n   * If compact IRI prefixes ending with a non-gen-delim character\n   * can be forced as a prefix using @prefix: true.\n   */\n  allowPrefixForcing: boolean;\n  /**\n   * If @vocab values are allowed contain IRIs relative to @base.\n   */\n  allowVocabRelativeToBase: boolean;\n}\nexport const defaultExpandOptions: IExpandOptions = {\n  allowPrefixForcing: true,\n  allowPrefixNonGenDelims: false,\n  allowVocabRelativeToBase: true,\n};\n","/**\n * An error that has a certain error code.\n *\n * The error code can be any string.\n * All standardized error codes are listed in {@link ERROR_CODES}.\n */\nexport class ErrorCoded extends Error {\n\n  /**\n   * An error code using which the type of error can be identified.\n   */\n  public readonly code: string;\n\n  /* istanbul ignore next */\n  constructor(message: string, code: string) {\n    super(message);\n    this.code = code;\n  }\n\n}\n\n/**\n * All standardized JSON-LD error codes.\n * @see https://w3c.github.io/json-ld-api/#dom-jsonlderrorcode\n */\n// tslint:disable:object-literal-sort-keys\nexport enum ERROR_CODES {\n  COLLIDING_KEYWORDS = 'colliding keywords',\n  CONFLICTING_INDEXES = 'conflicting indexes',\n  CYCLIC_IRI_MAPPING = 'cyclic IRI mapping',\n  INVALID_ID_VALUE = 'invalid @id value',\n  INVALID_INDEX_VALUE = 'invalid @index value',\n  INVALID_NEST_VALUE = 'invalid @nest value',\n  INVALID_PREFIX_VALUE = 'invalid @prefix value',\n  INVALID_PROPAGATE_VALUE = 'invalid @propagate value',\n  INVALID_REVERSE_VALUE = 'invalid @reverse value',\n  INVALID_IMPORT_VALUE = 'invalid @import value',\n  INVALID_VERSION_VALUE = 'invalid @version value',\n  INVALID_BASE_IRI = 'invalid base IRI',\n  INVALID_CONTAINER_MAPPING = 'invalid container mapping',\n  INVALID_CONTEXT_ENTRY = 'invalid context entry',\n  INVALID_CONTEXT_NULLIFICATION = 'invalid context nullification',\n  INVALID_DEFAULT_LANGUAGE = 'invalid default language',\n  INVALID_INCLUDED_VALUE = 'invalid @included value',\n  INVALID_IRI_MAPPING = 'invalid IRI mapping',\n  INVALID_JSON_LITERAL = 'invalid JSON literal',\n  INVALID_KEYWORD_ALIAS = 'invalid keyword alias',\n  INVALID_LANGUAGE_MAP_VALUE = 'invalid language map value',\n  INVALID_LANGUAGE_MAPPING = 'invalid language mapping',\n  INVALID_LANGUAGE_TAGGED_STRING = 'invalid language-tagged string',\n  INVALID_LANGUAGE_TAGGED_VALUE = 'invalid language-tagged value',\n  INVALID_LOCAL_CONTEXT = 'invalid local context',\n  INVALID_REMOTE_CONTEXT = 'invalid remote context',\n  INVALID_REVERSE_PROPERTY = 'invalid reverse property',\n  INVALID_REVERSE_PROPERTY_MAP = 'invalid reverse property map',\n  INVALID_REVERSE_PROPERTY_VALUE = 'invalid reverse property value',\n  INVALID_SCOPED_CONTEXT = 'invalid scoped context',\n  INVALID_SCRIPT_ELEMENT = 'invalid script element',\n  INVALID_SET_OR_LIST_OBJECT = 'invalid set or list object',\n  INVALID_TERM_DEFINITION = 'invalid term definition',\n  INVALID_TYPE_MAPPING = 'invalid type mapping',\n  INVALID_TYPE_VALUE = 'invalid type value',\n  INVALID_TYPED_VALUE = 'invalid typed value',\n  INVALID_VALUE_OBJECT = 'invalid value object',\n  INVALID_VALUE_OBJECT_VALUE = 'invalid value object value',\n  INVALID_VOCAB_MAPPING = 'invalid vocab mapping',\n  IRI_CONFUSED_WITH_PREFIX = 'IRI confused with prefix',\n  KEYWORD_REDEFINITION = 'keyword redefinition',\n  LOADING_DOCUMENT_FAILED = 'loading document failed',\n  LOADING_REMOTE_CONTEXT_FAILED = 'loading remote context failed',\n  MULTIPLE_CONTEXT_LINK_HEADERS = 'multiple context link headers',\n  PROCESSING_MODE_CONFLICT = 'processing mode conflict',\n  PROTECTED_TERM_REDEFINITION = 'protected term redefinition',\n  CONTEXT_OVERFLOW = 'context overflow',\n  INVALID_BASE_DIRECTION = 'invalid base direction',\n  RECURSIVE_CONTEXT_INCLUSION = 'recursive context inclusion',\n  INVALID_STREAMING_KEY_ORDER = 'invalid streaming key order',\n}\n","import 'cross-fetch/polyfill';\nimport {IDocumentLoader} from \"./IDocumentLoader\";\nimport {IJsonLdContext} from \"./JsonLdContext\";\nimport {ERROR_CODES, ErrorCoded} from \"./ErrorCoded\";\nimport {parse as parseLinkHeader} from \"http-link-header\";\nimport {resolve} from \"relative-to-absolute-iri\";\n\n/**\n * Loads documents via the fetch API.\n */\nexport class FetchDocumentLoader implements IDocumentLoader {\n\n  private readonly fetcher?: (url: string, init: RequestInit) => Promise<Response>;\n\n  constructor(fetcher?: (url: string, init: RequestInit) => Promise<Response>) {\n    this.fetcher = fetcher;\n  }\n\n  public async load(url: string): Promise<IJsonLdContext> {\n    const response: Response = await (this.fetcher || fetch)(url, { headers: new Headers({ accept: 'application/ld+json' }) });\n    if (response.ok && response.headers) {\n      let mediaType = response.headers.get('Content-Type');\n      if (mediaType) {\n        const colonPos = mediaType.indexOf(';');\n        if (colonPos > 0) {\n          mediaType = mediaType.substr(0, colonPos);\n        }\n      }\n      if (mediaType === 'application/ld+json') {\n        // Return JSON-LD if proper content type was returned\n        return (await response.json());\n      } else {\n        // Check for alternate link for a non-JSON-LD response\n        if (response.headers.has('Link')) {\n          let alternateUrl: string | undefined;\n          response.headers.forEach((value, key) => {\n            if (key === 'link') {\n              const linkHeader = parseLinkHeader(value);\n              for (const link of linkHeader.get('type', 'application/ld+json')) {\n                if (link.rel === 'alternate') {\n                  if (alternateUrl) {\n                    throw new Error('Multiple JSON-LD alternate links were found on ' + url);\n                  }\n                  alternateUrl = resolve(link.uri, url);\n                }\n              }\n            }\n          });\n          if (alternateUrl) {\n            return this.load(alternateUrl);\n          }\n        }\n\n        throw new ErrorCoded(`Unsupported JSON-LD media type ${mediaType}`,\n          ERROR_CODES.LOADING_DOCUMENT_FAILED);\n      }\n    } else {\n      throw new Error(response.statusText || `Status code: ${response.status}`);\n    }\n  }\n\n}\n","// tslint:disable:max-line-length\n\nexport type JsonLdContext = IJsonLdContext | string | (IJsonLdContext | string)[];\n\nexport interface IJsonLdContext {\n  '@base'?: Uri | null;     // 1.0; https://json-ld.org/spec/latest/json-ld/#base-iri\n  '@vocab'?: Uri | null;    // 1.0; https://json-ld.org/spec/latest/json-ld/#default-vocabulary\n  '@language'?: Language;   // 1.0; https://json-ld.org/spec/latest/json-ld/#string-internationalization\n  [id: string]: any;\n  // We can not define the following entries here due to TS restrictions\n  // [alias: string]: Uri;\n  // [prefix: string]: IPrefixValue; // 1.0; https://json-ld.org/spec/latest/json-ld/#iri-expansion-within-a-context\n  '@version'?: number;      // 1.1: https://json-ld.org/spec/latest/json-ld/#json-ld-1-1-processing-mode\n}\n\nexport interface IJsonLdContextNormalizedRaw {\n  '@base'?: Uri | null;     // 1.0; https://json-ld.org/spec/latest/json-ld/#base-iri\n  '@vocab'?: Uri | null;    // 1.0; https://json-ld.org/spec/latest/json-ld/#default-vocabulary\n  '@language'?: Language;   // 1.0; https://json-ld.org/spec/latest/json-ld/#string-internationalization\n  [id: string]: any;\n  // We can not define the following entries here due to TS restrictions\n  // [alias: string]: Uri;\n  // [prefix: string]: IPrefixValue; // 1.0; https://json-ld.org/spec/latest/json-ld/#iri-expansion-within-a-context\n  '@version'?: number;      // 1.1: https://json-ld.org/spec/latest/json-ld/#json-ld-1-1-processing-mode\n}\n\nexport type IPrefixValue = string\n  | {\n    '@id'?: Uri | Bnode;\n    '@reverse'?: Uri | boolean;   // 1.0; https://json-ld.org/spec/latest/json-ld/#reverse-properties\n    '@type'?: Types;              // 1.0; https://json-ld.org/spec/latest/json-ld/#typed-values\n                                  //      https://json-ld.org/spec/latest/json-ld/#type-coercion\n                                  //      https://json-ld.org/spec/latest/json-ld/#embedding\n    '@container'?: Containers;\n    '@value'?: string;            // 1.0; https://json-ld.org/spec/latest/json-ld/#typed-values\n    '@context'?: JsonLdContext;   // 1.1; https://json-ld.org/spec/latest/json-ld/#scoped-contexts\n    '@prefix'?: boolean;          // 1.1; https://json-ld.org/spec/latest/json-ld/#compact-iris\n  }\n  | '@nest'                       // 1.1; https://json-ld.org/spec/latest/json-ld/#nested-properties\n  ;\n\nexport type Uri = string;\nexport type Bnode = string;\n\nexport type Language = string;\n\nexport type Types = '@id' | Uri;\n\nexport type Containers =\n    '@language'                           // 1.0; https://json-ld.org/spec/latest/json-ld/#string-internationalization\n  | '@list'                               // 1.0; https://json-ld.org/spec/latest/json-ld/#sets-and-lists\n  | '@set'                                // 1.0; https://json-ld.org/spec/latest/json-ld/#sets-and-lists\n  | '@index'                              // 1.0; https://json-ld.org/spec/latest/json-ld/#data-indexing\n  | '@graph'                              // 1.1; https://json-ld.org/spec/latest/json-ld/#graph-containers\n  | ['@index', '@set']                    // 1.1; https://json-ld.org/spec/latest/json-ld/#data-indexing\n  | ['@graph', '@index']                  // 1.1; https://json-ld.org/spec/latest/json-ld/#named-graph-indexing\n  | '@language' | ['@language', '@set']   // 1.1; https://json-ld.org/spec/latest/json-ld/#language-indexing\n  | '@id' | ['@id', '@set']               // 1.1; https://json-ld.org/spec/latest/json-ld/#node-identifier-indexing\n  | ['@graph', '@id']                     // 1.1; https://json-ld.org/spec/latest/json-ld/#named-graph-indexing-by-identifier\n  | '@type' | ['@type', '@set']           // 1.1; https://json-ld.org/spec/latest/json-ld/#node-type-indexing\n  ;\n","import {resolve} from \"relative-to-absolute-iri\";\nimport {defaultExpandOptions, IExpandOptions} from \"./ContextParser\";\nimport {ERROR_CODES, ErrorCoded} from \"./ErrorCoded\";\nimport {IJsonLdContextNormalizedRaw} from \"./JsonLdContext\";\nimport {Util} from \"./Util\";\n\n/**\n * A class exposing operations over a normalized JSON-LD context.\n */\nexport class JsonLdContextNormalized {\n\n  private readonly contextRaw: IJsonLdContextNormalizedRaw;\n\n  constructor(contextRaw: IJsonLdContextNormalizedRaw) {\n    this.contextRaw = contextRaw;\n  }\n\n  /**\n   * @return The raw inner context.\n   */\n  public getContextRaw(): IJsonLdContextNormalizedRaw {\n    return this.contextRaw;\n  }\n\n  /**\n   * Expand the term or prefix of the given term if it has one,\n   * otherwise return the term as-is.\n   *\n   * This will try to expand the IRI as much as possible.\n   *\n   * Iff in vocab-mode, then other references to other terms in the context can be used,\n   * such as to `myTerm`:\n   * ```\n   * {\n   *   \"myTerm\": \"http://example.org/myLongTerm\"\n   * }\n   * ```\n   *\n   * @param {string} term A term that is an URL or a prefixed URL.\n   * @param {boolean} expandVocab If the term is a predicate or type and should be expanded based on @vocab,\n   *                              otherwise it is considered a regular term that is expanded based on @base.\n   * @param {IExpandOptions} options Options that define the way how expansion must be done.\n   * @return {string} The expanded term, the term as-is, or null if it was explicitly disabled in the context.\n   * @throws If the term is aliased to an invalid value (not a string, IRI or keyword).\n   */\n  public expandTerm(term: string, expandVocab?: boolean,\n                    options: IExpandOptions = defaultExpandOptions): string | null {\n    const contextValue = this.contextRaw[term];\n\n    // Immediately return if the term was disabled in the context\n    if (contextValue === null || (contextValue && contextValue['@id'] === null)) {\n      return null;\n    }\n\n    // Check the @id\n    let validIriMapping = true;\n    if (contextValue && expandVocab) {\n      const value = Util.getContextValueId(contextValue);\n      if (value && value !== term) {\n        if (typeof value !== 'string' || (!Util.isValidIri(value) && !Util.isValidKeyword(value))) {\n          // Don't mark this mapping as invalid if we have an unknown keyword, but of the correct form.\n          if (!Util.isPotentialKeyword(value)) {\n            validIriMapping = false;\n          }\n        } else {\n          return value;\n        }\n      }\n    }\n\n    // Check if the term is prefixed\n    const prefix: string | null = Util.getPrefix(term, this.contextRaw);\n    const vocab: string | undefined | null = this.contextRaw['@vocab'];\n    const vocabRelative: boolean = (!!vocab || vocab === '') && vocab.indexOf(':') < 0;\n    const base: string | undefined | null = this.contextRaw['@base'];\n    const potentialKeyword = Util.isPotentialKeyword(term);\n    if (prefix) {\n      const contextPrefixValue = this.contextRaw[prefix];\n      const value = Util.getContextValueId(contextPrefixValue);\n\n      if (value) {\n        if (typeof contextPrefixValue === 'string' || !options.allowPrefixForcing) {\n          // If we have a simple term definition,\n          // check the last character of the prefix to determine whether or not it is a prefix.\n          // Validate that prefix ends with gen-delim character, unless @prefix is true\n          if (!Util.isSimpleTermDefinitionPrefix(value, options)) {\n            // Treat the term as an absolute IRI\n            return term;\n          }\n        } else {\n          // If we have an expanded term definition, default to @prefix: false\n          if (value[0] !== '_' && !potentialKeyword && !contextPrefixValue['@prefix'] && !(term in this.contextRaw)) {\n            // Treat the term as an absolute IRI\n            return term;\n          }\n        }\n\n        return value + term.substr(prefix.length + 1);\n      }\n    } else if (expandVocab && ((vocab || vocab === '') || (options.allowVocabRelativeToBase && (base && vocabRelative)))\n      && !potentialKeyword && !Util.isCompactIri(term)) {\n      if (vocabRelative) {\n        if (options.allowVocabRelativeToBase) {\n          return ((vocab || base) ? resolve(<string> vocab, <any> base) : '') + term;\n        } else {\n          throw new ErrorCoded(`Relative vocab expansion for term '${term}' with vocab '${\n            vocab}' is not allowed.`, ERROR_CODES.INVALID_VOCAB_MAPPING);\n        }\n      } else {\n        return vocab + term;\n      }\n    } else if (!expandVocab && base && !potentialKeyword && !Util.isCompactIri(term)) {\n      return resolve(term, base);\n    }\n\n    // Return the term as-is, unless we discovered an invalid IRI mapping for this term in the context earlier.\n    if (validIriMapping) {\n      return term;\n    } else {\n      throw new ErrorCoded(`Invalid IRI mapping found for context entry '${term}': '${\n        JSON.stringify(contextValue)}'`, ERROR_CODES.INVALID_IRI_MAPPING);\n    }\n  }\n\n  /**\n   * Compact the given term using @base, @vocab, an aliased term, or a prefixed term.\n   *\n   * This will try to compact the IRI as much as possible.\n   *\n   * @param {string} iri An IRI to compact.\n   * @param {boolean} vocab If the term is a predicate or type and should be compacted based on @vocab,\n   *                        otherwise it is considered a regular term that is compacted based on @base.\n   * @return {string} The compacted term or the IRI as-is.\n   */\n  public compactIri(iri: string, vocab?: boolean): string {\n    // Try @vocab compacting\n    if (vocab && this.contextRaw['@vocab'] && iri.startsWith(this.contextRaw['@vocab'])) {\n      return iri.substr(this.contextRaw['@vocab'].length);\n    }\n\n    // Try @base compacting\n    if (!vocab && this.contextRaw['@base'] && iri.startsWith(this.contextRaw['@base'])) {\n      return iri.substr(this.contextRaw['@base'].length);\n    }\n\n    // Loop over all terms in the context\n    // This will try to prefix as short as possible.\n    // Once a fully compacted alias is found, return immediately, as we can not go any shorter.\n    const shortestPrefixing: { prefix: string, suffix: string } = { prefix: '', suffix: iri };\n    for (const key in this.contextRaw) {\n      const value = this.contextRaw[key];\n      if (value && !Util.isPotentialKeyword(key)) {\n        const contextIri = Util.getContextValueId(value);\n        if (iri.startsWith(contextIri)) {\n          const suffix = iri.substr(contextIri.length);\n          if (!suffix) {\n            if (vocab) {\n              // Immediately return on compacted alias\n              return key;\n            }\n          } else if (suffix.length < shortestPrefixing.suffix.length) {\n            // Overwrite the shortest prefix\n            shortestPrefixing.prefix = key;\n            shortestPrefixing.suffix = suffix;\n          }\n        }\n      }\n    }\n\n    // Return the shortest prefix\n    if (shortestPrefixing.prefix) {\n      return shortestPrefixing.prefix + ':' + shortestPrefixing.suffix;\n    }\n\n    return iri;\n  }\n\n}\n","import {IExpandOptions} from \"./ContextParser\";\nimport {IJsonLdContextNormalizedRaw, JsonLdContext} from \"./JsonLdContext\";\n\nexport class Util {\n\n  // Regex for valid IRIs\n  public static readonly IRI_REGEX: RegExp = /^([A-Za-z][A-Za-z0-9+-.]*|_):[^ \"<>{}|\\\\\\[\\]`#]*(#[^#]*)?$/;\n  // Weaker regex for valid IRIs, this includes relative IRIs\n  public static readonly IRI_REGEX_WEAK: RegExp = /(?::[^:])|\\//;\n  // Regex for keyword form\n  public static readonly KEYWORD_REGEX: RegExp = /^@[a-z]+$/i;\n  // Regex to see if an IRI ends with a gen-delim character (see RFC 3986)\n  public static readonly ENDS_WITH_GEN_DELIM: RegExp = /[:/?#\\[\\]@]$/;\n  // Regex for language tags\n  public static readonly REGEX_LANGUAGE_TAG: RegExp = /^[a-zA-Z]+(-[a-zA-Z0-9]+)*$/;\n  // Regex for base directions\n  public static readonly REGEX_DIRECTION_TAG: RegExp = /^(ltr)|(rtl)$/;\n\n  // All known valid JSON-LD keywords\n  // @see https://www.w3.org/TR/json-ld11/#keywords\n  public static readonly VALID_KEYWORDS: {[keyword: string]: boolean} = {\n    '@base': true,\n    '@container': true,\n    '@context': true,\n    '@direction': true,\n    '@graph': true,\n    '@id': true,\n    '@import': true,\n    '@included': true,\n    '@index': true,\n    '@json': true,\n    '@language': true,\n    '@list': true,\n    '@nest': true,\n    '@none': true,\n    '@prefix': true,\n    '@propagate': true,\n    '@protected': true,\n    '@reverse': true,\n    '@set': true,\n    '@type': true,\n    '@value': true,\n    '@version': true,\n    '@vocab': true,\n  };\n  // Keys in the contexts that will not be expanded based on the base IRI\n  public static readonly EXPAND_KEYS_BLACKLIST: string[] = [\n    '@base',\n    '@vocab',\n    '@language',\n    '@version',\n    '@direction',\n  ];\n  // Keys in the contexts that may not be aliased from\n  public static readonly ALIAS_DOMAIN_BLACKLIST: string[] = [\n    '@container',\n    '@graph',\n    '@id',\n    '@index',\n    '@list',\n    '@nest',\n    '@none',\n    '@prefix',\n    '@reverse',\n    '@set',\n    '@type',\n    '@value',\n    '@version',\n  ];\n  // Keys in the contexts that may not be aliased to\n  public static readonly ALIAS_RANGE_BLACKLIST: string[] = [\n    '@context',\n    '@preserve',\n  ];\n  // All valid @container values\n  public static readonly CONTAINERS: string[] = [\n    '@list',\n    '@set',\n    '@index',\n    '@language',\n    '@graph',\n    '@id',\n    '@type',\n  ];\n  // All valid @container values under processing mode 1.0\n  public static readonly CONTAINERS_1_0: string[] = [\n    '@list',\n    '@set',\n    '@index',\n  ];\n\n  /**\n   * Check if the given term is a valid compact IRI.\n   * Otherwise, it may be an IRI.\n   * @param {string} term A term.\n   * @return {boolean} If it is a compact IRI.\n   */\n  public static isCompactIri(term: string) {\n    return term.indexOf(':') > 0 && !(term && term[0] === '#');\n  }\n\n  /**\n   * Get the prefix from the given term.\n   * @see https://json-ld.org/spec/latest/json-ld/#compact-iris\n   * @param {string} term A term that is an URL or a prefixed URL.\n   * @param {IJsonLdContextNormalizedRaw} context A context.\n   * @return {string} The prefix or null.\n   */\n  public static getPrefix(term: string, context: IJsonLdContextNormalizedRaw): string | null {\n    // Do not consider relative IRIs starting with a hash as compact IRIs\n    if (term && term[0] === '#') {\n      return null;\n    }\n\n    const separatorPos: number = term.indexOf(':');\n    if (separatorPos >= 0) {\n      // Suffix can not begin with two slashes\n      if (term.length > separatorPos + 1\n        && term.charAt(separatorPos + 1) === '/'\n        && term.charAt(separatorPos + 2) === '/') {\n        return null;\n      }\n\n      const prefix: string = term.substr(0, separatorPos);\n\n      // Prefix can not be an underscore (this is a blank node)\n      if (prefix === '_' ) {\n        return null;\n      }\n\n      // Prefix must match a term in the active context\n      if (context[prefix]) {\n        return prefix;\n      }\n    }\n    return null;\n  }\n\n  /**\n   * From a given context entry value, get the string value, or the @id field.\n   * @param contextValue A value for a term in a context.\n   * @return {string} The id value, or null.\n   */\n  public static getContextValueId(contextValue: any): string {\n    if (contextValue === null || typeof contextValue === 'string') {\n      return contextValue;\n    }\n    const id = contextValue['@id'];\n    return id ? id : null;\n  }\n\n  /**\n   * Check if the given simple term definition (string-based value of a context term)\n   * should be considered a prefix.\n   * @param value A simple term definition value.\n   * @param options Options that define the way how expansion must be done.\n   */\n  public static isSimpleTermDefinitionPrefix(value: string, options: IExpandOptions): boolean {\n    return !Util.isPotentialKeyword(value)\n      && (value[0] === '_' || options.allowPrefixNonGenDelims || Util.isPrefixIriEndingWithGenDelim(value));\n  }\n\n  /**\n   * Check if the given keyword is of the keyword format \"@\"1*ALPHA.\n   * @param {string} keyword A potential keyword.\n   * @return {boolean} If the given keyword is of the keyword format.\n   */\n  public static isPotentialKeyword(keyword: any): boolean {\n    return typeof keyword === 'string' && Util.KEYWORD_REGEX.test(keyword);\n  }\n\n  /**\n   * Check if the given prefix ends with a gen-delim character.\n   * @param {string} prefixIri A prefix IRI.\n   * @return {boolean} If the given prefix IRI is valid.\n   */\n  public static isPrefixIriEndingWithGenDelim(prefixIri: string): boolean {\n    return Util.ENDS_WITH_GEN_DELIM.test(prefixIri);\n  }\n\n  /**\n   * Check if the given context value can be a prefix value.\n   * @param value A context value.\n   * @return {boolean} If it can be a prefix value.\n   */\n  public static isPrefixValue(value: any): boolean {\n    return value && (typeof value === 'string' || (value && typeof value === 'object'));\n  }\n\n  /**\n   * Check if the given IRI is valid.\n   * @param {string} iri A potential IRI.\n   * @return {boolean} If the given IRI is valid.\n   */\n  public static isValidIri(iri: string | null): boolean {\n    return Boolean(iri && Util.IRI_REGEX.test(iri));\n  }\n\n  /**\n   * Check if the given IRI is valid, this includes the possibility of being a relative IRI.\n   * @param {string} iri A potential IRI.\n   * @return {boolean} If the given IRI is valid.\n   */\n  public static isValidIriWeak(iri: string | null): boolean {\n    return !!iri && iri[0] !== ':' && Util.IRI_REGEX_WEAK.test(iri);\n  }\n\n  /**\n   * Check if the given keyword is a defined according to the JSON-LD specification.\n   * @param {string} keyword A potential keyword.\n   * @return {boolean} If the given keyword is valid.\n   */\n  public static isValidKeyword(keyword: any): boolean {\n    return Util.VALID_KEYWORDS[keyword];\n  }\n\n  /**\n   * Check if the given term is protected in the context.\n   * @param {IJsonLdContextNormalizedRaw} context A context.\n   * @param {string} key A context term.\n   * @return {boolean} If the given term has an @protected flag.\n   */\n  public static isTermProtected(context: IJsonLdContextNormalizedRaw, key: string): boolean {\n    const value = context[key];\n    return !(typeof value === 'string') && value && value['@protected'];\n  }\n\n  /**\n   * Check if the given context has at least one protected term.\n   * @param context A context.\n   * @return If the context has a protected term.\n   */\n  public static hasProtectedTerms(context: IJsonLdContextNormalizedRaw) {\n    for (const key of Object.keys(context)) {\n      if (Util.isTermProtected(context, key)) {\n        return true;\n      }\n    }\n    return false;\n  }\n\n  /**\n   * Check if the given key is an internal reserved keyword.\n   * @param key A context key.\n   */\n  public static isReservedInternalKeyword(key: string) {\n    return key.startsWith('@__');\n  }\n}\n","\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __exportStar = (this && this.__exportStar) || function(m, exports) {\n    for (var p in m) if (p !== \"default\" && !Object.prototype.hasOwnProperty.call(exports, p)) __createBinding(exports, m, p);\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\n__exportStar(require(\"./lib/JsonLdParser\"), exports);\n//# sourceMappingURL=index.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.ContextTree = void 0;\n/**\n * A tree structure that holds all contexts,\n * based on their position in the JSON object.\n *\n * Positions are identified by a path of keys.\n */\nclass ContextTree {\n    constructor() {\n        this.subTrees = {};\n    }\n    getContext(keys) {\n        if (keys.length > 0) {\n            const [head, ...tail] = keys;\n            const subTree = this.subTrees[head];\n            if (subTree) {\n                const subContext = subTree.getContext(tail);\n                if (subContext) {\n                    return subContext.then(({ context, depth }) => ({ context, depth: depth + 1 }));\n                }\n            }\n        }\n        return this.context ? this.context.then((context) => ({ context, depth: 0 })) : null;\n    }\n    setContext(keys, context) {\n        if (keys.length === 0) {\n            this.context = context;\n        }\n        else {\n            const [head, ...tail] = keys;\n            let subTree = this.subTrees[head];\n            if (!subTree) {\n                subTree = this.subTrees[head] = new ContextTree();\n            }\n            subTree.setContext(tail, context);\n        }\n    }\n    removeContext(path) {\n        this.setContext(path, null);\n    }\n}\nexports.ContextTree = ContextTree;\n//# sourceMappingURL=ContextTree.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.JsonLdParser = void 0;\n// tslint:disable-next-line:no-var-requires\nconst Parser = require('jsonparse');\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\nconst stream_1 = require(\"stream\");\nconst EntryHandlerArrayValue_1 = require(\"./entryhandler/EntryHandlerArrayValue\");\nconst EntryHandlerContainer_1 = require(\"./entryhandler/EntryHandlerContainer\");\nconst EntryHandlerInvalidFallback_1 = require(\"./entryhandler/EntryHandlerInvalidFallback\");\nconst EntryHandlerPredicate_1 = require(\"./entryhandler/EntryHandlerPredicate\");\nconst EntryHandlerKeywordContext_1 = require(\"./entryhandler/keyword/EntryHandlerKeywordContext\");\nconst EntryHandlerKeywordGraph_1 = require(\"./entryhandler/keyword/EntryHandlerKeywordGraph\");\nconst EntryHandlerKeywordId_1 = require(\"./entryhandler/keyword/EntryHandlerKeywordId\");\nconst EntryHandlerKeywordIncluded_1 = require(\"./entryhandler/keyword/EntryHandlerKeywordIncluded\");\nconst EntryHandlerKeywordNest_1 = require(\"./entryhandler/keyword/EntryHandlerKeywordNest\");\nconst EntryHandlerKeywordType_1 = require(\"./entryhandler/keyword/EntryHandlerKeywordType\");\nconst EntryHandlerKeywordUnknownFallback_1 = require(\"./entryhandler/keyword/EntryHandlerKeywordUnknownFallback\");\nconst EntryHandlerKeywordValue_1 = require(\"./entryhandler/keyword/EntryHandlerKeywordValue\");\nconst ParsingContext_1 = require(\"./ParsingContext\");\nconst Util_1 = require(\"./Util\");\nconst http_link_header_1 = require(\"http-link-header\");\n/**\n * A stream transformer that parses JSON-LD (text) streams to an {@link RDF.Stream}.\n */\nclass JsonLdParser extends stream_1.Transform {\n    constructor(options) {\n        super({ readableObjectMode: true });\n        options = options || {};\n        this.options = options;\n        this.parsingContext = new ParsingContext_1.ParsingContext(Object.assign({ parser: this }, options));\n        this.util = new Util_1.Util({ dataFactory: options.dataFactory, parsingContext: this.parsingContext });\n        this.jsonParser = new Parser();\n        this.contextJobs = [];\n        this.typeJobs = [];\n        this.contextAwaitingJobs = [];\n        this.lastDepth = 0;\n        this.lastKeys = [];\n        this.lastOnValueJob = Promise.resolve();\n        this.attachJsonParserListeners();\n        this.on('end', () => {\n            if (typeof this.jsonParser.mode !== 'undefined') {\n                this.emit('error', new Error('Unclosed document'));\n            }\n        });\n    }\n    /**\n     * Construct a JsonLdParser from the given HTTP response.\n     *\n     * This will throw an error if no valid JSON response is received\n     * (application/ld+json, application/json, or something+json).\n     *\n     * For raw JSON responses, exactly one link header pointing to a JSON-LD context is required.\n     *\n     * This method is not responsible for handling redirects.\n     *\n     * @param baseIRI The URI of the received response.\n     * @param mediaType The received content type.\n     * @param headers Optional HTTP headers.\n     * @param options Optional parser options.\n     */\n    static fromHttpResponse(baseIRI, mediaType, headers, options) {\n        let context;\n        // Special cases when receiving something else than the JSON-LD media type\n        if (mediaType !== 'application/ld+json') {\n            // Only accept JSON or JSON extension types\n            if (mediaType !== 'application/json' && !mediaType.endsWith('+json')) {\n                throw new jsonld_context_parser_1.ErrorCoded(`Unsupported JSON-LD media type ${mediaType}`, jsonld_context_parser_1.ERROR_CODES.LOADING_DOCUMENT_FAILED);\n            }\n            // We need exactly one JSON-LD context in the link header\n            if (headers && headers.has('Link')) {\n                headers.forEach((value, key) => {\n                    if (key === 'link') {\n                        const linkHeader = http_link_header_1.parse(value);\n                        for (const link of linkHeader.get('rel', 'http://www.w3.org/ns/json-ld#context')) {\n                            if (context) {\n                                throw new jsonld_context_parser_1.ErrorCoded('Multiple JSON-LD context link headers were found on ' + baseIRI, jsonld_context_parser_1.ERROR_CODES.MULTIPLE_CONTEXT_LINK_HEADERS);\n                            }\n                            context = link.uri;\n                        }\n                    }\n                });\n            }\n            if (!context && !(options === null || options === void 0 ? void 0 : options.ignoreMissingContextLinkHeader)) {\n                throw new jsonld_context_parser_1.ErrorCoded(`Missing context link header for media type ${mediaType} on ${baseIRI}`, jsonld_context_parser_1.ERROR_CODES.LOADING_DOCUMENT_FAILED);\n            }\n        }\n        // Check if the streaming profile is present\n        let streamingProfile;\n        if (headers && headers.has('Content-Type')) {\n            const contentType = headers.get('Content-Type');\n            const match = /; *profile=([^\"]*)/.exec(contentType);\n            if (match && match[1] === 'http://www.w3.org/ns/json-ld#streaming') {\n                streamingProfile = true;\n            }\n        }\n        return new JsonLdParser(Object.assign({ baseIRI,\n            context,\n            streamingProfile }, options ? options : {}));\n    }\n    /**\n     * Parses the given text stream into a quad stream.\n     * @param {NodeJS.EventEmitter} stream A text stream.\n     * @return {RDF.Stream} A quad stream.\n     */\n    import(stream) {\n        const output = new stream_1.PassThrough({ readableObjectMode: true });\n        stream.on('error', (error) => parsed.emit('error', error));\n        stream.on('data', (data) => output.push(data));\n        stream.on('end', () => output.push(null));\n        const parsed = output.pipe(new JsonLdParser(this.options));\n        return parsed;\n    }\n    _transform(chunk, encoding, callback) {\n        this.jsonParser.write(chunk);\n        this.lastOnValueJob\n            .then(() => callback(), (error) => callback(error));\n    }\n    /**\n     * Start a new job for parsing the given value.\n     *\n     * This will let the first valid {@link IEntryHandler} handle the entry.\n     *\n     * @param {any[]} keys The stack of keys.\n     * @param value The value to parse.\n     * @param {number} depth The depth to parse at.\n     * @param {boolean} lastDepthCheck If the lastDepth check should be done for buffer draining.\n     * @return {Promise<void>} A promise resolving when the job is done.\n     */\n    async newOnValueJob(keys, value, depth, lastDepthCheck) {\n        let flushStacks = true;\n        // When we go up the stack, emit all unidentified values\n        // We need to do this before the new job, because the new job may require determined values from the flushed jobs.\n        if (lastDepthCheck && depth < this.lastDepth) {\n            // Check if we had any RDF lists that need to be terminated with an rdf:nil\n            const listPointer = this.parsingContext.listPointerStack[this.lastDepth];\n            if (listPointer) {\n                // Terminate the list if the had at least one value\n                if (listPointer.value) {\n                    this.emit('data', this.util.dataFactory.quad(listPointer.value, this.util.rdfRest, this.util.rdfNil, this.util.getDefaultGraph()));\n                }\n                // Add the list id to the id stack, so it can be used higher up in the stack\n                listPointer.listId.listHead = true;\n                this.parsingContext.idStack[listPointer.listRootDepth + 1] = [listPointer.listId];\n                this.parsingContext.listPointerStack.splice(this.lastDepth, 1);\n            }\n            // Flush the buffer for lastDepth\n            // If the parent key is a special type of container, postpone flushing until that parent is handled.\n            if (await EntryHandlerContainer_1.EntryHandlerContainer.isBufferableContainerHandler(this.parsingContext, this.lastKeys, this.lastDepth)) {\n                this.parsingContext.pendingContainerFlushBuffers\n                    .push({ depth: this.lastDepth, keys: this.lastKeys.slice(0, this.lastKeys.length) });\n                flushStacks = false;\n            }\n            else {\n                await this.flushBuffer(this.lastDepth, this.lastKeys);\n            }\n        }\n        const key = await this.util.unaliasKeyword(keys[depth], keys, depth);\n        const parentKey = await this.util.unaliasKeywordParent(keys, depth);\n        this.parsingContext.emittedStack[depth] = true;\n        let handleKey = true;\n        // Keywords inside @reverse is not allowed apart from @context\n        if (jsonld_context_parser_1.Util.isValidKeyword(key) && parentKey === '@reverse' && key !== '@context') {\n            this.emit('error', new jsonld_context_parser_1.ErrorCoded(`Found the @id '${value}' inside an @reverse property`, jsonld_context_parser_1.ERROR_CODES.INVALID_REVERSE_PROPERTY_MAP));\n        }\n        // Skip further processing if one of the parent nodes are invalid.\n        // We use the validationStack to reuse validation results that were produced before with common key stacks.\n        let inProperty = false;\n        if (this.parsingContext.validationStack.length > 1) {\n            inProperty = this.parsingContext.validationStack[this.parsingContext.validationStack.length - 1].property;\n        }\n        for (let i = Math.max(1, this.parsingContext.validationStack.length - 1); i < keys.length - 1; i++) {\n            const validationResult = this.parsingContext.validationStack[i]\n                || (this.parsingContext.validationStack[i] = await this.validateKey(keys.slice(0, i + 1), i, inProperty));\n            if (!validationResult.valid) {\n                this.parsingContext.emittedStack[depth] = false;\n                handleKey = false;\n                break;\n            }\n            else if (!inProperty && validationResult.property) {\n                inProperty = true;\n            }\n        }\n        // Skip further processing if this node is part of a literal\n        if (this.util.isLiteral(depth)) {\n            handleKey = false;\n        }\n        // Get handler\n        if (handleKey) {\n            for (const entryHandler of JsonLdParser.ENTRY_HANDLERS) {\n                const testResult = await entryHandler.test(this.parsingContext, this.util, key, keys, depth);\n                if (testResult) {\n                    // Pass processing over to the handler\n                    await entryHandler.handle(this.parsingContext, this.util, key, keys, value, depth, testResult);\n                    // Flag that this depth is processed\n                    if (entryHandler.isStackProcessor()) {\n                        this.parsingContext.processingStack[depth] = true;\n                    }\n                    break;\n                }\n            }\n        }\n        // Validate value indexes on the root.\n        if (depth === 0 && Array.isArray(value)) {\n            await this.util.validateValueIndexes(value);\n        }\n        // When we go up the stack, flush the old stack\n        if (flushStacks && depth < this.lastDepth) {\n            // Reset our stacks\n            this.flushStacks(this.lastDepth);\n        }\n        this.lastDepth = depth;\n        this.lastKeys = keys;\n        // Clear the keyword cache at this depth, and everything underneath.\n        this.parsingContext.unaliasedKeywordCacheStack.splice(depth - 1);\n    }\n    /**\n     * Flush the processing stacks at the given depth.\n     * @param {number} depth A depth.\n     */\n    flushStacks(depth) {\n        this.parsingContext.processingStack.splice(depth, 1);\n        this.parsingContext.processingType.splice(depth, 1);\n        this.parsingContext.emittedStack.splice(depth, 1);\n        this.parsingContext.idStack.splice(depth, 1);\n        this.parsingContext.graphStack.splice(depth + 1, 1);\n        this.parsingContext.graphContainerTermStack.splice(depth, 1);\n        this.parsingContext.jsonLiteralStack.splice(depth, 1);\n        this.parsingContext.validationStack.splice(depth - 1, 2);\n        this.parsingContext.literalStack.splice(depth, this.parsingContext.literalStack.length - depth);\n        // TODO: just like the literal stack, splice all other stack until the end as well?\n    }\n    /**\n     * Flush buffers for the given depth.\n     *\n     * This should be called after the last entry at a given depth was processed.\n     *\n     * @param {number} depth A depth.\n     * @param {any[]} keys A stack of keys.\n     * @return {Promise<void>} A promise resolving if flushing is done.\n     */\n    async flushBuffer(depth, keys) {\n        let subjects = this.parsingContext.idStack[depth];\n        if (!subjects) {\n            subjects = this.parsingContext.idStack[depth] = [this.util.dataFactory.blankNode()];\n        }\n        // Flush values at this level\n        const valueBuffer = this.parsingContext.unidentifiedValuesBuffer[depth];\n        if (valueBuffer) {\n            for (const subject of subjects) {\n                const depthOffsetGraph = await this.util.getDepthOffsetGraph(depth, keys);\n                const graphs = (this.parsingContext.graphStack[depth] || depthOffsetGraph >= 0)\n                    ? this.parsingContext.idStack[depth - depthOffsetGraph - 1]\n                    : [await this.util.getGraphContainerValue(keys, depth)];\n                if (graphs) {\n                    for (const graph of graphs) {\n                        // Flush values to stream if the graph @id is known\n                        this.parsingContext.emittedStack[depth] = true;\n                        for (const bufferedValue of valueBuffer) {\n                            if (bufferedValue.reverse) {\n                                this.parsingContext.emitQuad(depth, this.util.dataFactory.quad(bufferedValue.object, bufferedValue.predicate, subject, graph));\n                            }\n                            else {\n                                this.parsingContext.emitQuad(depth, this.util.dataFactory.quad(subject, bufferedValue.predicate, bufferedValue.object, graph));\n                            }\n                        }\n                    }\n                }\n                else {\n                    // Place the values in the graphs buffer if the graph @id is not yet known\n                    const subGraphBuffer = this.parsingContext.getUnidentifiedGraphBufferSafe(depth - await this.util.getDepthOffsetGraph(depth, keys) - 1);\n                    for (const bufferedValue of valueBuffer) {\n                        if (bufferedValue.reverse) {\n                            subGraphBuffer.push({\n                                object: subject,\n                                predicate: bufferedValue.predicate,\n                                subject: bufferedValue.object,\n                            });\n                        }\n                        else {\n                            subGraphBuffer.push({\n                                object: bufferedValue.object,\n                                predicate: bufferedValue.predicate,\n                                subject,\n                            });\n                        }\n                    }\n                }\n            }\n            this.parsingContext.unidentifiedValuesBuffer.splice(depth, 1);\n            this.parsingContext.literalStack.splice(depth, 1);\n            this.parsingContext.jsonLiteralStack.splice(depth, 1);\n        }\n        // Flush graphs at this level\n        const graphBuffer = this.parsingContext.unidentifiedGraphsBuffer[depth];\n        if (graphBuffer) {\n            for (const subject of subjects) {\n                // A @graph statement at the root without @id relates to the default graph,\n                // unless there are top-level properties,\n                // others relate to blank nodes.\n                const graph = depth === 1 && subject.termType === 'BlankNode'\n                    && !this.parsingContext.topLevelProperties ? this.util.getDefaultGraph() : subject;\n                this.parsingContext.emittedStack[depth] = true;\n                for (const bufferedValue of graphBuffer) {\n                    this.parsingContext.emitQuad(depth, this.util.dataFactory.quad(bufferedValue.subject, bufferedValue.predicate, bufferedValue.object, graph));\n                }\n            }\n            this.parsingContext.unidentifiedGraphsBuffer.splice(depth, 1);\n        }\n    }\n    /**\n     * Check if at least one {@link IEntryHandler} validates the entry to true.\n     * @param {any[]} keys A stack of keys.\n     * @param {number} depth A depth.\n     * @param {boolean} inProperty If the current depth is part of a valid property node.\n     * @return {Promise<{ valid: boolean, property: boolean }>} A promise resolving to true or false.\n     */\n    async validateKey(keys, depth, inProperty) {\n        for (const entryHandler of JsonLdParser.ENTRY_HANDLERS) {\n            if (await entryHandler.validate(this.parsingContext, this.util, keys, depth, inProperty)) {\n                return { valid: true, property: inProperty || entryHandler.isPropertyHandler() };\n            }\n        }\n        return { valid: false, property: false };\n    }\n    /**\n     * Attach all required listeners to the JSON parser.\n     *\n     * This should only be called once.\n     */\n    attachJsonParserListeners() {\n        // Listen to json parser events\n        this.jsonParser.onValue = (value) => {\n            const depth = this.jsonParser.stack.length;\n            const keys = (new Array(depth + 1).fill(0)).map((v, i) => {\n                return i === depth ? this.jsonParser.key : this.jsonParser.stack[i].key;\n            });\n            if (!this.isParsingContextInner(depth)) { // Don't parse inner nodes inside @context\n                const valueJobCb = () => this.newOnValueJob(keys, value, depth, true);\n                if (!this.parsingContext.streamingProfile\n                    && !this.parsingContext.contextTree.getContext(keys.slice(0, -1))) {\n                    // If an out-of-order context is allowed,\n                    // we have to buffer everything.\n                    // We store jobs for @context's and @type's separately,\n                    // because at the end, we have to process them first.\n                    // We also handle @type because these *could* introduce a type-scoped context.\n                    if (keys[depth] === '@context') {\n                        let jobs = this.contextJobs[depth];\n                        if (!jobs) {\n                            jobs = this.contextJobs[depth] = [];\n                        }\n                        jobs.push(valueJobCb);\n                    }\n                    else if (keys[depth] === '@type'\n                        || typeof keys[depth] === 'number' && keys[depth - 1] === '@type') { // Also capture @type with array values\n                        // Remove @type from keys, because we want it to apply to parent later on\n                        this.typeJobs.push({ job: valueJobCb, keys: keys.slice(0, keys.length - 1) });\n                    }\n                    else {\n                        this.contextAwaitingJobs.push({ job: valueJobCb, keys });\n                    }\n                }\n                else {\n                    // Make sure that our value jobs are chained synchronously\n                    this.lastOnValueJob = this.lastOnValueJob.then(valueJobCb);\n                }\n                // Execute all buffered jobs on deeper levels\n                if (!this.parsingContext.streamingProfile && depth === 0) {\n                    this.lastOnValueJob = this.lastOnValueJob\n                        .then(() => this.executeBufferedJobs());\n                }\n            }\n        };\n        this.jsonParser.onError = (error) => {\n            this.emit('error', error);\n        };\n    }\n    /**\n     * Check if the parser is currently parsing an element that is part of an @context entry.\n     * @param {number} depth A depth.\n     * @return {boolean} A boolean.\n     */\n    isParsingContextInner(depth) {\n        for (let i = depth; i > 0; i--) {\n            if (this.jsonParser.stack[i - 1].key === '@context') {\n                return true;\n            }\n        }\n        return false;\n    }\n    /**\n     * Execute all buffered jobs.\n     * @return {Promise<void>} A promise resolving if all jobs are finished.\n     */\n    async executeBufferedJobs() {\n        // Handle context jobs\n        for (const jobs of this.contextJobs) {\n            if (jobs) {\n                for (const job of jobs) {\n                    await job();\n                }\n            }\n        }\n        // Clear the keyword cache.\n        this.parsingContext.unaliasedKeywordCacheStack.splice(0);\n        // Handle non-context jobs\n        for (const job of this.contextAwaitingJobs) {\n            // Check if we have a type (with possible type-scoped context) that should be handled before.\n            // We check all possible parent nodes for the current job, from root to leaves.\n            if (this.typeJobs.length > 0) {\n                // First collect all applicable type jobs\n                const applicableTypeJobs = [];\n                const applicableTypeJobIds = [];\n                for (let i = 0; i < this.typeJobs.length; i++) {\n                    const typeJob = this.typeJobs[i];\n                    if (Util_1.Util.isPrefixArray(typeJob.keys, job.keys)) {\n                        applicableTypeJobs.push(typeJob);\n                        applicableTypeJobIds.push(i);\n                    }\n                }\n                // Next, sort the jobs from short to long key length (to ensure types higher up in the tree to be handled first)\n                const sortedTypeJobs = applicableTypeJobs.sort((job1, job2) => job1.keys.length - job2.keys.length);\n                // Finally, execute the jobs in order\n                for (const typeJob of sortedTypeJobs) {\n                    await typeJob.job();\n                }\n                // Remove the executed type jobs\n                // Sort first, so we can efficiently splice\n                const sortedApplicableTypeJobIds = applicableTypeJobIds.sort().reverse();\n                for (const jobId of sortedApplicableTypeJobIds) {\n                    this.typeJobs.splice(jobId, 1);\n                }\n            }\n            await job.job();\n        }\n    }\n}\nexports.JsonLdParser = JsonLdParser;\nJsonLdParser.DEFAULT_PROCESSING_MODE = '1.1';\nJsonLdParser.ENTRY_HANDLERS = [\n    new EntryHandlerArrayValue_1.EntryHandlerArrayValue(),\n    new EntryHandlerKeywordContext_1.EntryHandlerKeywordContext(),\n    new EntryHandlerKeywordId_1.EntryHandlerKeywordId(),\n    new EntryHandlerKeywordIncluded_1.EntryHandlerKeywordIncluded(),\n    new EntryHandlerKeywordGraph_1.EntryHandlerKeywordGraph(),\n    new EntryHandlerKeywordNest_1.EntryHandlerKeywordNest(),\n    new EntryHandlerKeywordType_1.EntryHandlerKeywordType(),\n    new EntryHandlerKeywordValue_1.EntryHandlerKeywordValue(),\n    new EntryHandlerContainer_1.EntryHandlerContainer(),\n    new EntryHandlerKeywordUnknownFallback_1.EntryHandlerKeywordUnknownFallback(),\n    new EntryHandlerPredicate_1.EntryHandlerPredicate(),\n    new EntryHandlerInvalidFallback_1.EntryHandlerInvalidFallback(),\n];\n//# sourceMappingURL=JsonLdParser.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.ParsingContext = void 0;\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\nconst ErrorCoded_1 = require(\"jsonld-context-parser/lib/ErrorCoded\");\nconst ContextTree_1 = require(\"./ContextTree\");\nconst JsonLdParser_1 = require(\"./JsonLdParser\");\n/**\n * Data holder for parsing information.\n */\nclass ParsingContext {\n    constructor(options) {\n        // Initialize settings\n        this.contextParser = new jsonld_context_parser_1.ContextParser({ documentLoader: options.documentLoader, skipValidation: options.skipContextValidation });\n        this.streamingProfile = !!options.streamingProfile;\n        this.baseIRI = options.baseIRI;\n        this.produceGeneralizedRdf = !!options.produceGeneralizedRdf;\n        this.allowSubjectList = !!options.allowSubjectList;\n        this.processingMode = options.processingMode || JsonLdParser_1.JsonLdParser.DEFAULT_PROCESSING_MODE;\n        this.strictValues = !!options.strictValues;\n        this.validateValueIndexes = !!options.validateValueIndexes;\n        this.defaultGraph = options.defaultGraph;\n        this.rdfDirection = options.rdfDirection;\n        this.normalizeLanguageTags = options.normalizeLanguageTags;\n        this.streamingProfileAllowOutOfOrderPlainType = options.streamingProfileAllowOutOfOrderPlainType;\n        this.topLevelProperties = false;\n        this.activeProcessingMode = parseFloat(this.processingMode);\n        // Initialize stacks\n        this.processingStack = [];\n        this.processingType = [];\n        this.emittedStack = [];\n        this.idStack = [];\n        this.graphStack = [];\n        this.graphContainerTermStack = [];\n        this.listPointerStack = [];\n        this.contextTree = new ContextTree_1.ContextTree();\n        this.literalStack = [];\n        this.validationStack = [];\n        this.unaliasedKeywordCacheStack = [];\n        this.jsonLiteralStack = [];\n        this.unidentifiedValuesBuffer = [];\n        this.unidentifiedGraphsBuffer = [];\n        this.pendingContainerFlushBuffers = [];\n        this.parser = options.parser;\n        if (options.context) {\n            this.rootContext = this.parseContext(options.context);\n            this.rootContext.then((context) => this.validateContext(context));\n        }\n        else {\n            this.rootContext = Promise.resolve(new jsonld_context_parser_1.JsonLdContextNormalized(this.baseIRI ? { '@base': this.baseIRI, '@__baseDocument': true } : {}));\n        }\n    }\n    /**\n     * Parse the given context with the configured options.\n     * @param {JsonLdContext} context A context to parse.\n     * @param {JsonLdContextNormalized} parentContext An optional parent context.\n     * @param {boolean} ignoreProtection If @protected term checks should be ignored.\n     * @return {Promise<JsonLdContextNormalized>} A promise resolving to the parsed context.\n     */\n    async parseContext(context, parentContext, ignoreProtection) {\n        return this.contextParser.parse(context, {\n            baseIRI: this.baseIRI,\n            ignoreProtection,\n            normalizeLanguageTags: this.normalizeLanguageTags,\n            parentContext,\n            processingMode: this.activeProcessingMode,\n        });\n    }\n    /**\n     * Check if the given context is valid.\n     * If not, an error will be thrown.\n     * @param {JsonLdContextNormalized} context A context.\n     */\n    validateContext(context) {\n        const activeVersion = context.getContextRaw()['@version'];\n        if (activeVersion) {\n            if (this.activeProcessingMode && activeVersion > this.activeProcessingMode) {\n                throw new ErrorCoded_1.ErrorCoded(`Unsupported JSON-LD version '${activeVersion}' under active processing mode ${this.activeProcessingMode}.`, ErrorCoded_1.ERROR_CODES.PROCESSING_MODE_CONFLICT);\n            }\n            else {\n                if (this.activeProcessingMode && activeVersion < this.activeProcessingMode) {\n                    throw new ErrorCoded_1.ErrorCoded(`Invalid JSON-LD version ${activeVersion} under active processing mode ${this.activeProcessingMode}.`, ErrorCoded_1.ERROR_CODES.INVALID_VERSION_VALUE);\n                }\n                this.activeProcessingMode = activeVersion;\n            }\n        }\n    }\n    /**\n     * Get the context at the given path.\n     * @param {keys} keys The path of keys to get the context at.\n     * @param {number} offset The path offset, defaults to 1.\n     * @return {Promise<JsonLdContextNormalized>} A promise resolving to a context.\n     */\n    async getContext(keys, offset = 1) {\n        const keysOriginal = keys;\n        // Ignore array keys at the end\n        while (typeof keys[keys.length - 1] === 'number') {\n            keys = keys.slice(0, keys.length - 1);\n        }\n        // Handle offset on keys\n        if (offset) {\n            keys = keys.slice(0, -offset);\n        }\n        // Determine the closest context\n        const contextData = await this.getContextPropagationAware(keys);\n        const context = contextData.context;\n        // Process property-scoped contexts (high-to-low)\n        let contextRaw = context.getContextRaw();\n        for (let i = contextData.depth; i < keysOriginal.length - offset; i++) {\n            const key = keysOriginal[i];\n            const contextKeyEntry = contextRaw[key];\n            if (contextKeyEntry && typeof contextKeyEntry === 'object' && '@context' in contextKeyEntry) {\n                const scopedContext = (await this.parseContext(contextKeyEntry, contextRaw, true)).getContextRaw();\n                const propagate = !(key in scopedContext)\n                    || scopedContext[key]['@context']['@propagate']; // Propagation is true by default\n                if (propagate !== false || i === keysOriginal.length - 1 - offset) {\n                    contextRaw = scopedContext;\n                    // Clean up final context\n                    delete contextRaw['@propagate'];\n                    contextRaw[key] = Object.assign({}, contextRaw[key]);\n                    if ('@id' in contextKeyEntry) {\n                        contextRaw[key]['@id'] = contextKeyEntry['@id'];\n                    }\n                    delete contextRaw[key]['@context'];\n                    if (propagate !== false) {\n                        this.contextTree.setContext(keysOriginal.slice(0, i + offset), Promise.resolve(new jsonld_context_parser_1.JsonLdContextNormalized(contextRaw)));\n                    }\n                }\n            }\n        }\n        return new jsonld_context_parser_1.JsonLdContextNormalized(contextRaw);\n    }\n    /**\n     * Get the context at the given path.\n     * Non-propagating contexts will be skipped,\n     * unless the context at that exact depth is retrieved.\n     *\n     * This ONLY takes into account context propagation logic,\n     * so this should usually not be called directly,\n     * call {@link #getContext} instead.\n     *\n     * @param keys The path of keys to get the context at.\n     * @return {Promise<{ context: JsonLdContextNormalized, depth: number }>} A context and its depth.\n     */\n    async getContextPropagationAware(keys) {\n        const originalDepth = keys.length;\n        let contextData = null;\n        let hasApplicablePropertyScopedContext;\n        do {\n            hasApplicablePropertyScopedContext = false;\n            if (contextData && '@__propagateFallback' in contextData.context.getContextRaw()) {\n                // If a propagation fallback context has been set,\n                // fallback to that context and retry for the same depth.\n                contextData.context = new jsonld_context_parser_1.JsonLdContextNormalized(contextData.context.getContextRaw()['@__propagateFallback']);\n            }\n            else {\n                if (contextData) {\n                    // If we had a previous iteration, jump to the parent of context depth.\n                    // We must do this because once we get here, last context had propagation disabled,\n                    // so we check its first parent instead.\n                    keys = keys.slice(0, contextData.depth - 1);\n                }\n                contextData = await this.contextTree.getContext(keys) || { context: await this.rootContext, depth: 0 };\n            }\n            // Allow non-propagating contexts to propagate one level deeper\n            // if it defines a property-scoped context that is applicable for the current key.\n            // @see https://w3c.github.io/json-ld-api/tests/toRdf-manifest#tc012\n            const lastKey = keys[keys.length - 1];\n            if (lastKey in contextData.context.getContextRaw()) {\n                const lastKeyValue = contextData.context.getContextRaw()[lastKey];\n                if (lastKeyValue && typeof lastKeyValue === 'object' && '@context' in lastKeyValue) {\n                    hasApplicablePropertyScopedContext = true;\n                }\n            }\n        } while (contextData.depth > 0 // Root context has a special case\n            && contextData.context.getContextRaw()['@propagate'] === false // Stop loop if propagation is true\n            && contextData.depth !== originalDepth // Stop loop if requesting exact depth of non-propagating\n            && !hasApplicablePropertyScopedContext);\n        // Special case for root context that does not allow propagation.\n        // Fallback to empty context in that case.\n        if (contextData.depth === 0\n            && contextData.context.getContextRaw()['@propagate'] === false\n            && contextData.depth !== originalDepth) {\n            contextData.context = new jsonld_context_parser_1.JsonLdContextNormalized({});\n        }\n        return contextData;\n    }\n    /**\n     * Start a new job for parsing the given value.\n     * @param {any[]} keys The stack of keys.\n     * @param value The value to parse.\n     * @param {number} depth The depth to parse at.\n     * @param {boolean} lastDepthCheck If the lastDepth check should be done for buffer draining.\n     * @return {Promise<void>} A promise resolving when the job is done.\n     */\n    async newOnValueJob(keys, value, depth, lastDepthCheck) {\n        await this.parser.newOnValueJob(keys, value, depth, lastDepthCheck);\n    }\n    /**\n     * Flush the pending container flush buffers\n     * @return {boolean} If any pending buffers were flushed.\n     */\n    async handlePendingContainerFlushBuffers() {\n        if (this.pendingContainerFlushBuffers.length > 0) {\n            for (const pendingFlushBuffer of this.pendingContainerFlushBuffers) {\n                await this.parser.flushBuffer(pendingFlushBuffer.depth, pendingFlushBuffer.keys);\n                this.parser.flushStacks(pendingFlushBuffer.depth);\n            }\n            this.pendingContainerFlushBuffers.splice(0, this.pendingContainerFlushBuffers.length);\n            return true;\n        }\n        else {\n            return false;\n        }\n    }\n    /**\n     * Emit the given quad into the output stream.\n     * @param {number} depth The depth the quad was generated at.\n     * @param {Quad} quad A quad to emit.\n     */\n    emitQuad(depth, quad) {\n        if (depth === 1) {\n            this.topLevelProperties = true;\n        }\n        this.parser.push(quad);\n    }\n    /**\n     * Emit the given error into the output stream.\n     * @param {Error} error An error to emit.\n     */\n    emitError(error) {\n        this.parser.emit('error', error);\n    }\n    /**\n     * Emit the given context into the output stream under the 'context' event.\n     * @param {JsonLdContext} context A context to emit.\n     */\n    emitContext(context) {\n        this.parser.emit('context', context);\n    }\n    /**\n     * Safely get or create the depth value of {@link ParsingContext.unidentifiedValuesBuffer}.\n     * @param {number} depth A depth.\n     * @return {{predicate: Term; object: Term; reverse: boolean}[]} An element of\n     *                                                               {@link ParsingContext.unidentifiedValuesBuffer}.\n     */\n    getUnidentifiedValueBufferSafe(depth) {\n        let buffer = this.unidentifiedValuesBuffer[depth];\n        if (!buffer) {\n            buffer = [];\n            this.unidentifiedValuesBuffer[depth] = buffer;\n        }\n        return buffer;\n    }\n    /**\n     * Safely get or create the depth value of {@link ParsingContext.unidentifiedGraphsBuffer}.\n     * @param {number} depth A depth.\n     * @return {{predicate: Term; object: Term; reverse: boolean}[]} An element of\n     *                                                               {@link ParsingContext.unidentifiedGraphsBuffer}.\n     */\n    getUnidentifiedGraphBufferSafe(depth) {\n        let buffer = this.unidentifiedGraphsBuffer[depth];\n        if (!buffer) {\n            buffer = [];\n            this.unidentifiedGraphsBuffer[depth] = buffer;\n        }\n        return buffer;\n    }\n    /**\n     * @return IExpandOptions The expand options for the active processing mode.\n     */\n    getExpandOptions() {\n        return ParsingContext.EXPAND_OPTIONS[this.activeProcessingMode];\n    }\n    /**\n     * Shift the stack at the given offset to the given depth.\n     *\n     * This will override anything in the stack at `depth`,\n     * and this will remove anything at `depth + depthOffset`\n     *\n     * @param depth The target depth.\n     * @param depthOffset The origin depth, relative to `depth`.\n     */\n    shiftStack(depth, depthOffset) {\n        // Copy the id stack value up one level so that the next job can access the id.\n        const deeperIdStack = this.idStack[depth + depthOffset];\n        if (deeperIdStack) {\n            this.idStack[depth] = deeperIdStack;\n            this.emittedStack[depth] = true;\n            delete this.idStack[depth + depthOffset];\n        }\n        // Shorten key stack\n        if (this.pendingContainerFlushBuffers.length) {\n            for (const buffer of this.pendingContainerFlushBuffers) {\n                if (buffer.depth >= depth + depthOffset) {\n                    buffer.depth -= depthOffset;\n                    buffer.keys.splice(depth, depthOffset);\n                }\n            }\n        }\n        // Splice stacks\n        if (this.unidentifiedValuesBuffer[depth + depthOffset]) {\n            this.unidentifiedValuesBuffer[depth] = this.unidentifiedValuesBuffer[depth + depthOffset];\n            delete this.unidentifiedValuesBuffer[depth + depthOffset];\n        }\n        // TODO: also do the same for other stacks\n    }\n}\nexports.ParsingContext = ParsingContext;\nParsingContext.EXPAND_OPTIONS = {\n    1.0: {\n        allowPrefixForcing: false,\n        allowPrefixNonGenDelims: false,\n        allowVocabRelativeToBase: false,\n    },\n    1.1: {\n        allowPrefixForcing: true,\n        allowPrefixNonGenDelims: false,\n        allowVocabRelativeToBase: true,\n    },\n};\n//# sourceMappingURL=ParsingContext.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.Util = void 0;\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\nconst rdf_data_factory_1 = require(\"rdf-data-factory\");\nconst EntryHandlerContainer_1 = require(\"./entryhandler/EntryHandlerContainer\");\n// tslint:disable-next-line:no-var-requires\nconst canonicalizeJson = require('canonicalize');\n/**\n * Utility functions and methods.\n */\nclass Util {\n    constructor(options) {\n        this.parsingContext = options.parsingContext;\n        this.dataFactory = options.dataFactory || new rdf_data_factory_1.DataFactory();\n        this.rdfFirst = this.dataFactory.namedNode(Util.RDF + 'first');\n        this.rdfRest = this.dataFactory.namedNode(Util.RDF + 'rest');\n        this.rdfNil = this.dataFactory.namedNode(Util.RDF + 'nil');\n        this.rdfType = this.dataFactory.namedNode(Util.RDF + 'type');\n        this.rdfJson = this.dataFactory.namedNode(Util.RDF + 'JSON');\n    }\n    /**\n     * Helper function to get the value of a context entry,\n     * or fallback to a certain value.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param {string} contextKey A pre-defined JSON-LD key in context entries.\n     * @param {string} key A context entry key.\n     * @param {string} fallback A fallback value for when the given contextKey\n     *                          could not be found in the value with the given key.\n     * @return {string} The value of the given contextKey in the entry behind key in the given context,\n     *                  or the given fallback value.\n     */\n    static getContextValue(context, contextKey, key, fallback) {\n        const entry = context.getContextRaw()[key];\n        if (!entry) {\n            return fallback;\n        }\n        const type = entry[contextKey];\n        return type === undefined ? fallback : type;\n    }\n    /**\n     * Get the container type of the given key in the context.\n     *\n     * Should any context-scoping bugs should occur related to this in the future,\n     * it may be required to increase the offset from the depth at which the context is retrieved by one (to 2).\n     * This is because containers act 2 levels deep.\n     *\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param {string} key A context entry key.\n     * @return {string} The container type.\n     */\n    static getContextValueContainer(context, key) {\n        return Util.getContextValue(context, '@container', key, { '@set': true });\n    }\n    /**\n     * Get the value type of the given key in the context.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param {string} key A context entry key.\n     * @return {string} The node type.\n     */\n    static getContextValueType(context, key) {\n        const valueType = Util.getContextValue(context, '@type', key, null);\n        if (valueType === '@none') {\n            return null;\n        }\n        return valueType;\n    }\n    /**\n     * Get the language of the given key in the context.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param {string} key A context entry key.\n     * @return {string} The node type.\n     */\n    static getContextValueLanguage(context, key) {\n        return Util.getContextValue(context, '@language', key, context.getContextRaw()['@language'] || null);\n    }\n    /**\n     * Get the direction of the given key in the context.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param {string} key A context entry key.\n     * @return {string} The node type.\n     */\n    static getContextValueDirection(context, key) {\n        return Util.getContextValue(context, '@direction', key, context.getContextRaw()['@direction'] || null);\n    }\n    /**\n     * Check if the given key in the context is a reversed property.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param {string} key A context entry key.\n     * @return {boolean} If the context value has a @reverse key.\n     */\n    static isContextValueReverse(context, key) {\n        return !!Util.getContextValue(context, '@reverse', key, null);\n    }\n    /**\n     * Get the @index of the given key in the context.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param {string} key A context entry key.\n     * @return {string} The index.\n     */\n    static getContextValueIndex(context, key) {\n        return Util.getContextValue(context, '@index', key, context.getContextRaw()['@index'] || null);\n    }\n    /**\n     * Check if the given key refers to a reversed property.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param {string} key The property key.\n     * @param {string} parentKey The parent key.\n     * @return {boolean} If the property must be reversed.\n     */\n    static isPropertyReverse(context, key, parentKey) {\n        // '!==' is needed because reversed properties in a @reverse container should cancel each other out.\n        return parentKey === '@reverse' !== Util.isContextValueReverse(context, key);\n    }\n    /**\n     * Check if the given IRI is valid.\n     * @param {string} iri A potential IRI.\n     * @return {boolean} If the given IRI is valid.\n     */\n    static isValidIri(iri) {\n        return iri !== null && jsonld_context_parser_1.Util.isValidIri(iri);\n    }\n    /**\n     * Check if the given first array (needle) is a prefix of the given second array (haystack).\n     * @param needle An array to check if it is a prefix.\n     * @param haystack An array to look in.\n     */\n    static isPrefixArray(needle, haystack) {\n        if (needle.length > haystack.length) {\n            return false;\n        }\n        for (let i = 0; i < needle.length; i++) {\n            if (needle[i] !== haystack[i]) {\n                return false;\n            }\n        }\n        return true;\n    }\n    /**\n     * Make sure that @id-@index pairs are equal over all array values.\n     * Reject otherwise.\n     * @param {any[]} value An array value.\n     * @return {Promise<void>} A promise rejecting if conflicts are present.\n     */\n    async validateValueIndexes(value) {\n        if (this.parsingContext.validateValueIndexes) {\n            const indexHashes = {};\n            for (const entry of value) {\n                if (entry && typeof entry === 'object') {\n                    const id = entry['@id'];\n                    const index = entry['@index'];\n                    if (id && index) {\n                        const existingIndexValue = indexHashes[id];\n                        if (existingIndexValue && existingIndexValue !== index) {\n                            throw new jsonld_context_parser_1.ErrorCoded(`Conflicting @index value for ${id}`, jsonld_context_parser_1.ERROR_CODES.CONFLICTING_INDEXES);\n                        }\n                        indexHashes[id] = index;\n                    }\n                }\n            }\n        }\n    }\n    /**\n     * Convert a given JSON value to an RDF term.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param {string} key The current JSON key.\n     * @param value A JSON value.\n     * @param {number} depth The depth the value is at.\n     * @param {string[]} keys The path of keys.\n     * @return {Promise<RDF.Term[]>} An RDF term array.\n     */\n    async valueToTerm(context, key, value, depth, keys) {\n        // Skip further processing if we have an @type: @json\n        if (Util.getContextValueType(context, key) === '@json') {\n            return [this.dataFactory.literal(this.valueToJsonString(value), this.rdfJson)];\n        }\n        const type = typeof value;\n        switch (type) {\n            case 'object':\n                // Skip if we have a null or undefined object\n                if (value === null || value === undefined) {\n                    return [];\n                }\n                // Special case for arrays\n                if (Array.isArray(value)) {\n                    // We handle arrays at value level so we can emit earlier, so this is handled already when we get here.\n                    // Empty context-based lists are emitted at this place, because our streaming algorithm doesn't detect those.\n                    if ('@list' in Util.getContextValueContainer(context, key)) {\n                        if (value.length === 0) {\n                            return [this.rdfNil];\n                        }\n                        else {\n                            return this.parsingContext.idStack[depth + 1] || [];\n                        }\n                    }\n                    await this.validateValueIndexes(value);\n                    return [];\n                }\n                // Handle property-scoped contexts\n                context = await this.getContextSelfOrPropertyScoped(context, key);\n                // Handle local context in the value\n                if ('@context' in value) {\n                    context = await this.parsingContext.parseContext(value['@context'], (await this.parsingContext.getContext(keys, 0)).getContextRaw());\n                }\n                // In all other cases, we have a hash\n                value = await this.unaliasKeywords(value, keys, depth, context); // Un-alias potential keywords in this hash\n                if ('@value' in value) {\n                    let val;\n                    let valueLanguage;\n                    let valueDirection;\n                    let valueType;\n                    let valueIndex; // We don't use the index, but we need to check its type for spec-compliance\n                    for (key in value) {\n                        const subValue = value[key];\n                        switch (key) {\n                            case '@value':\n                                val = subValue;\n                                break;\n                            case '@language':\n                                valueLanguage = subValue;\n                                break;\n                            case '@direction':\n                                valueDirection = subValue;\n                                break;\n                            case '@type':\n                                valueType = subValue;\n                                break;\n                            case '@index':\n                                valueIndex = subValue;\n                                break;\n                            default:\n                                throw new jsonld_context_parser_1.ErrorCoded(`Unknown value entry '${key}' in @value: ${JSON.stringify(value)}`, jsonld_context_parser_1.ERROR_CODES.INVALID_VALUE_OBJECT);\n                        }\n                    }\n                    // Skip further processing if we have an @type: @json\n                    if (await this.unaliasKeyword(valueType, keys, depth, true, context) === '@json') {\n                        return [this.dataFactory.literal(this.valueToJsonString(val), this.rdfJson)];\n                    }\n                    // Validate @value\n                    if (val === null) {\n                        return [];\n                    }\n                    if (typeof val === 'object') {\n                        throw new jsonld_context_parser_1.ErrorCoded(`The value of an '@value' can not be an object, got '${JSON.stringify(val)}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_VALUE_OBJECT_VALUE);\n                    }\n                    // Validate @index\n                    if (this.parsingContext.validateValueIndexes && valueIndex && typeof valueIndex !== 'string') {\n                        throw new jsonld_context_parser_1.ErrorCoded(`The value of an '@index' must be a string, got '${JSON.stringify(valueIndex)}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_INDEX_VALUE);\n                    }\n                    // Validate @language and @direction\n                    if (valueLanguage) {\n                        if (typeof val !== 'string') {\n                            throw new jsonld_context_parser_1.ErrorCoded(`When an '@language' is set, the value of '@value' must be a string, got '${JSON.stringify(val)}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_LANGUAGE_TAGGED_VALUE);\n                        }\n                        if (!jsonld_context_parser_1.ContextParser.validateLanguage(valueLanguage, this.parsingContext.strictValues, jsonld_context_parser_1.ERROR_CODES.INVALID_LANGUAGE_TAGGED_STRING)) {\n                            return [];\n                        }\n                        // Language tags are always normalized to lowercase in 1.0.\n                        if (this.parsingContext.normalizeLanguageTags || this.parsingContext.activeProcessingMode === 1.0) {\n                            valueLanguage = valueLanguage.toLowerCase();\n                        }\n                    }\n                    if (valueDirection) {\n                        if (typeof val !== 'string') {\n                            throw new Error(`When an '@direction' is set, the value of '@value' must be a string, got '${JSON.stringify(val)}'`);\n                        }\n                        if (!jsonld_context_parser_1.ContextParser.validateDirection(valueDirection, this.parsingContext.strictValues)) {\n                            return [];\n                        }\n                    }\n                    // Check @language and @direction\n                    if (valueLanguage && valueDirection && this.parsingContext.rdfDirection) {\n                        if (valueType) {\n                            throw new jsonld_context_parser_1.ErrorCoded(`Can not have '@language', '@direction' and '@type' in a value: '${JSON\n                                .stringify(value)}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_VALUE_OBJECT);\n                        }\n                        return this.nullableTermToArray(this\n                            .createLanguageDirectionLiteral(depth, val, valueLanguage, valueDirection));\n                    }\n                    else if (valueLanguage) { // Check @language\n                        if (valueType) {\n                            throw new jsonld_context_parser_1.ErrorCoded(`Can not have both '@language' and '@type' in a value: '${JSON.stringify(value)}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_VALUE_OBJECT);\n                        }\n                        return [this.dataFactory.literal(val, valueLanguage)];\n                    }\n                    else if (valueDirection && this.parsingContext.rdfDirection) { // Check @direction\n                        if (valueType) {\n                            throw new jsonld_context_parser_1.ErrorCoded(`Can not have both '@direction' and '@type' in a value: '${JSON.stringify(value)}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_VALUE_OBJECT);\n                        }\n                        return this.nullableTermToArray(this\n                            .createLanguageDirectionLiteral(depth, val, valueLanguage, valueDirection));\n                    }\n                    else if (valueType) { // Validate @type\n                        if (typeof valueType !== 'string') {\n                            throw new jsonld_context_parser_1.ErrorCoded(`The value of an '@type' must be a string, got '${JSON.stringify(valueType)}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_TYPED_VALUE);\n                        }\n                        const typeTerm = this.createVocabOrBaseTerm(context, valueType);\n                        if (!typeTerm) {\n                            throw new jsonld_context_parser_1.ErrorCoded(`Invalid '@type' value, got '${JSON.stringify(valueType)}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_TYPED_VALUE);\n                        }\n                        if (typeTerm.termType !== 'NamedNode') {\n                            throw new jsonld_context_parser_1.ErrorCoded(`Illegal value type (${typeTerm.termType}): ${valueType}`, jsonld_context_parser_1.ERROR_CODES.INVALID_TYPED_VALUE);\n                        }\n                        return [this.dataFactory.literal(val, typeTerm)];\n                    }\n                    // We don't pass the context, because context-based things like @language should be ignored\n                    return await this.valueToTerm(new jsonld_context_parser_1.JsonLdContextNormalized({}), key, val, depth, keys);\n                }\n                else if ('@set' in value) {\n                    // No other entries are allow in this value\n                    if (Object.keys(value).length > 1) {\n                        throw new jsonld_context_parser_1.ErrorCoded(`Found illegal neighbouring entries next to @set for key: '${key}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_SET_OR_LIST_OBJECT);\n                    }\n                    // No need to do anything here, this is handled at the deeper level.\n                    return [];\n                }\n                else if ('@list' in value) {\n                    // No other entries are allowed in this value\n                    if (Object.keys(value).length > 1) {\n                        throw new jsonld_context_parser_1.ErrorCoded(`Found illegal neighbouring entries next to @list for key: '${key}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_SET_OR_LIST_OBJECT);\n                    }\n                    const listValue = value[\"@list\"];\n                    // We handle lists at value level so we can emit earlier, so this is handled already when we get here.\n                    // Empty anonymous lists are emitted at this place, because our streaming algorithm doesn't detect those.\n                    if (Array.isArray(listValue)) {\n                        if (listValue.length === 0) {\n                            return [this.rdfNil];\n                        }\n                        else {\n                            return this.parsingContext.idStack[depth + 1] || [];\n                        }\n                    }\n                    else {\n                        // We only have a single list element here, so emit this directly as single element\n                        return await this.valueToTerm(await this.parsingContext.getContext(keys), key, listValue, depth - 1, keys.slice(0, -1));\n                    }\n                }\n                else if ('@reverse' in value && typeof value['@reverse'] === 'boolean') {\n                    // We handle reverse properties at value level so we can emit earlier,\n                    // so this is handled already when we get here.\n                    return [];\n                }\n                else if ('@graph' in Util.getContextValueContainer(await this.parsingContext.getContext(keys), key)) {\n                    // We are processing a graph container\n                    const graphContainerEntries = this.parsingContext.graphContainerTermStack[depth + 1];\n                    return graphContainerEntries ? Object.values(graphContainerEntries) : [this.dataFactory.blankNode()];\n                }\n                else if (\"@id\" in value) {\n                    // Use deeper context if the value node contains other properties next to @id.\n                    if (Object.keys(value).length > 1) {\n                        context = await this.parsingContext.getContext(keys, 0);\n                    }\n                    // Handle local context in the value\n                    if ('@context' in value) {\n                        context = await this.parsingContext.parseContext(value['@context'], context.getContextRaw());\n                    }\n                    if (value[\"@type\"] === '@vocab') {\n                        return this.nullableTermToArray(this.createVocabOrBaseTerm(context, value[\"@id\"]));\n                    }\n                    else {\n                        return this.nullableTermToArray(this.resourceToTerm(context, value[\"@id\"]));\n                    }\n                }\n                else {\n                    // Only make a blank node if at least one triple was emitted at the value's level.\n                    if (this.parsingContext.emittedStack[depth + 1]\n                        || (value && typeof value === 'object' && Object.keys(value).length === 0)) {\n                        return (this.parsingContext.idStack[depth + 1]\n                            || (this.parsingContext.idStack[depth + 1] = [this.dataFactory.blankNode()]));\n                    }\n                    else {\n                        return [];\n                    }\n                }\n            case 'string':\n                return this.nullableTermToArray(this.stringValueToTerm(depth, await this.getContextSelfOrPropertyScoped(context, key), key, value, null));\n            case 'boolean':\n                return this.nullableTermToArray(this.stringValueToTerm(depth, await this.getContextSelfOrPropertyScoped(context, key), key, Boolean(value).toString(), this.dataFactory.namedNode(Util.XSD_BOOLEAN)));\n            case 'number':\n                return this.nullableTermToArray(this.stringValueToTerm(depth, await this.getContextSelfOrPropertyScoped(context, key), key, value, this.dataFactory.namedNode(value % 1 === 0 && value < 1e21 ? Util.XSD_INTEGER : Util.XSD_DOUBLE)));\n            default:\n                this.parsingContext.emitError(new Error(`Could not determine the RDF type of a ${type}`));\n                return [];\n        }\n    }\n    /**\n     * If the context defines a property-scoped context for the given key,\n     * that context will be returned.\n     * Otherwise, the given context will be returned as-is.\n     *\n     * This should be used for valueToTerm cases that are not objects.\n     * @param context A context.\n     * @param key A JSON key.\n     */\n    async getContextSelfOrPropertyScoped(context, key) {\n        const contextKeyEntry = context.getContextRaw()[key];\n        if (contextKeyEntry && typeof contextKeyEntry === 'object' && '@context' in contextKeyEntry) {\n            context = await this.parsingContext.parseContext(contextKeyEntry, context.getContextRaw(), true);\n        }\n        return context;\n    }\n    /**\n     * If the given term is null, return an empty array, otherwise return an array with the single given term.\n     * @param term A term.\n     */\n    nullableTermToArray(term) {\n        return term ? [term] : [];\n    }\n    /**\n     * Convert a given JSON key to an RDF predicate term,\n     * based on @vocab.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param key A JSON key.\n     * @return {RDF.NamedNode} An RDF named node.\n     */\n    predicateToTerm(context, key) {\n        const expanded = context.expandTerm(key, true, this.parsingContext.getExpandOptions());\n        // Immediately return if the predicate was disabled in the context\n        if (!expanded) {\n            return null;\n        }\n        // Check if the predicate is a blank node\n        if (expanded[0] === '_' && expanded[1] === ':') {\n            if (this.parsingContext.produceGeneralizedRdf) {\n                return this.dataFactory.blankNode(expanded.substr(2));\n            }\n            else {\n                return null;\n            }\n        }\n        // Check if the predicate is a valid IRI\n        if (Util.isValidIri(expanded)) {\n            return this.dataFactory.namedNode(expanded);\n        }\n        else {\n            if (expanded && this.parsingContext.strictValues) {\n                this.parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Invalid predicate IRI: ${expanded}`, jsonld_context_parser_1.ERROR_CODES.INVALID_IRI_MAPPING));\n            }\n            else {\n                return null;\n            }\n        }\n        return null;\n    }\n    /**\n     * Convert a given JSON key to an RDF resource term or blank node,\n     * based on @base.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param key A JSON key.\n     * @return {RDF.NamedNode} An RDF named node or null.\n     */\n    resourceToTerm(context, key) {\n        if (key.startsWith('_:')) {\n            return this.dataFactory.blankNode(key.substr(2));\n        }\n        const iri = context.expandTerm(key, false, this.parsingContext.getExpandOptions());\n        if (!Util.isValidIri(iri)) {\n            if (iri && this.parsingContext.strictValues) {\n                this.parsingContext.emitError(new Error(`Invalid resource IRI: ${iri}`));\n            }\n            else {\n                return null;\n            }\n        }\n        return this.dataFactory.namedNode(iri);\n    }\n    /**\n     * Convert a given JSON key to an RDF resource term.\n     * It will do this based on the @vocab,\n     * and fallback to @base.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param key A JSON key.\n     * @return {RDF.NamedNode} An RDF named node or null.\n     */\n    createVocabOrBaseTerm(context, key) {\n        if (key.startsWith('_:')) {\n            return this.dataFactory.blankNode(key.substr(2));\n        }\n        const expandOptions = this.parsingContext.getExpandOptions();\n        let expanded = context.expandTerm(key, true, expandOptions);\n        if (expanded === key) {\n            expanded = context.expandTerm(key, false, expandOptions);\n        }\n        if (!Util.isValidIri(expanded)) {\n            if (expanded && this.parsingContext.strictValues && !expanded.startsWith('@')) {\n                this.parsingContext.emitError(new Error(`Invalid term IRI: ${expanded}`));\n            }\n            else {\n                return null;\n            }\n        }\n        return this.dataFactory.namedNode(expanded);\n    }\n    /**\n     * Ensure that the given value becomes a string.\n     * @param {string | number} value A string or number.\n     * @param {NamedNode} datatype The intended datatype.\n     * @return {string} The returned string.\n     */\n    intToString(value, datatype) {\n        if (typeof value === 'number') {\n            if (Number.isFinite(value)) {\n                const isInteger = value % 1 === 0;\n                if (isInteger && (!datatype || datatype.value !== Util.XSD_DOUBLE)) {\n                    return Number(value).toString();\n                }\n                else {\n                    return value.toExponential(15).replace(/(\\d)0*e\\+?/, '$1E');\n                }\n            }\n            else {\n                return value > 0 ? 'INF' : '-INF';\n            }\n        }\n        else {\n            return value;\n        }\n    }\n    /**\n     * Convert a given JSON string value to an RDF term.\n     * @param {number} depth The current stack depth.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param {string} key The current JSON key.\n     * @param {string} value A JSON value.\n     * @param {NamedNode} defaultDatatype The default datatype for the given value.\n     * @return {RDF.Term} An RDF term or null.\n     */\n    stringValueToTerm(depth, context, key, value, defaultDatatype) {\n        // Check the datatype from the context\n        const contextType = Util.getContextValueType(context, key);\n        if (contextType) {\n            if (contextType === '@id') {\n                if (!defaultDatatype) {\n                    return this.resourceToTerm(context, this.intToString(value, defaultDatatype));\n                }\n            }\n            else if (contextType === '@vocab') {\n                if (!defaultDatatype) {\n                    return this.createVocabOrBaseTerm(context, this.intToString(value, defaultDatatype));\n                }\n            }\n            else {\n                defaultDatatype = this.dataFactory.namedNode(contextType);\n            }\n        }\n        // If we don't find such a datatype, check the language from the context\n        if (!defaultDatatype) {\n            const contextLanguage = Util.getContextValueLanguage(context, key);\n            const contextDirection = Util.getContextValueDirection(context, key);\n            if (contextDirection && this.parsingContext.rdfDirection) {\n                return this.createLanguageDirectionLiteral(depth, this.intToString(value, defaultDatatype), contextLanguage, contextDirection);\n            }\n            else {\n                return this.dataFactory.literal(this.intToString(value, defaultDatatype), contextLanguage);\n            }\n        }\n        // If all else fails, make a literal based on the default content type\n        return this.dataFactory.literal(this.intToString(value, defaultDatatype), defaultDatatype);\n    }\n    /**\n     * Create a literal for the given value with the given language and direction.\n     * Auxiliary quads may be emitted.\n     * @param {number} depth The current stack depth.\n     * @param {string} value A string value.\n     * @param {string} language A language tag.\n     * @param {string} direction A direction.\n     * @return {Term} An RDF term.\n     */\n    createLanguageDirectionLiteral(depth, value, language, direction) {\n        if (this.parsingContext.rdfDirection === 'i18n-datatype') {\n            // Create a datatyped literal, by encoding the language and direction into https://www.w3.org/ns/i18n#.\n            if (!language) {\n                language = '';\n            }\n            return this.dataFactory.literal(value, this.dataFactory.namedNode(`https://www.w3.org/ns/i18n#${language}_${direction}`));\n        }\n        else {\n            // Reify the literal.\n            const valueNode = this.dataFactory.blankNode();\n            const graph = this.getDefaultGraph();\n            this.parsingContext.emitQuad(depth, this.dataFactory.quad(valueNode, this.dataFactory.namedNode(Util.RDF + 'value'), this.dataFactory.literal(value), graph));\n            if (language) {\n                this.parsingContext.emitQuad(depth, this.dataFactory.quad(valueNode, this.dataFactory.namedNode(Util.RDF + 'language'), this.dataFactory.literal(language), graph));\n            }\n            this.parsingContext.emitQuad(depth, this.dataFactory.quad(valueNode, this.dataFactory.namedNode(Util.RDF + 'direction'), this.dataFactory.literal(direction), graph));\n            return valueNode;\n        }\n    }\n    /**\n     * Stringify the given JSON object to a canonical JSON string.\n     * @param value Any valid JSON value.\n     * @return {string} A canonical JSON string.\n     */\n    valueToJsonString(value) {\n        return canonicalizeJson(value);\n    }\n    /**\n     * If the key is not a keyword, try to check if it is an alias for a keyword,\n     * and if so, un-alias it.\n     * @param {string} key A key, can be falsy.\n     * @param {string[]} keys The path of keys.\n     * @param {number} depth The depth to\n     * @param {boolean} disableCache If the cache should be disabled\n     * @param {JsonLdContextNormalized} context A context to unalias with,\n     *                                           will fallback to retrieving the context for the given keys.\n     * @return {Promise<string>} A promise resolving to the key itself, or another key.\n     */\n    async unaliasKeyword(key, keys, depth, disableCache, context) {\n        // Numbers can not be an alias\n        if (Number.isInteger(key)) {\n            return key;\n        }\n        // Try to grab from cache if it was already un-aliased before.\n        if (!disableCache) {\n            const cachedUnaliasedKeyword = this.parsingContext.unaliasedKeywordCacheStack[depth];\n            if (cachedUnaliasedKeyword) {\n                return cachedUnaliasedKeyword;\n            }\n        }\n        if (!jsonld_context_parser_1.Util.isPotentialKeyword(key)) {\n            context = context || await this.parsingContext.getContext(keys);\n            let unliased = context.getContextRaw()[key];\n            if (unliased && typeof unliased === 'object') {\n                unliased = unliased['@id'];\n            }\n            if (jsonld_context_parser_1.Util.isValidKeyword(unliased)) {\n                key = unliased;\n            }\n        }\n        return disableCache ? key : (this.parsingContext.unaliasedKeywordCacheStack[depth] = key);\n    }\n    /**\n     * Unalias the keyword of the parent.\n     * This adds a safety check if no parent exist.\n     * @param {any[]} keys A stack of keys.\n     * @param {number} depth The current depth.\n     * @return {Promise<any>} A promise resolving to the parent key, or another key.\n     */\n    async unaliasKeywordParent(keys, depth) {\n        return await this.unaliasKeyword(depth > 0 && keys[depth - 1], keys, depth - 1);\n    }\n    /**\n     * Un-alias all keywords in the given hash.\n     * @param {{[p: string]: any}} hash A hash object.\n     * @param {string[]} keys The path of keys.\n     * @param {number} depth The depth.\n     * @param {JsonLdContextNormalized} context A context to unalias with,\n     *                                           will fallback to retrieving the context for the given keys.\n     * @return {Promise<{[p: string]: any}>} A promise resolving to the new hash.\n     */\n    async unaliasKeywords(hash, keys, depth, context) {\n        const newHash = {};\n        for (const key in hash) {\n            newHash[await this.unaliasKeyword(key, keys, depth + 1, true, context)] = hash[key];\n        }\n        return newHash;\n    }\n    /**\n     * Check if we are processing a literal (including JSON literals) at the given depth.\n     * This will also check higher levels,\n     * because if a parent is a literal,\n     * then the deeper levels are definitely a literal as well.\n     * @param {number} depth The depth.\n     * @return {boolean} If we are processing a literal.\n     */\n    isLiteral(depth) {\n        for (let i = depth; i >= 0; i--) {\n            if (this.parsingContext.literalStack[i] || this.parsingContext.jsonLiteralStack[i]) {\n                return true;\n            }\n        }\n        return false;\n    }\n    /**\n     * Check how many parents should be skipped for checking the @graph for the given node.\n     *\n     * @param {number} depth The depth of the node.\n     * @param {any[]} keys An array of keys.\n     * @return {number} The graph depth offset.\n     */\n    async getDepthOffsetGraph(depth, keys) {\n        for (let i = depth - 1; i > 0; i--) {\n            if (await this.unaliasKeyword(keys[i], keys, i) === '@graph') {\n                // Skip further processing if we are already in an @graph-@id or @graph-@index container\n                const containers = (await EntryHandlerContainer_1.EntryHandlerContainer.getContainerHandler(this.parsingContext, keys, i)).containers;\n                if (EntryHandlerContainer_1.EntryHandlerContainer.isComplexGraphContainer(containers)) {\n                    return -1;\n                }\n                return depth - i - 1;\n            }\n        }\n        return -1;\n    }\n    /**\n     * Check if the given subject is of a valid type.\n     * This should be called when applying @reverse'd properties.\n     * @param {Term} subject A subject.\n     */\n    validateReverseSubject(subject) {\n        if (subject.termType === 'Literal') {\n            throw new jsonld_context_parser_1.ErrorCoded(`Found illegal literal in subject position: ${subject.value}`, jsonld_context_parser_1.ERROR_CODES.INVALID_REVERSE_PROPERTY_VALUE);\n        }\n    }\n    /**\n     * Get the default graph.\n     * @return {Term} An RDF term.\n     */\n    getDefaultGraph() {\n        return this.parsingContext.defaultGraph || this.dataFactory.defaultGraph();\n    }\n    /**\n     * Get the current graph, while taking into account a graph that can be defined via @container: @graph.\n     * If not within a graph container, the default graph will be returned.\n     * @param keys The current keys.\n     * @param depth The current depth.\n     */\n    async getGraphContainerValue(keys, depth) {\n        // Default to default graph\n        let graph = this.getDefaultGraph();\n        // Check if we are in an @container: @graph.\n        const { containers, depth: depthContainer } = await EntryHandlerContainer_1.EntryHandlerContainer\n            .getContainerHandler(this.parsingContext, keys, depth);\n        if ('@graph' in containers) {\n            // Get the graph from the stack.\n            const graphContainerIndex = EntryHandlerContainer_1.EntryHandlerContainer.getContainerGraphIndex(containers, depthContainer, keys);\n            const entry = this.parsingContext.graphContainerTermStack[depthContainer];\n            graph = entry ? entry[graphContainerIndex] : null;\n            // Set the graph in the stack if none has been set yet.\n            if (!graph) {\n                let graphId = null;\n                if ('@id' in containers) {\n                    const keyUnaliased = await this.getContainerKey(keys[depthContainer], keys, depthContainer);\n                    if (keyUnaliased !== null) {\n                        graphId = await this.resourceToTerm(await this.parsingContext.getContext(keys), keyUnaliased);\n                    }\n                }\n                if (!graphId) {\n                    graphId = this.dataFactory.blankNode();\n                }\n                if (!this.parsingContext.graphContainerTermStack[depthContainer]) {\n                    this.parsingContext.graphContainerTermStack[depthContainer] = {};\n                }\n                graph = this.parsingContext.graphContainerTermStack[depthContainer][graphContainerIndex] = graphId;\n            }\n        }\n        return graph;\n    }\n    /**\n     * Get the properties depth for retrieving properties.\n     *\n     * Typically, the properties depth will be identical to the given depth.\n     *\n     * The following exceptions apply:\n     * * When the parent is @reverse, the depth is decremented by one.\n     * * When @nest parents are found, the depth is decremented by the number of @nest parents.\n     * If in combination with the exceptions above an intermediary array is discovered,\n     * the depth is also decremented by this number of arrays.\n     *\n     * @param keys The current key chain.\n     * @param depth The current depth.\n     */\n    async getPropertiesDepth(keys, depth) {\n        let lastValidDepth = depth;\n        for (let i = depth - 1; i > 0; i--) {\n            if (typeof keys[i] !== 'number') { // Skip array keys\n                const parentKey = await this.unaliasKeyword(keys[i], keys, i);\n                if (parentKey === '@reverse') {\n                    return i;\n                }\n                else if (parentKey === '@nest') {\n                    lastValidDepth = i;\n                }\n                else {\n                    return lastValidDepth;\n                }\n            }\n        }\n        return lastValidDepth;\n    }\n    /**\n     * Get the key for the current container entry.\n     * @param key A key, can be falsy.\n     * @param keys The key chain.\n     * @param depth The current depth to get the key from.\n     * @return Promise resolving to the key.\n     *         Null will be returned for @none entries, with aliasing taken into account.\n     */\n    async getContainerKey(key, keys, depth) {\n        const keyUnaliased = await this.unaliasKeyword(key, keys, depth);\n        return keyUnaliased === '@none' ? null : keyUnaliased;\n    }\n}\nexports.Util = Util;\nUtil.XSD = 'http://www.w3.org/2001/XMLSchema#';\nUtil.XSD_BOOLEAN = Util.XSD + 'boolean';\nUtil.XSD_INTEGER = Util.XSD + 'integer';\nUtil.XSD_DOUBLE = Util.XSD + 'double';\nUtil.RDF = 'http://www.w3.org/1999/02/22-rdf-syntax-ns#';\n//# sourceMappingURL=Util.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.ContainerHandlerIdentifier = void 0;\n/**\n * Container handler for @id.\n *\n * It assumes that the current key is the identifier of the current value.\n * This will add this value to the parent node.\n */\nclass ContainerHandlerIdentifier {\n    canCombineWithGraph() {\n        return true;\n    }\n    async handle(containers, parsingContext, util, keys, value, depth) {\n        let id;\n        // First check if the child node already has a defined id.\n        if (parsingContext.emittedStack[depth + 1] && parsingContext.idStack[depth + 1]) {\n            // Use the existing identifier\n            id = parsingContext.idStack[depth + 1][0];\n        }\n        else {\n            // Create the identifier\n            const keyUnaliased = await util.getContainerKey(keys[depth], keys, depth);\n            const maybeId = keyUnaliased !== null\n                ? await util.resourceToTerm(await parsingContext.getContext(keys), keys[depth])\n                : util.dataFactory.blankNode();\n            // Do nothing if the id is invalid\n            if (!maybeId) {\n                parsingContext.emittedStack[depth] = false; // Don't emit the predicate owning this container.\n                return;\n            }\n            id = maybeId;\n            // Insert the id into the stack so that buffered children can make us of it.\n            parsingContext.idStack[depth + 1] = [id];\n        }\n        // Insert the id into the stack so that parents can make use of it.\n        // Insert it as an array because multiple id container entries may exist\n        let ids = parsingContext.idStack[depth];\n        if (!ids) {\n            ids = parsingContext.idStack[depth] = [];\n        }\n        // Only insert the term if it does not exist yet in the array.\n        if (!ids.some((term) => term.equals(id))) {\n            ids.push(id);\n        }\n        // Flush any pending flush buffers\n        if (!await parsingContext.handlePendingContainerFlushBuffers()) {\n            parsingContext.emittedStack[depth] = false; // Don't emit the predicate owning this container.\n        }\n    }\n}\nexports.ContainerHandlerIdentifier = ContainerHandlerIdentifier;\n//# sourceMappingURL=ContainerHandlerIdentifier.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.ContainerHandlerIndex = void 0;\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\nconst EntryHandlerPredicate_1 = require(\"../entryhandler/EntryHandlerPredicate\");\nconst Util_1 = require(\"../Util\");\n/**\n * Container handler for @index.\n *\n * This will ignore the current key and add this entry to the parent node.\n */\nclass ContainerHandlerIndex {\n    canCombineWithGraph() {\n        return true;\n    }\n    async handle(containers, parsingContext, util, keys, value, depth) {\n        if (!Array.isArray(value)) {\n            const graphContainer = '@graph' in containers;\n            // Check if the container is a property-based container by checking if there is a valid @index.\n            const context = await parsingContext.getContext(keys);\n            const indexKey = keys[depth - 1];\n            const indexPropertyRaw = Util_1.Util.getContextValueIndex(context, indexKey);\n            if (indexPropertyRaw) {\n                // Validate the @index value\n                if (jsonld_context_parser_1.Util.isPotentialKeyword(indexPropertyRaw)) {\n                    throw new jsonld_context_parser_1.ErrorCoded(`Keywords can not be used as @index value, got: ${indexPropertyRaw}`, jsonld_context_parser_1.ERROR_CODES.INVALID_TERM_DEFINITION);\n                }\n                if (typeof indexPropertyRaw !== 'string') {\n                    throw new jsonld_context_parser_1.ErrorCoded(`@index values must be strings, got: ${indexPropertyRaw}`, jsonld_context_parser_1.ERROR_CODES.INVALID_TERM_DEFINITION);\n                }\n                // When @index is used, values must be node values, unless @type: @id is defined in the context\n                if (typeof value !== 'object') {\n                    // Error if we don't have @type: @id\n                    if (Util_1.Util.getContextValueType(context, indexKey) !== '@id') {\n                        throw new jsonld_context_parser_1.ErrorCoded(`Property-based index containers require nodes as values or strings with @type: @id, but got: ${value}`, jsonld_context_parser_1.ERROR_CODES.INVALID_VALUE_OBJECT);\n                    }\n                    // Add an @id to the stack, so our expanded @index value can make use of it\n                    const id = util.resourceToTerm(context, value);\n                    if (id) {\n                        parsingContext.idStack[depth + 1] = [id];\n                    }\n                }\n                // Expand the @index value\n                const indexProperty = util.createVocabOrBaseTerm(context, indexPropertyRaw);\n                if (indexProperty) {\n                    const indexValues = await util.valueToTerm(context, indexPropertyRaw, await util.getContainerKey(keys[depth], keys, depth), depth, keys);\n                    if (graphContainer) {\n                        // When we're in a graph container, attach the index to the graph identifier\n                        const graphId = await util.getGraphContainerValue(keys, depth + 1);\n                        for (const indexValue of indexValues) {\n                            parsingContext.emitQuad(depth, util.dataFactory.quad(graphId, indexProperty, indexValue, util.getDefaultGraph()));\n                        }\n                    }\n                    else {\n                        // Otherwise, attach the index to the node identifier\n                        for (const indexValue of indexValues) {\n                            await EntryHandlerPredicate_1.EntryHandlerPredicate.handlePredicateObject(parsingContext, util, keys, depth + 1, indexProperty, indexValue, false);\n                        }\n                    }\n                }\n            }\n            const depthOffset = graphContainer ? 2 : 1;\n            await parsingContext.newOnValueJob(keys.slice(0, keys.length - depthOffset), value, depth - depthOffset, true);\n            // Flush any pending flush buffers\n            await parsingContext.handlePendingContainerFlushBuffers();\n        }\n        parsingContext.emittedStack[depth] = false; // We have emitted a level higher\n    }\n}\nexports.ContainerHandlerIndex = ContainerHandlerIndex;\n//# sourceMappingURL=ContainerHandlerIndex.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.ContainerHandlerLanguage = void 0;\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\n/**\n * Container handler for @language.\n *\n * It assumes that the current key is the language of the current value.\n * This will add this value to the parent node.\n */\nclass ContainerHandlerLanguage {\n    canCombineWithGraph() {\n        return false;\n    }\n    async handle(containers, parsingContext, util, keys, value, depth) {\n        const language = await util.getContainerKey(keys[depth], keys, depth);\n        if (Array.isArray(value)) {\n            // No type-checking needed, will be handled on each value when this handler is called recursively.\n            value = value.map((subValue) => ({ '@value': subValue, '@language': language }));\n        }\n        else {\n            if (typeof value !== 'string') {\n                throw new jsonld_context_parser_1.ErrorCoded(`Got invalid language map value, got '${JSON.stringify(value)}', but expected string`, jsonld_context_parser_1.ERROR_CODES.INVALID_LANGUAGE_MAP_VALUE);\n            }\n            value = { '@value': value, '@language': language };\n        }\n        await parsingContext.newOnValueJob(keys.slice(0, keys.length - 1), value, depth - 1, true);\n        parsingContext.emittedStack[depth] = false; // We have emitted a level higher\n    }\n}\nexports.ContainerHandlerLanguage = ContainerHandlerLanguage;\n//# sourceMappingURL=ContainerHandlerLanguage.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.ContainerHandlerType = void 0;\nconst EntryHandlerPredicate_1 = require(\"../entryhandler/EntryHandlerPredicate\");\nconst Util_1 = require(\"../Util\");\n/**\n * Container handler for @type.\n *\n * This will add this entry to the parent node, and use the current key as an rdf:type value.\n */\nclass ContainerHandlerType {\n    canCombineWithGraph() {\n        return false;\n    }\n    async handle(containers, parsingContext, util, keys, value, depth) {\n        if (!Array.isArray(value)) {\n            if (typeof value === 'string') {\n                // Determine the @type of the container\n                const context = await parsingContext.getContext(keys);\n                const containerTypeType = Util_1.Util.getContextValueType(context, keys[depth - 1]);\n                // String values refer to node references\n                const id = containerTypeType === '@vocab'\n                    ? await util.createVocabOrBaseTerm(context, value)\n                    : await util.resourceToTerm(context, value);\n                if (id) {\n                    // Handle the value of this node as @id, which will also cause the predicate from above to be emitted.\n                    const subValue = { '@id': id.termType === 'NamedNode' ? id.value : value };\n                    await parsingContext.newOnValueJob(keys.slice(0, keys.length - 1), subValue, depth - 1, true);\n                    // Set the id in the stack so it can be used for the rdf:type handling later on\n                    parsingContext.idStack[depth + 1] = [id];\n                }\n            }\n            else {\n                // Other values are handled by handling them as a proper job\n                // Check needed for cases where entries don't have an explicit @id\n                const entryHasIdentifier = !!parsingContext.idStack[depth + 1];\n                // Handle the value of this node, which will also cause the predicate from above to be emitted.\n                if (!entryHasIdentifier) {\n                    delete parsingContext.idStack[depth]; // Force new (blank node) identifier\n                }\n                await parsingContext.newOnValueJob(keys.slice(0, keys.length - 1), value, depth - 1, true);\n                if (!entryHasIdentifier) {\n                    parsingContext.idStack[depth + 1] = parsingContext.idStack[depth]; // Copy the id to the child node, for @type\n                }\n            }\n            // Identify the type to emit.\n            const keyOriginal = await util.getContainerKey(keys[depth], keys, depth);\n            const type = keyOriginal !== null\n                ? util.createVocabOrBaseTerm(await parsingContext.getContext(keys), keyOriginal)\n                : null;\n            if (type) {\n                // Push the type to the stack using the rdf:type predicate\n                await EntryHandlerPredicate_1.EntryHandlerPredicate.handlePredicateObject(parsingContext, util, keys, depth + 1, util.rdfType, type, false);\n            }\n            // Flush any pending flush buffers\n            await parsingContext.handlePendingContainerFlushBuffers();\n        }\n        parsingContext.emittedStack[depth] = false; // Don't emit the predicate owning this container.\n    }\n}\nexports.ContainerHandlerType = ContainerHandlerType;\n//# sourceMappingURL=ContainerHandlerType.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerArrayValue = void 0;\nconst Util_1 = require(\"../Util\");\n/**\n * Handles values that are part of an array.\n */\nclass EntryHandlerArrayValue {\n    isPropertyHandler() {\n        return false;\n    }\n    isStackProcessor() {\n        return true;\n    }\n    async validate(parsingContext, util, keys, depth, inProperty) {\n        return this.test(parsingContext, util, null, keys, depth);\n    }\n    async test(parsingContext, util, key, keys, depth) {\n        return typeof keys[depth] === 'number';\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        let parentKey = await util.unaliasKeywordParent(keys, depth);\n        // Check if we have an anonymous list\n        if (parentKey === '@list') {\n            // Our value is part of an array\n            // Determine the list root key\n            let listRootKey = null;\n            let listRootDepth = 0;\n            for (let i = depth - 2; i > 0; i--) {\n                const keyOption = keys[i];\n                if (typeof keyOption === 'string' || typeof keyOption === 'number') {\n                    listRootDepth = i;\n                    listRootKey = keyOption;\n                    break;\n                }\n            }\n            if (listRootKey !== null) {\n                // Emit the given objects as list elements\n                const values = await util.valueToTerm(await parsingContext.getContext(keys), listRootKey, value, depth, keys);\n                for (const object of values) {\n                    await this.handleListElement(parsingContext, util, object, value, depth, keys.slice(0, listRootDepth), listRootDepth);\n                }\n                // If no values were found, emit a falsy list element to force an empty RDF list to be emitted.\n                if (values.length === 0) {\n                    await this.handleListElement(parsingContext, util, null, value, depth, keys.slice(0, listRootDepth), listRootDepth);\n                }\n            }\n        }\n        else if (parentKey === '@set') {\n            // Our value is part of a set, so we just add it to the parent-parent\n            await parsingContext.newOnValueJob(keys.slice(0, -2), value, depth - 2, false);\n        }\n        else if (parentKey !== undefined && parentKey !== '@type') {\n            // Buffer our value using the parent key as predicate\n            // Determine the first parent key that is *not* an array key\n            // This is needed in case we have an @list container with nested arrays,\n            // where each of them should produce nested RDF lists.\n            for (let i = depth - 1; i > 0; i--) {\n                if (typeof keys[i] !== 'number') {\n                    parentKey = await util.unaliasKeyword(keys[i], keys, i);\n                    break;\n                }\n            }\n            // Check if the predicate is marked as an @list in the context\n            const parentContext = await parsingContext.getContext(keys.slice(0, -1));\n            if ('@list' in Util_1.Util.getContextValueContainer(parentContext, parentKey)) {\n                // Our value is part of an array\n                // Emit the given objects as list elements\n                parsingContext.emittedStack[depth + 1] = true; // Ensure the creation of bnodes for empty nodes\n                const values = await util.valueToTerm(await parsingContext.getContext(keys), parentKey, value, depth, keys);\n                for (const object of values) {\n                    await this.handleListElement(parsingContext, util, object, value, depth, keys.slice(0, -1), depth - 1);\n                }\n                // If no values were found, emit a falsy list element to force an empty RDF list to be emitted.\n                if (values.length === 0) {\n                    await this.handleListElement(parsingContext, util, null, value, depth, keys.slice(0, -1), depth - 1);\n                }\n            }\n            else {\n                // Copy the stack values up one level so that the next job can access them.\n                parsingContext.shiftStack(depth, 1);\n                // Execute the job one level higher\n                await parsingContext.newOnValueJob(keys.slice(0, -1), value, depth - 1, false);\n                // Remove any defined contexts at this level to avoid it to propagate to the next array element.\n                parsingContext.contextTree.removeContext(keys.slice(0, -1));\n            }\n        }\n    }\n    async handleListElement(parsingContext, util, value, valueOriginal, depth, listRootKeys, listRootDepth) {\n        // Buffer our value as an RDF list using the listRootKey as predicate\n        let listPointer = parsingContext.listPointerStack[depth];\n        if (valueOriginal !== null && (await util.unaliasKeywords(valueOriginal, listRootKeys, depth))['@value'] !== null) {\n            if (!listPointer || !listPointer.value) {\n                const linkTerm = util.dataFactory.blankNode();\n                listPointer = { value: linkTerm, listRootDepth, listId: linkTerm };\n            }\n            else {\n                // rdf:rest links are always emitted before the next element,\n                // as the blank node identifier is only created at that point.\n                // Because of this reason, the final rdf:nil is emitted when the stack depth is decreased.\n                const newLinkTerm = util.dataFactory.blankNode();\n                parsingContext.emitQuad(depth, util.dataFactory.quad(listPointer.value, util.rdfRest, newLinkTerm, util.getDefaultGraph()));\n                // Update the list pointer for the next element\n                listPointer.value = newLinkTerm;\n            }\n            // Emit a list element for the current value\n            // Omit rdf:first if the value is invalid\n            if (value) {\n                parsingContext.emitQuad(depth, util.dataFactory.quad(listPointer.value, util.rdfFirst, value, util.getDefaultGraph()));\n            }\n        }\n        else {\n            // A falsy list element if found.\n            // Mark it as an rdf:nil list until another valid list element comes in\n            if (!listPointer) {\n                listPointer = { listRootDepth, listId: util.rdfNil };\n            }\n        }\n        parsingContext.listPointerStack[depth] = listPointer;\n    }\n}\nexports.EntryHandlerArrayValue = EntryHandlerArrayValue;\n//# sourceMappingURL=EntryHandlerArrayValue.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerContainer = void 0;\nconst ContainerHandlerIdentifier_1 = require(\"../containerhandler/ContainerHandlerIdentifier\");\nconst ContainerHandlerIndex_1 = require(\"../containerhandler/ContainerHandlerIndex\");\nconst ContainerHandlerLanguage_1 = require(\"../containerhandler/ContainerHandlerLanguage\");\nconst ContainerHandlerType_1 = require(\"../containerhandler/ContainerHandlerType\");\nconst Util_1 = require(\"../Util\");\n/**\n * Handles values that are part of a container type (like @index),\n * as specified by {@link IContainerHandler}.\n */\nclass EntryHandlerContainer {\n    /**\n     * Check fit the given container is a simple @graph container.\n     * Concretely, it will check if no @index or @id is active as well.\n     * @param containers A container hash.\n     */\n    static isSimpleGraphContainer(containers) {\n        return '@graph' in containers\n            && (('@set' in containers && Object.keys(containers).length === 2) || Object.keys(containers).length === 1);\n    }\n    /**\n     * Check fit the given container is a complex @graph container.\n     * Concretely, it will check if @index or @id is active as well next to @graph.\n     * @param containers A container hash.\n     */\n    static isComplexGraphContainer(containers) {\n        return '@graph' in containers\n            && (('@set' in containers && Object.keys(containers).length > 2)\n                || (!('@set' in containers) && Object.keys(containers).length > 1));\n    }\n    /**\n     * Create an graph container index that can be used for identifying a graph term inside the graphContainerTermStack.\n     * @param containers The applicable containers.\n     * @param depth The container depth.\n     * @param keys The array of keys.\n     * @return The graph index.\n     */\n    static getContainerGraphIndex(containers, depth, keys) {\n        let isSimpleGraphContainer = EntryHandlerContainer.isSimpleGraphContainer(containers);\n        let index = '';\n        for (let i = depth; i < keys.length; i++) {\n            if (!isSimpleGraphContainer || typeof keys[i] === 'number') {\n                index += ':' + keys[i];\n            }\n            // Only allow a second 'real' key if in a non-simple graph container.\n            if (!isSimpleGraphContainer && typeof keys[i] !== 'number') {\n                isSimpleGraphContainer = true;\n            }\n        }\n        return index;\n    }\n    /**\n     * Return the applicable container type at the given depth.\n     *\n     * This will ignore any arrays in the key chain.\n     *\n     * @param {ParsingContext} parsingContext A parsing context.\n     * @param {any[]} keys The array of keys.\n     * @param {number} depth The current depth.\n     * @return {Promise<{ containers: {[typeName: string]: boolean}, depth: number, fallback: boolean }>}\n     *          All applicable containers for the given depth,\n     *          the `depth` of the container root (can change when arrays are in the key chain),\n     *          and the `fallback` flag that indicates if the default container type was returned\n     *            (i.e., no dedicated container type is defined).\n     */\n    static async getContainerHandler(parsingContext, keys, depth) {\n        const fallback = {\n            containers: { '@set': true },\n            depth,\n            fallback: true,\n        };\n        // A flag that is enabled when @graph container should be tested in next iteration\n        let checkGraphContainer = false;\n        // Iterate from deeper to higher\n        const context = await parsingContext.getContext(keys, 2);\n        for (let i = depth - 1; i >= 0; i--) {\n            if (typeof keys[i] !== 'number') { // Skip array keys\n                // @graph containers without any other types are one level less deep, and require special handling\n                const containersSelf = Util_1.Util.getContextValue(context, '@container', keys[i], false);\n                if (containersSelf && EntryHandlerContainer.isSimpleGraphContainer(containersSelf)) {\n                    return {\n                        containers: containersSelf,\n                        depth: i + 1,\n                        fallback: false,\n                    };\n                }\n                const containersParent = Util_1.Util.getContextValue(context, '@container', keys[i - 1], false);\n                if (!containersParent) { // If we have the fallback container value\n                    if (checkGraphContainer) {\n                        // Return false if we were already expecting a @graph-@id of @graph-@index container\n                        return fallback;\n                    }\n                    // Check parent-parent, we may be in a @graph-@id of @graph-@index container, which have two levels\n                    checkGraphContainer = true;\n                }\n                else {\n                    // We had an invalid container next iteration, so we now have to check if we were in an @graph container\n                    const graphContainer = '@graph' in containersParent;\n                    // We're in a regular container\n                    for (const containerHandleName in EntryHandlerContainer.CONTAINER_HANDLERS) {\n                        if (containersParent[containerHandleName]) {\n                            if (graphContainer) {\n                                // Only accept graph containers if their combined handlers can handle them.\n                                if (EntryHandlerContainer.CONTAINER_HANDLERS[containerHandleName].canCombineWithGraph()) {\n                                    return {\n                                        containers: containersParent,\n                                        depth: i,\n                                        fallback: false,\n                                    };\n                                }\n                                else {\n                                    return fallback;\n                                }\n                            }\n                            else {\n                                // Only accept if we were not expecting a @graph-@id of @graph-@index container\n                                if (checkGraphContainer) {\n                                    return fallback;\n                                }\n                                else {\n                                    return {\n                                        containers: containersParent,\n                                        depth: i,\n                                        fallback: false,\n                                    };\n                                }\n                            }\n                        }\n                    }\n                    // Fail if no valid container handlers were found\n                    return fallback;\n                }\n            }\n        }\n        return fallback;\n    }\n    /**\n     * Check if we are handling a value at the given depth\n     * that is part of something that should be handled as a container,\n     * AND if this container should be buffered, so that it can be handled by a dedicated container handler.\n     *\n     * For instance, any container with @graph will NOT be buffered.\n     *\n     * This will ignore any arrays in the key chain.\n     *\n     * @param {ParsingContext} parsingContext A parsing context.\n     * @param {any[]} keys The array of keys.\n     * @param {number} depth The current depth.\n     * @return {Promise<boolean>} If we are in the scope of a container handler.\n     */\n    static async isBufferableContainerHandler(parsingContext, keys, depth) {\n        const handler = await EntryHandlerContainer.getContainerHandler(parsingContext, keys, depth);\n        return !handler.fallback && !('@graph' in handler.containers);\n    }\n    isPropertyHandler() {\n        return false;\n    }\n    isStackProcessor() {\n        return true;\n    }\n    async validate(parsingContext, util, keys, depth, inProperty) {\n        return !!await this.test(parsingContext, util, null, keys, depth);\n    }\n    async test(parsingContext, util, key, keys, depth) {\n        const containers = Util_1.Util.getContextValueContainer(await parsingContext.getContext(keys, 2), keys[depth - 1]);\n        for (const containerName in EntryHandlerContainer.CONTAINER_HANDLERS) {\n            if (containers[containerName]) {\n                return {\n                    containers,\n                    handler: EntryHandlerContainer.CONTAINER_HANDLERS[containerName],\n                };\n            }\n        }\n        return null;\n    }\n    async handle(parsingContext, util, key, keys, value, depth, testResult) {\n        return testResult.handler.handle(testResult.containers, parsingContext, util, keys, value, depth);\n    }\n}\nexports.EntryHandlerContainer = EntryHandlerContainer;\nEntryHandlerContainer.CONTAINER_HANDLERS = {\n    '@id': new ContainerHandlerIdentifier_1.ContainerHandlerIdentifier(),\n    '@index': new ContainerHandlerIndex_1.ContainerHandlerIndex(),\n    '@language': new ContainerHandlerLanguage_1.ContainerHandlerLanguage(),\n    '@type': new ContainerHandlerType_1.ContainerHandlerType(),\n};\n//# sourceMappingURL=EntryHandlerContainer.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerInvalidFallback = void 0;\n/**\n * A catch-all for properties, that will either emit an error or ignore,\n * depending on whether or not the `strictValues` property is set.\n */\nclass EntryHandlerInvalidFallback {\n    isPropertyHandler() {\n        return false;\n    }\n    isStackProcessor() {\n        return true;\n    }\n    async validate(parsingContext, util, keys, depth, inProperty) {\n        return false;\n    }\n    async test(parsingContext, util, key, keys, depth) {\n        return true;\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        parsingContext.emittedStack[depth] = false;\n    }\n}\nexports.EntryHandlerInvalidFallback = EntryHandlerInvalidFallback;\n//# sourceMappingURL=EntryHandlerInvalidFallback.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerPredicate = void 0;\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\nconst Util_1 = require(\"../Util\");\n/**\n * Interprets keys as predicates.\n * The most common case in JSON-LD processing.\n */\nclass EntryHandlerPredicate {\n    /**\n     * Handle the given predicate-object by either emitting it,\n     * or by placing it in the appropriate stack for later emission when no @graph and/or @id has been defined.\n     * @param {ParsingContext} parsingContext A parsing context.\n     * @param {Util} util A utility instance.\n     * @param {any[]} keys A stack of keys.\n     * @param {number} depth The current depth.\n     * @param {Term} predicate The predicate.\n     * @param {Term} object The object.\n     * @param {boolean} reverse If the property is reversed.\n     * @return {Promise<void>} A promise resolving when handling is done.\n     */\n    static async handlePredicateObject(parsingContext, util, keys, depth, predicate, object, reverse) {\n        const depthProperties = await util.getPropertiesDepth(keys, depth);\n        const depthOffsetGraph = await util.getDepthOffsetGraph(depth, keys);\n        const depthPropertiesGraph = depth - depthOffsetGraph;\n        const subjects = parsingContext.idStack[depthProperties];\n        if (subjects) {\n            // Emit directly if the @id was already defined\n            for (const subject of subjects) {\n                // Check if we're in a @graph context\n                const atGraph = depthOffsetGraph >= 0;\n                if (atGraph) {\n                    const graphs = parsingContext.idStack[depthPropertiesGraph - 1];\n                    if (graphs) {\n                        for (const graph of graphs) {\n                            // Emit our quad if graph @id is known\n                            if (reverse) {\n                                util.validateReverseSubject(object);\n                                parsingContext.emitQuad(depth, util.dataFactory.quad(object, predicate, subject, graph));\n                            }\n                            else {\n                                parsingContext.emitQuad(depth, util.dataFactory.quad(subject, predicate, object, graph));\n                            }\n                        }\n                    }\n                    else {\n                        // Buffer our triple if graph @id is not known yet.\n                        if (reverse) {\n                            util.validateReverseSubject(object);\n                            parsingContext.getUnidentifiedGraphBufferSafe(depthPropertiesGraph - 1).push({ subject: object, predicate, object: subject });\n                        }\n                        else {\n                            parsingContext.getUnidentifiedGraphBufferSafe(depthPropertiesGraph - 1)\n                                .push({ subject, predicate, object });\n                        }\n                    }\n                }\n                else {\n                    // Emit if no @graph was applicable\n                    const graph = await util.getGraphContainerValue(keys, depthProperties);\n                    if (reverse) {\n                        util.validateReverseSubject(object);\n                        parsingContext.emitQuad(depth, util.dataFactory.quad(object, predicate, subject, graph));\n                    }\n                    else {\n                        parsingContext.emitQuad(depth, util.dataFactory.quad(subject, predicate, object, graph));\n                    }\n                }\n            }\n        }\n        else {\n            // Buffer until our @id becomes known, or we go up the stack\n            if (reverse) {\n                util.validateReverseSubject(object);\n            }\n            parsingContext.getUnidentifiedValueBufferSafe(depthProperties).push({ predicate, object, reverse });\n        }\n    }\n    isPropertyHandler() {\n        return true;\n    }\n    isStackProcessor() {\n        return true;\n    }\n    async validate(parsingContext, util, keys, depth, inProperty) {\n        const key = keys[depth];\n        if (key) {\n            const context = await parsingContext.getContext(keys);\n            if (!parsingContext.jsonLiteralStack[depth] && await util.predicateToTerm(context, keys[depth])) {\n                // If this valid predicate is of type @json, mark it so in the stack so that no deeper handling of nodes occurs.\n                if (Util_1.Util.getContextValueType(context, key) === '@json') {\n                    parsingContext.jsonLiteralStack[depth + 1] = true;\n                }\n                return true;\n            }\n        }\n        return false;\n    }\n    async test(parsingContext, util, key, keys, depth) {\n        return keys[depth];\n    }\n    async handle(parsingContext, util, key, keys, value, depth, testResult) {\n        const keyOriginal = keys[depth];\n        const context = await parsingContext.getContext(keys);\n        const predicate = await util.predicateToTerm(context, key);\n        if (predicate) {\n            const objects = await util.valueToTerm(context, key, value, depth, keys);\n            if (objects.length) {\n                for (let object of objects) {\n                    const reverse = Util_1.Util.isPropertyReverse(context, keyOriginal, await util.unaliasKeywordParent(keys, depth));\n                    if (value) {\n                        // Special case if our term was defined as an @list, but does not occur in an array,\n                        // In that case we just emit it as an RDF list with a single element.\n                        const listValueContainer = '@list' in Util_1.Util.getContextValueContainer(context, key);\n                        if (listValueContainer || value['@list']) {\n                            if (((listValueContainer && !Array.isArray(value) && !value['@list'])\n                                || (value['@list'] && !Array.isArray(value['@list'])))\n                                && object !== util.rdfNil) {\n                                const listPointer = util.dataFactory.blankNode();\n                                parsingContext.emitQuad(depth, util.dataFactory.quad(listPointer, util.rdfRest, util.rdfNil, util.getDefaultGraph()));\n                                parsingContext.emitQuad(depth, util.dataFactory.quad(listPointer, util.rdfFirst, object, util.getDefaultGraph()));\n                                object = listPointer;\n                            }\n                            // Lists are not allowed in @reverse'd properties\n                            if (reverse && !parsingContext.allowSubjectList) {\n                                throw new jsonld_context_parser_1.ErrorCoded(`Found illegal list value in subject position at ${key}`, jsonld_context_parser_1.ERROR_CODES.INVALID_REVERSE_PROPERTY_VALUE);\n                            }\n                        }\n                    }\n                    await EntryHandlerPredicate.handlePredicateObject(parsingContext, util, keys, depth, predicate, object, reverse);\n                }\n            }\n        }\n    }\n}\nexports.EntryHandlerPredicate = EntryHandlerPredicate;\n//# sourceMappingURL=EntryHandlerPredicate.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerKeyword = void 0;\n/**\n * An abstract keyword entry handler.\n */\nclass EntryHandlerKeyword {\n    constructor(keyword) {\n        this.keyword = keyword;\n    }\n    isPropertyHandler() {\n        return false;\n    }\n    isStackProcessor() {\n        return true;\n    }\n    async validate(parsingContext, util, keys, depth, inProperty) {\n        return false;\n    }\n    async test(parsingContext, util, key, keys, depth) {\n        return key === this.keyword;\n    }\n}\nexports.EntryHandlerKeyword = EntryHandlerKeyword;\n//# sourceMappingURL=EntryHandlerKeyword.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerKeywordContext = void 0;\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\nconst EntryHandlerKeyword_1 = require(\"./EntryHandlerKeyword\");\n/**\n * Handles @context entries.\n */\nclass EntryHandlerKeywordContext extends EntryHandlerKeyword_1.EntryHandlerKeyword {\n    constructor() {\n        super('@context');\n    }\n    isStackProcessor() {\n        return false;\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        // Error if an out-of-order context was found when support is not enabled.\n        if (parsingContext.streamingProfile\n            && (parsingContext.processingStack[depth]\n                || parsingContext.processingType[depth]\n                || parsingContext.idStack[depth] !== undefined)) {\n            parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded('Found an out-of-order context, while streaming is enabled.' +\n                '(disable `streamingProfile`)', jsonld_context_parser_1.ERROR_CODES.INVALID_STREAMING_KEY_ORDER));\n        }\n        // Find the parent context to inherit from.\n        // We actually request a context for the current depth (with fallback to parent)\n        // because we want to take into account any property-scoped contexts that are defined for this depth.\n        const parentContext = parsingContext.getContext(keys);\n        // Set the context for this scope\n        const context = parsingContext.parseContext(value, (await parentContext).getContextRaw());\n        parsingContext.contextTree.setContext(keys.slice(0, -1), context);\n        parsingContext.emitContext(value);\n        await parsingContext.validateContext(await context);\n    }\n}\nexports.EntryHandlerKeywordContext = EntryHandlerKeywordContext;\n//# sourceMappingURL=EntryHandlerKeywordContext.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerKeywordGraph = void 0;\nconst EntryHandlerKeyword_1 = require(\"./EntryHandlerKeyword\");\n/**\n * Handles @graph entries.\n */\nclass EntryHandlerKeywordGraph extends EntryHandlerKeyword_1.EntryHandlerKeyword {\n    constructor() {\n        super('@graph');\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        // The current identifier identifies a graph for the deeper level.\n        parsingContext.graphStack[depth + 1] = true;\n    }\n}\nexports.EntryHandlerKeywordGraph = EntryHandlerKeywordGraph;\n//# sourceMappingURL=EntryHandlerKeywordGraph.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerKeywordId = void 0;\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\nconst EntryHandlerKeyword_1 = require(\"./EntryHandlerKeyword\");\n/**\n * Handles @id entries.\n */\nclass EntryHandlerKeywordId extends EntryHandlerKeyword_1.EntryHandlerKeyword {\n    constructor() {\n        super('@id');\n    }\n    isStackProcessor() {\n        return false;\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        if (typeof value !== 'string') {\n            parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found illegal @id '${value}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_ID_VALUE));\n        }\n        // Determine the canonical place for this id.\n        // For example, @nest parents should be ignored.\n        const depthProperties = await util.getPropertiesDepth(keys, depth);\n        // Error if an @id for this node already existed.\n        if (parsingContext.idStack[depthProperties] !== undefined) {\n            if (parsingContext.idStack[depthProperties][0].listHead) {\n                // Error if an @list was already defined for this node\n                parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found illegal neighbouring entries next to @list for key: '${keys[depth - 1]}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_SET_OR_LIST_OBJECT));\n            }\n            else {\n                // Otherwise, the previous id was just because of an @id entry.\n                parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found duplicate @ids '${parsingContext\n                    .idStack[depthProperties][0].value}' and '${value}'`, jsonld_context_parser_1.ERROR_CODES.COLLIDING_KEYWORDS));\n            }\n        }\n        // Save our @id on the stack\n        parsingContext.idStack[depthProperties] = util.nullableTermToArray(await util.resourceToTerm(await parsingContext.getContext(keys), value));\n    }\n}\nexports.EntryHandlerKeywordId = EntryHandlerKeywordId;\n//# sourceMappingURL=EntryHandlerKeywordId.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerKeywordIncluded = void 0;\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\nconst EntryHandlerKeyword_1 = require(\"./EntryHandlerKeyword\");\n/**\n * Handles @included entries.\n */\nclass EntryHandlerKeywordIncluded extends EntryHandlerKeyword_1.EntryHandlerKeyword {\n    constructor() {\n        super('@included');\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        if (typeof value !== 'object') {\n            parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found illegal @included '${value}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_INCLUDED_VALUE));\n        }\n        const valueUnliased = await util.unaliasKeywords(value, keys, depth, await parsingContext.getContext(keys));\n        if ('@value' in valueUnliased) {\n            parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found an illegal @included @value node '${JSON.stringify(value)}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_INCLUDED_VALUE));\n        }\n        if ('@list' in valueUnliased) {\n            parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found an illegal @included @list node '${JSON.stringify(value)}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_INCLUDED_VALUE));\n        }\n        parsingContext.emittedStack[depth] = false;\n    }\n}\nexports.EntryHandlerKeywordIncluded = EntryHandlerKeywordIncluded;\n//# sourceMappingURL=EntryHandlerKeywordIncluded.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerKeywordNest = void 0;\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\nconst EntryHandlerKeyword_1 = require(\"./EntryHandlerKeyword\");\n/**\n * Handles @nest entries.\n */\nclass EntryHandlerKeywordNest extends EntryHandlerKeyword_1.EntryHandlerKeyword {\n    constructor() {\n        super('@nest');\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        if (typeof value !== 'object') {\n            parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found invalid @nest entry for '${key}': '${value}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_NEST_VALUE));\n        }\n        if ('@value' in await util.unaliasKeywords(value, keys, depth, await parsingContext.getContext(keys))) {\n            parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found an invalid @value node for '${key}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_NEST_VALUE));\n        }\n        parsingContext.emittedStack[depth] = false;\n    }\n}\nexports.EntryHandlerKeywordNest = EntryHandlerKeywordNest;\n//# sourceMappingURL=EntryHandlerKeywordNest.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerKeywordType = void 0;\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\nconst Util_1 = require(\"../../Util\");\nconst EntryHandlerPredicate_1 = require(\"../EntryHandlerPredicate\");\nconst EntryHandlerKeyword_1 = require(\"./EntryHandlerKeyword\");\n/**\n * Handles @graph entries.\n */\nclass EntryHandlerKeywordType extends EntryHandlerKeyword_1.EntryHandlerKeyword {\n    constructor() {\n        super('@type');\n    }\n    isStackProcessor() {\n        return false;\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        const keyOriginal = keys[depth];\n        // The current identifier identifies an rdf:type predicate.\n        // But we only emit it once the node closes,\n        // as it's possible that the @type is used to identify the datatype of a literal, which we ignore here.\n        const context = await parsingContext.getContext(keys);\n        const predicate = util.rdfType;\n        const reverse = Util_1.Util.isPropertyReverse(context, keyOriginal, await util.unaliasKeywordParent(keys, depth));\n        // Handle multiple values if the value is an array\n        const elements = Array.isArray(value) ? value : [value];\n        for (const element of elements) {\n            if (typeof element !== 'string') {\n                parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found illegal @type '${element}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_TYPE_VALUE));\n            }\n            const type = util.createVocabOrBaseTerm(context, element);\n            if (type) {\n                await EntryHandlerPredicate_1.EntryHandlerPredicate.handlePredicateObject(parsingContext, util, keys, depth, predicate, type, reverse);\n            }\n        }\n        // Collect type-scoped contexts if they exist\n        let scopedContext = Promise.resolve(context);\n        let hasTypedScopedContext = false;\n        for (const element of elements.sort()) { // Spec requires lexicographical ordering\n            const typeContext = Util_1.Util.getContextValue(context, '@context', element, null);\n            if (typeContext) {\n                hasTypedScopedContext = true;\n                scopedContext = scopedContext.then((c) => parsingContext.parseContext(typeContext, c.getContextRaw()));\n            }\n        }\n        // Error if an out-of-order type-scoped context was found when support is not enabled.\n        if (parsingContext.streamingProfile\n            && (hasTypedScopedContext || !parsingContext.streamingProfileAllowOutOfOrderPlainType)\n            && (parsingContext.processingStack[depth] || parsingContext.idStack[depth])) {\n            parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded('Found an out-of-order type-scoped context, while streaming is enabled.' +\n                '(disable `streamingProfile`)', jsonld_context_parser_1.ERROR_CODES.INVALID_STREAMING_KEY_ORDER));\n        }\n        // If at least least one type-scoped context applies, set them in the tree.\n        if (hasTypedScopedContext) {\n            // Do not propagate by default\n            scopedContext = scopedContext.then((c) => {\n                if (!('@propagate' in c.getContextRaw())) {\n                    c.getContextRaw()['@propagate'] = false;\n                }\n                // Set the original context at this depth as a fallback\n                // This is needed when a context was already defined at the given depth,\n                // and this context needs to remain accessible from child nodes when propagation is disabled.\n                if (c.getContextRaw()['@propagate'] === false) {\n                    c.getContextRaw()['@__propagateFallback'] = context.getContextRaw();\n                }\n                return c;\n            });\n            // Set the new context in the context tree\n            parsingContext.contextTree.setContext(keys.slice(0, keys.length - 1), scopedContext);\n        }\n        // Flag that type has been processed at this depth\n        parsingContext.processingType[depth] = true;\n    }\n}\nexports.EntryHandlerKeywordType = EntryHandlerKeywordType;\n//# sourceMappingURL=EntryHandlerKeywordType.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerKeywordUnknownFallback = void 0;\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\n/**\n * A catch-all for keywords, that will either emit an error or ignore,\n * depending on whether or not the `strictValues` property is set.\n */\nclass EntryHandlerKeywordUnknownFallback {\n    isPropertyHandler() {\n        return false;\n    }\n    isStackProcessor() {\n        return true;\n    }\n    async validate(parsingContext, util, keys, depth, inProperty) {\n        const key = await util.unaliasKeyword(keys[depth], keys, depth);\n        if (jsonld_context_parser_1.Util.isPotentialKeyword(key)) {\n            // Don't emit anything inside free-floating lists\n            if (!inProperty) {\n                if (key === '@list') {\n                    return false;\n                }\n            }\n            return true;\n        }\n        return false;\n    }\n    async test(parsingContext, util, key, keys, depth) {\n        return jsonld_context_parser_1.Util.isPotentialKeyword(key);\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        const keywordType = EntryHandlerKeywordUnknownFallback.VALID_KEYWORDS_TYPES[key];\n        if (keywordType !== undefined) {\n            if (keywordType && typeof value !== keywordType.type) {\n                parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Invalid value type for '${key}' with value '${value}'`, keywordType.errorCode));\n            }\n        }\n        else if (parsingContext.strictValues) {\n            parsingContext.emitError(new Error(`Unknown keyword '${key}' with value '${value}'`));\n        }\n        parsingContext.emittedStack[depth] = false;\n    }\n}\nexports.EntryHandlerKeywordUnknownFallback = EntryHandlerKeywordUnknownFallback;\nEntryHandlerKeywordUnknownFallback.VALID_KEYWORDS_TYPES = {\n    '@index': { type: 'string', errorCode: jsonld_context_parser_1.ERROR_CODES.INVALID_INDEX_VALUE },\n    '@list': null,\n    '@reverse': { type: 'object', errorCode: jsonld_context_parser_1.ERROR_CODES.INVALID_REVERSE_VALUE },\n    '@set': null,\n    '@value': null,\n};\n//# sourceMappingURL=EntryHandlerKeywordUnknownFallback.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerKeywordValue = void 0;\nconst EntryHandlerKeyword_1 = require(\"./EntryHandlerKeyword\");\n/**\n * Handles @value entries.\n */\nclass EntryHandlerKeywordValue extends EntryHandlerKeyword_1.EntryHandlerKeyword {\n    constructor() {\n        super('@value');\n    }\n    async validate(parsingContext, util, keys, depth, inProperty) {\n        // If this is @value, mark it so in the stack so that no deeper handling of nodes occurs.\n        const key = keys[depth];\n        if (key && !parsingContext.literalStack[depth] && await this.test(parsingContext, util, key, keys, depth)) {\n            parsingContext.literalStack[depth] = true;\n        }\n        return super.validate(parsingContext, util, keys, depth, inProperty);\n    }\n    async test(parsingContext, util, key, keys, depth) {\n        return await util.unaliasKeyword(keys[depth], keys.slice(0, keys.length - 1), depth - 1, true) === '@value';\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        // If the value is valid, indicate that we are processing a literal.\n        // The actual value will be determined at the parent level when the @value is part of an object,\n        // because we may want to take into account additional entries such as @language.\n        // See {@link Util.valueToTerm}\n        // Indicate that we are processing a literal, and that no later predicates should be parsed at this depth.\n        parsingContext.literalStack[depth] = true;\n        // Void any buffers that we may have accumulated up until now\n        delete parsingContext.unidentifiedValuesBuffer[depth];\n        delete parsingContext.unidentifiedGraphsBuffer[depth];\n        // Indicate that we have not emitted at this depth\n        parsingContext.emittedStack[depth] = false;\n    }\n}\nexports.EntryHandlerKeywordValue = EntryHandlerKeywordValue;\n//# sourceMappingURL=EntryHandlerKeywordValue.js.map","/**\n * Convert the given relative IRI to an absolute IRI\n * by taking into account the given optional baseIRI.\n *\n * @param {string} relativeIRI The relative IRI to convert to an absolute IRI.\n * @param {string} baseIRI The optional base IRI.\n * @return {string} an absolute IRI.\n */\nexport function resolve(relativeIRI: string, baseIRI?: string): string {\n  baseIRI = baseIRI || '';\n  const baseFragmentPos: number = baseIRI.indexOf('#');\n\n  // Ignore any fragments in the base IRI\n  if (baseFragmentPos > 0) {\n    baseIRI = baseIRI.substr(0, baseFragmentPos);\n  }\n\n  // Convert empty value directly to base IRI\n  if (!relativeIRI.length) {\n    // At this point, the baseIRI MUST be absolute, otherwise we error\n    if (baseIRI.indexOf(':') < 0) {\n      throw new Error(`Found invalid baseIRI '${baseIRI}' for value '${relativeIRI}'`);\n    }\n    return baseIRI;\n  }\n\n  // If the value starts with a query character, concat directly (but strip the existing query)\n  if (relativeIRI.startsWith('?')) {\n    const baseQueryPos: number = baseIRI.indexOf('?');\n    if (baseQueryPos > 0) {\n      baseIRI = baseIRI.substr(0, baseQueryPos);\n    }\n    return baseIRI + relativeIRI;\n  }\n\n  // If the value starts with a fragment character, concat directly\n  if (relativeIRI.startsWith('#')) {\n    return baseIRI + relativeIRI;\n  }\n\n  // Ignore baseIRI if it is empty\n  if (!baseIRI.length) {\n    const relativeColonPos = relativeIRI.indexOf(':');\n    if (relativeColonPos < 0) {\n      throw new Error(`Found invalid relative IRI '${relativeIRI}' for a missing baseIRI`);\n    }\n    return removeDotSegmentsOfPath(relativeIRI, relativeColonPos);\n  }\n\n  // Ignore baseIRI if the value is absolute\n  const valueColonPos: number = relativeIRI.indexOf(':');\n  if (valueColonPos >= 0) {\n    return removeDotSegmentsOfPath(relativeIRI, valueColonPos);\n  }\n\n  // At this point, the baseIRI MUST be absolute, otherwise we error\n  const baseColonPos: number = baseIRI.indexOf(':');\n  if (baseColonPos < 0) {\n    throw new Error(`Found invalid baseIRI '${baseIRI}' for value '${relativeIRI}'`);\n  }\n\n  const baseIRIScheme = baseIRI.substr(0, baseColonPos + 1);\n  // Inherit the baseIRI scheme if the value starts with '//'\n  if (relativeIRI.indexOf('//') === 0) {\n    return baseIRIScheme + removeDotSegmentsOfPath(relativeIRI, valueColonPos);\n  }\n\n  // Check cases where '://' occurs in the baseIRI, and where there is no '/' after a ':' anymore.\n  let baseSlashAfterColonPos;\n  if (baseIRI.indexOf('//', baseColonPos) === baseColonPos + 1) {\n    // If there is no additional '/' after the '//'.\n    baseSlashAfterColonPos = baseIRI.indexOf('/', baseColonPos + 3);\n    if (baseSlashAfterColonPos < 0) {\n      // If something other than a '/' follows the '://', append the value after a '/',\n      // otherwise, prefix the value with only the baseIRI scheme.\n      if (baseIRI.length > baseColonPos + 3) {\n        return baseIRI + '/' + removeDotSegmentsOfPath(relativeIRI, valueColonPos);\n      } else {\n        return baseIRIScheme + removeDotSegmentsOfPath(relativeIRI, valueColonPos);\n      }\n    }\n  } else {\n    // If there is not even a single '/' after the ':'\n    baseSlashAfterColonPos = baseIRI.indexOf('/', baseColonPos + 1);\n    if (baseSlashAfterColonPos < 0) {\n      // If we don't have a '/' after the ':',\n      // prefix the value with only the baseIRI scheme.\n      return baseIRIScheme + removeDotSegmentsOfPath(relativeIRI, valueColonPos);\n    }\n  }\n\n  // If the value starts with a '/', then prefix it with everything before the first effective slash of the base IRI.\n  if (relativeIRI.indexOf('/') === 0) {\n    return baseIRI.substr(0, baseSlashAfterColonPos) + removeDotSegments(relativeIRI);\n  }\n\n  let baseIRIPath = baseIRI.substr(baseSlashAfterColonPos);\n  const baseIRILastSlashPos = baseIRIPath.lastIndexOf('/');\n\n  // Ignore everything after the last '/' in the baseIRI path\n  if (baseIRILastSlashPos >= 0 && baseIRILastSlashPos < baseIRIPath.length - 1) {\n    baseIRIPath = baseIRIPath.substr(0, baseIRILastSlashPos + 1);\n    // Also remove the first character of the relative path if it starts with '.' (and not '..' or './')\n    // This change is only allowed if there is something else following the path\n    if (relativeIRI[0] === '.' && relativeIRI[1] !== '.' && relativeIRI[1] !== '/' && relativeIRI[2]) {\n      relativeIRI = relativeIRI.substr(1);\n    }\n  }\n\n  // Prefix the value with the baseIRI path where\n  relativeIRI = baseIRIPath + relativeIRI;\n\n  // Remove dot segment from the IRI\n  relativeIRI = removeDotSegments(relativeIRI);\n\n  // Prefix our transformed value with the part of the baseIRI until the first '/' after the first ':'.\n  return baseIRI.substr(0, baseSlashAfterColonPos) + relativeIRI;\n}\n\n/**\n * Remove dot segments from the given path,\n * as described in https://www.ietf.org/rfc/rfc3986.txt (page 32).\n * @param {string} path An IRI path.\n * @return {string} A path, will always start with a '/'.\n */\nexport function removeDotSegments(path: string): string {\n  // Prepare a buffer with segments between each '/.\n  // Each segment represents an array of characters.\n  const segmentBuffers: string[][] = [];\n\n  let i = 0;\n  while (i < path.length) {\n    // Remove '/.' or '/..'\n    switch (path[i]) {\n    case '/':\n      if (path[i + 1] === '.') {\n        if (path[i + 2] === '.') {\n          // Start a new segment if we find an invalid character after the '.'\n          if (!isCharacterAllowedAfterRelativePathSegment(path[i + 3])) {\n            segmentBuffers.push([]);\n            i++;\n            break;\n          }\n\n          // Go to parent directory,\n          // so we remove a parent segment\n          segmentBuffers.pop();\n\n          // Ensure that we end with a slash if there is a trailing '/..'\n          if (!path[i + 3]) {\n            segmentBuffers.push([]);\n          }\n\n          i += 3;\n        } else {\n          // Start a new segment if we find an invalid character after the '.'\n          if (!isCharacterAllowedAfterRelativePathSegment(path[i + 2])) {\n            segmentBuffers.push([]);\n            i++;\n            break;\n          }\n\n          // Ensure that we end with a slash if there is a trailing '/.'\n          if (!path[i + 2]) {\n            segmentBuffers.push([]);\n          }\n\n          // Go to the current directory,\n          // so we do nothing\n          i += 2;\n        }\n      } else {\n        // Start a new segment\n        segmentBuffers.push([]);\n        i++;\n      }\n      break;\n    case '#':\n    case '?':\n      // Query and fragment string should be appended unchanged\n      if (!segmentBuffers.length) {\n        segmentBuffers.push([]);\n      }\n      segmentBuffers[segmentBuffers.length - 1].push(path.substr(i));\n      // Break the while loop\n      i = path.length;\n      break;\n    default:\n      // Not a special character, just append it to our buffer\n      if (!segmentBuffers.length) {\n        segmentBuffers.push([]);\n      }\n      segmentBuffers[segmentBuffers.length - 1].push(path[i]);\n      i++;\n      break;\n    }\n  }\n\n  return '/' + segmentBuffers.map((buffer) => buffer.join('')).join('/');\n}\n\n/**\n * Removes dot segments of the given IRI.\n * @param {string} iri An IRI (or part of IRI).\n * @param {number} colonPosition The position of the first ':' in the IRI.\n * @return {string} The IRI where dot segments were removed.\n */\nexport function removeDotSegmentsOfPath(iri: string, colonPosition: number): string {\n  // Determine where we should start looking for the first '/' that indicates the start of the path\n  let searchOffset = colonPosition + 1;\n  if (colonPosition >= 0) {\n    if (iri[colonPosition + 1] === '/' && iri[colonPosition + 2] === '/') {\n      searchOffset = colonPosition + 3;\n    }\n  } else {\n    if (iri[0] === '/' && iri[1] === '/') {\n      searchOffset = 2;\n    }\n  }\n\n  // Determine the path\n  const pathSeparator = iri.indexOf('/', searchOffset);\n  if (pathSeparator < 0) {\n    return iri;\n  }\n  const base = iri.substr(0, pathSeparator);\n  const path = iri.substr(pathSeparator);\n\n  // Remove dot segments from the path\n  return base + removeDotSegments(path);\n}\n\nfunction isCharacterAllowedAfterRelativePathSegment(character: string) {\n  return !character || character === '#' || character === '?' || character === '/';\n}\n"],"mappings":";;;;;;;;;AAAA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;;ACTA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AAEA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AAMA;AAEA;AACA;AACA;AAEA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;;;;;;;;;;;;AC3EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;ACz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nhBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAMA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AAEA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AAEA;AAEA;AAEA;AAEA;AACA;AACA;AACA;AACA;AAEA;AAEA;AAEA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AAGA;AAEA;AAEA;AAEA;AAEA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAGA;AACA;AACA;AACA;AAKA;AACA;AAEA;AAEA;AAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACtZA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;ACNA;AACA;AACA;AACA;AAGA;AACA;AAEA;AACA;AAEA;;;AAGA;AAWA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;AASA;AACA;AACA;;AAGA;AACA;AACA;AAEA;AACA;;;AAIA;AACA;AAEA;;;;;;;;AAQA;AACA;AACA;;AAIA;AACA;AACA;AAEA;AACA;;;AAIA;AACA;AAEA;;;;;AAKA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;;;;;AAMA;AACA;AAEA;;;;;;AAMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;;AAIA;AACA;AACA;AACA;;AAGA;AACA;AAEA;;AAIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAGA;AAGA;AACA;AACA;AACA;;AAEA;;;AAGA;AACA;;;;;AAKA;AAEA;;;;;AAKA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;AAMA;AAEA;;;;AAIA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;;AAEA;;;;AAIA;AAEA;;;;;AAKA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;;;AAIA;;;AAGA;AAEA;;;;;;AAMA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;;;AAIA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;;;;AAOA;AAEA;;;;;AAKA;AAAA;AAAA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;;AAIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AAAA;AAGA;AACA;AACA;;AAKA;;AAGA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AAEA;AACA;;;AAKA;AACA;AACA;AAEA;;AAIA;AACA;AACA;AACA;;AAGA;AACA;AACA;AAEA;;AAGA;AACA;AACA;AAEA;AAEA;;;AAKA;AACA;;AAIA;AACA;;AAIA;AACA;AACA;AACA;;AAIA;AACA;;AAGA;AAIA;;AAGA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAGA;AACA;AACA;AACA;AAEA;AACA;;;AAGA;AACA;AACA;;AAGA;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;;AAGA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;;AAEA;;AAGA;AACA;AACA;AACA;;;AAIA;AAEA;;;;;;;AAOA;AAEA;AACA;AACA;;AAGA;AACA;AAEA;AACA;AACA;;;AAIA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;;AAIA;AACA;AAEA;;;;;;AAMA;AACA;AACA;AACA;AACA;AACA;;;AAIA;AACA;AACA;;AAGA;AACA;AAEA;;;;;;AAMA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;;;AAIA;AACA;AAAA;AAAA;AAAA;AAAA;;;;AAKA;AACA;AAEA;;;;;;AAMA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAEA;AACA;AAEA;AACA;AACA;;AAIA;AACA;AACA;AACA;;AAIA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AAGA;AACA;AACA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AAEA;AACA;AACA;;AAGA;AAGA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAIA;AACA;AAEA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;;AAGA;AACA;AAEA;AACA;AACA;;AAGA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;;AAIA;AACA;AACA;AACA;AACA;;;AAKA;AACA;AAMA;AAEA;AACA;AAEA;AACA;AAGA;;AAGA;AACA;AACA;AAEA;AACA;AACA;;AAGA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AACA;AAAA;AAAA;;AAGA;AACA;AACA;;AAGA;AAEA;;;;;AAKA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;;AAIA;AACA;AACA;;AAIA;AACA;AAEA;;;;;;;;;AASA;AACA;AACA;AACA;AACA;AACA;;;AAIA;AACA;AAEA;;;;AAIA;AACA;AACA;AAEA;AACA;AACA;;AAIA;AACA;AACA;;AAIA;AACA;AACA;AACA;AACA;;AAv2BA;AAEA;AAg9BA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;ACr+BA;;;;;;AAMA;AAOA;AACA;AACA;AACA;AACA;;AAXA;AAeA;;;;AAIA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;AC7EA;AAGA;AACA;AACA;AAEA;;;AAGA;AAIA;AACA;AACA;AAEA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;;;AAIA;AACA;AACA;;;AAIA;;AAGA;AACA;;AAEA;;AAjDA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACVA;;;;;;;;;;;;;;;;;;;;;ACAA;AACA;AACA;AAEA;AAEA;;;AAGA;AAIA;AACA;AACA;AAEA;;;AAGA;AACA;AACA;AAEA;;;;;;;;;;;;;;;;;;;;;AAqBA;AAEA;AAEA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;;;AAKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;;AAIA;;AAEA;AAEA;AACA;AACA;AACA;AACA;;AAGA;AACA;;AAEA;AACA;;AAGA;AACA;AACA;AACA;AACA;;AAGA;AAEA;;;;;;;;;;AAUA;AACA;AACA;AACA;;AAGA;AACA;AACA;;AAGA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;;;;AAMA;AACA;AACA;;AAGA;AACA;;AAtKA;;;;;;;;;;;;;;;;;;ACNA;AAwFA;;;;;;AAMA;AACA;AACA;AAEA;;;;;;;AAOA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AAGA;;AAGA;AAEA;AACA;AACA;;AAGA;AACA;AACA;;;AAGA;AACA;AAEA;;;;;AAKA;AACA;AACA;;AAEA;AACA;AACA;AAEA;;;;;;AAMA;AACA;AAEA;AAEA;;;;;AAKA;AACA;AACA;AAEA;;;;;AAKA;AACA;AACA;AAEA;;;;;AAKA;AACA;AACA;AAEA;;;;;AAKA;AACA;AACA;AAEA;;;;;AAKA;AACA;AACA;AAEA;;;;;AAKA;AACA;AACA;AAEA;;;;;;AAMA;AACA;AACA;AACA;AAEA;;;;;AAKA;AACA;AACA;AACA;;;AAGA;AACA;AAEA;;;;AAIA;AACA;AACA;;AApPA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAOA;AACA;AAeA;AACA;AAIA;AACA;AASA;AACA;;;;;;;;;;;;ACrFA;AACA;AAAA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;;;;;;;;;;;;ACZA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;AC3CA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AAEA;AAAA;AAAA;AAAA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;ACvbA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AAEA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;AChUA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;AC7xBA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;;;;;;;;;;;;ACnDA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;;;;;;;;;;;;ACrEA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AAEA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;;;;;;;;;;;;AC9BA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;;;;;;;;;;;;AC5DA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;ACzHA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;AC3LA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;ACxBA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAEA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;ACxIA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;ACvBA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAIA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;ACnCA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;AChBA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;ACtCA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;AC1BA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;ACtBA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;AC3EA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;;;;;;;;;;;;ACnDA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;A5BpCA;;;;;;;;;;;;;;;;;;A6BAA;;;;;;;;AAQA;AACA;AACA;AAEA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;;AAEA;;AAGA;AACA;AACA;AACA;AACA;;AAEA;;AAGA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;;AAEA;;AAGA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAIA;AACA;AACA;;AAGA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAIA;AACA;AAEA;AACA;AAEA;AACA;AACA;AA7GA;AA+GA;;;;;;AAMA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AAEA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;;AAGA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAAA;;AAIA;AACA;AA1EA;AA4EA;;;;;;AAMA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;;AAIA;AACA;AACA;AACA;;AAEA;AACA;AAEA;AACA;AACA;AAvBA;AAyBA;AACA;AACA;;;;A","sourceRoot":""}